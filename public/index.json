[{"content":"You can back up your AKS clusters using Azure Backup in preview! Preferably you have your clusters stateless and you can redeploy everything from code when sh*t hits the fan. However, I can think of a few enterprise use cases that will be relevant for this new feature.\nhttps://learn.microsoft.com/en-us/azure/backup/azure-kubernetes-service-cluster-backup\nLinks: 202310130610\n[[aks]]\n[[kubernetes]]\n[[azure]]\n","permalink":"https://mischavandenburg.com/zet/aks-azure-backup-preview/","summary":"You can back up your AKS clusters using Azure Backup in preview! Preferably you have your clusters stateless and you can redeploy everything from code when sh*t hits the fan. However, I can think of a few enterprise use cases that will be relevant for this new feature.\nhttps://learn.microsoft.com/en-us/azure/backup/azure-kubernetes-service-cluster-backup\nLinks: 202310130610\n[[aks]]\n[[kubernetes]]\n[[azure]]","title":"Backing up AKS Clusters with Azure Backup is now in preview"},{"content":"This week I\u0026rsquo;ve been tackling an issue at work with akv2k8s.\nWe are running CloudnativePG, similar to EnterpriseDB. After upgrading akv2k8s to v2.5.0 our database pods were not coming up anymore due to an error with the initcontainer:\nError: container has runAsNonRoot and image has non-numeric user (nonroot), cannot verify user is non-root (pod: \u0026#34;vcs-pooler-rw-858bf7c954-vjzr4_vcs(e19bfa4c-26d8-4a6d-b4ad-bba8b52c01e6)\u0026#34;, container: bootstrap-controller) Pods have a security context where you specify how the containers in the pod should be run.\nsecurityContext: runAsUser: 998 runAsGroup: 996 runAsNonRoot: true fsGroup: 996 Here we are telling the pod that we may not run as the root user and that we will run as user 998.\nMy error states that it cannot verify whether it is running as root or not because we are using a non-numeric user.\nWe were dumbfounded by this because the deployment and ReplicaSet neatly had their securitycontexts configured and the pods should inherit them. After a lot of searching I figured out that the securitycontext of the pods was actually empty, so somehow it must be overridden somewhere.\nThe culprit was the akv2k8s envinjector. This tool injects the secrets into the environment of the pods. It took a lot of experimentation but we managed to narrow it down to the akv2k8s upgrade and eventually we found this GitHub issue:\nhttps://github.com/SparebankenVest/azure-key-vault-to-kubernetes/issues/605\nFor some reason the envinjector is overriding the securitycontext of the pods. The issue was fixed by downgrading the helm chart back to 2.4.2\nI did learn a lot in the process though!\nLinks: 202310130610\nhttps://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/installation_upgrade/\nhttps://github.com/SparebankenVest/azure-key-vault-to-kubernetes/issues/605\nhttps://stackoverflow.com/questions/53949329/kubernetes-runasnonroot-failing-createcontainerconfigerror\nhttps://github.com/cloudnative-pg/cloudnative-pg\n","permalink":"https://mischavandenburg.com/zet/akv2k8s-edb-initcontainer-securitycontext/","summary":"This week I\u0026rsquo;ve been tackling an issue at work with akv2k8s.\nWe are running CloudnativePG, similar to EnterpriseDB. After upgrading akv2k8s to v2.5.0 our database pods were not coming up anymore due to an error with the initcontainer:\nError: container has runAsNonRoot and image has non-numeric user (nonroot), cannot verify user is non-root (pod: \u0026#34;vcs-pooler-rw-858bf7c954-vjzr4_vcs(e19bfa4c-26d8-4a6d-b4ad-bba8b52c01e6)\u0026#34;, container: bootstrap-controller) Pods have a security context where you specify how the containers in the pod should be run.","title":"Fixed an issue with akv2k8s overriding security context"},{"content":"Learned a new trick to force a new cert from letsencrypt. Had this error message:\nThe certificate request has failed to complete and will be retried: Failed to wait for order resource \u0026#34;vcs-secret-j8gnj-3121219202\u0026#34; to become ready: order is in \u0026#34;errored\u0026#34; state: Failed to create Order: 429 urn:ietf:params:acme:error:rateLimited: Error creating new order :: too many certificates (5) already issued for this exact set of domains in the last 168 hours: sadfsadf.com, retry after 2023-10-12T18:54:27Z: see https://letsencrypt.org/docs/duplicate-certificate-limit/ I asked for too many certificates during a 168 hour period. However, there is a really easy fix. Just add a new subdomain and LetsEncrypt will treat it as an entirely new certificate!\nFor example, when using cert-manager:\napiVersion: cert-manager.io/v1 kind: Certificate metadata: creationTimestamp: \u0026#39;2023-10-12T11:09:36Z\u0026#39; generation: 2 labels: argocd.argoproj.io/instance: vcs-dev name: vcs-secret namespace: vcs ownerReferences: - apiVersion: networking.k8s.io/v1 blockOwnerDeletion: true controller: true kind: Ingress name: vcs-ingress uid: xxxxx resourceVersion: \u0026#39;226558404\u0026#39; uid: xxxx spec: dnsNames: - vcs.mischavandenburg.com - test.mischavandenburg.com issuerRef: group: cert-manager.io kind: ClusterIssuer name: letsencrypt-prod secretName: vcs-secret usages: - digital signature - key encipherment Just add another domain under spec.dnsNames and it will treat it as a new cert.\nspec: dnsNames: - vcs.mischavandenburg.com - test.mischavandenburg.com - hello.mischavandenburg.com Links: 202310121310\n[[kubernetes]]\n","permalink":"https://mischavandenburg.com/zet/forcing-new-cert-letsencrypt-timeout/","summary":"Learned a new trick to force a new cert from letsencrypt. Had this error message:\nThe certificate request has failed to complete and will be retried: Failed to wait for order resource \u0026#34;vcs-secret-j8gnj-3121219202\u0026#34; to become ready: order is in \u0026#34;errored\u0026#34; state: Failed to create Order: 429 urn:ietf:params:acme:error:rateLimited: Error creating new order :: too many certificates (5) already issued for this exact set of domains in the last 168 hours: sadfsadf.com, retry after 2023-10-12T18:54:27Z: see https://letsencrypt.","title":"Forcing a new cert from letsencrypt when too many have been issued"},{"content":"Missed a few weeknotes due to holidays but today I felt like writing one again.\nI started a new consultancy gig at Van Oord this week. They gave me a warm welcome and after a few days of setting everything up and waiting for some accounts I look forward to get productive next monday. I\u0026rsquo;ll be working in an Azure environment with Kubernetes clusters that need some love and there will be much room to develop my skillset while making contributions to the company.\nExercise \u0026amp; Weight Loss After transitioning to barefoot shoes I\u0026rsquo;m now running 4km about 3-4 times a week. My achilles tendons hurt a bit but otherwise the transition is going well.\nContent Consumption Reading I abaondoned the Polity series and sci-fi project for know and started re-reading The Last Kingdom series instead. I love reading about Uthred and his adventures in England around 860AD. It\u0026rsquo;s been years since I\u0026rsquo;ve read them and I\u0026rsquo;ve forgotton most of the story. I find myself particulary interested by King Alfred the Great.\nGaming Last week I met an old friend and he showed me the Magic The Gathering collection that he amassed over the years. I used to play when I was a kid and it spawned a wave of nostalgia. He invited me to some tabletop / magic game nights that he regularly does with his friends which was very kind of him. It\u0026rsquo;s something I\u0026rsquo;ve always wanted to discover but I never found the right group.\nWhen I came home I started searching the internet about MTG and I discovered MTG Arena and I\u0026rsquo;ve been re-learning the game and it has been quite fun.\nThis Sunday I still felt very tired from the first week at the new workplace. It\u0026rsquo;s always a lot of stimualtion and impulses to process for me and I forced myself to do absolutely nothing this weekend. So this sunday I played MTG Arena all day and now that I\u0026rsquo;m writing these weeknotes on sunday evening I feel very calm, relaxed and recharged, ready for the new work week.\nListening Listening to Tyr a lot.\nLinks: 202310082110\n","permalink":"https://mischavandenburg.com/zet/2023-week-40/","summary":"Missed a few weeknotes due to holidays but today I felt like writing one again.\nI started a new consultancy gig at Van Oord this week. They gave me a warm welcome and after a few days of setting everything up and waiting for some accounts I look forward to get productive next monday. I\u0026rsquo;ll be working in an Azure environment with Kubernetes clusters that need some love and there will be much room to develop my skillset while making contributions to the company.","title":"2023 week 40"},{"content":"This Sunday I still felt very tired from the first week at the new workplace. It\u0026rsquo;s always a lot of stimualtion and impulses to process for me and I forced myself to do absolutely nothing this weekend. So today I played Magic The Gathering Arena all day and now that I\u0026rsquo;m writing these weeknotes on sunday evening I feel very calm, relaxed and recharged, ready for the new work week.\nThis is also something that came up during my hikes in Norway. I have a need to introduce more play and less rigidity into my life. I love routines, protocols and predictability. Play is about improvisation, creativity and not knowing what will happen.\nI need more of that in my life, and I feel now that it is having a positive effect. I\u0026rsquo;m not saying I should game for 8 hours a day, I just need to loosen up a little bit on the productivity. Especially play that involves other people.\nI purchased a Magic The Gathering starter kit and hung out with my brother on Saturday and we had a great time socializing over this game. It is a bonding activity through play.\nLinks: 202310082110\n","permalink":"https://mischavandenburg.com/zet/more-play/","summary":"This Sunday I still felt very tired from the first week at the new workplace. It\u0026rsquo;s always a lot of stimualtion and impulses to process for me and I forced myself to do absolutely nothing this weekend. So today I played Magic The Gathering Arena all day and now that I\u0026rsquo;m writing these weeknotes on sunday evening I feel very calm, relaxed and recharged, ready for the new work week.","title":"Introducing more play into my life"},{"content":"Ran into a problem when cloning my second brain repository on a new windows machine which I need to use for work. Also trying to get familiar with VSCode although I\u0026rsquo;m doing my best to get a good WSL setup going on my new windows setup.\nOne problem I was running into was that I could not for the life of me clone my repository at all on Windows. Eventually I realized that it kept failing on a file that had a question mark in its filename.\nI renamed all the files that had invalid characters.\nIt also failed because apparently I had a file in the repo named \u0026ldquo;\u0026quot;. It didn\u0026rsquo;t like that at all.\nAfter changing the filenames it worked.\nIt is good to keep my second brain compatible with all operating systems so this is actually a good practice session.\nLinks: 202310052010\n","permalink":"https://mischavandenburg.com/zet/windows-filenames-invalid/","summary":"Ran into a problem when cloning my second brain repository on a new windows machine which I need to use for work. Also trying to get familiar with VSCode although I\u0026rsquo;m doing my best to get a good WSL setup going on my new windows setup.\nOne problem I was running into was that I could not for the life of me clone my repository at all on Windows. Eventually I realized that it kept failing on a file that had a question mark in its filename.","title":"Dont Use Question Marks in Windows Filenames"},{"content":"Although I rarely use Obsidian anymore, I still have it open because it is running the obsidian-git plugin in the background and it is constantly backing up my second brain to GitHub.\nI use iCloud to synch my vault across my iOs devices and I always create and edit my files using neovim.\nFor my new gig at work I\u0026rsquo;m forced to use a windows laptop which means I cannot use iCloud to synch my vault. Then it is a godsend to be able to install Obsidian and use that to interact with my second brain.\nIt is very good to keep it compatible with obsidian so I can use the software for synching and interacting with my second brain on other operating systems conveniently.\nLinks: 202310052010\n[[second-brain]] [[notetaking]]\n","permalink":"https://mischavandenburg.com/zet/keep-second-brain-obsidian-compatible/","summary":"Although I rarely use Obsidian anymore, I still have it open because it is running the obsidian-git plugin in the background and it is constantly backing up my second brain to GitHub.\nI use iCloud to synch my vault across my iOs devices and I always create and edit my files using neovim.\nFor my new gig at work I\u0026rsquo;m forced to use a windows laptop which means I cannot use iCloud to synch my vault.","title":"It is good to keep your second brain compatible with Obsidian"},{"content":"Recently I was comparing apps for navigation (TopoGPS and Outdooractive). Both apps are great, but the main perk of Outdooractive is that it has a web interface. You can plan routes from your computer and access them on the iPhone app, but TopoGPS is on the iPhone only.\nThe app I probably have the most interaction with during the day is my calorie tracking app. I\u0026rsquo;ve been using YAZIO for about two years and it has been satisfactory, but there were a few small annoyances to the app and I was never completely satisfied with.\nA missing web interface being one of them. I\u0026rsquo;d love to be able to sit behind my 4K screen and plan out the week\u0026rsquo;s nutrition from there instead of using the clunky copy function on my phone.\nEnter MyFitnessPal. It has a web interface. It has charts and graphs. Me happy.\nWhy didn\u0026rsquo;t I chose this app when I began using an app for my phone? I remember trying it out, but I was unhappy with it somehow. I remember something about the food database not containing the foods I was eating at the time. I\u0026rsquo;ve been doing some testing and up until now I haven\u0026rsquo;t had to add any foods.\nI have a year\u0026rsquo;s subscription on YAZIO until March so it is a bit of a waste, but I\u0026rsquo;m already sold on the web interface of MFP. I have one free month of premium and I\u0026rsquo;ll make the decision then.\nLinks: 202310011810\n[[health]]\n[[diet]]\n[[vegan]]\n[[weight-loss]]\n","permalink":"https://mischavandenburg.com/zet/myfitnesspal-web-interface/","summary":"Recently I was comparing apps for navigation (TopoGPS and Outdooractive). Both apps are great, but the main perk of Outdooractive is that it has a web interface. You can plan routes from your computer and access them on the iPhone app, but TopoGPS is on the iPhone only.\nThe app I probably have the most interaction with during the day is my calorie tracking app. I\u0026rsquo;ve been using YAZIO for about two years and it has been satisfactory, but there were a few small annoyances to the app and I was never completely satisfied with.","title":"Apps with web interfaces win any day, switching to MyFitnessPal"},{"content":"Professor Longo recommends eating the same ingredients that your ancestors ate in his book The Longevity Diet.\nToday I asked my 91 year old grandmother about her diet and her eating habits when she was younger. She was around 10 years old during the Second World War when food was very scarce and people were struggling to survive. I knew already that meat was a luxury product during her early life and that they consumed meat maybe once or twice a week in small quantities.\nFrom our conversation I learned the following:\nthey ate three meals a day: breakfast, a larger warm midday meal and a light evening meal the staples were oatmeal, rice (which surprised me), potatoes, carrots, bread, milk, cheese and eggs breakfast was usually oatmeal porridge they ate dinner at noon and had a light meal in the evening, usually a couple of slices of bread dinner was often rice porridge boiled in milk or potatoes with carrots, onions and a little meat (hutspot) she had never eaten french fries until she was 60 years old they didn\u0026rsquo;t have any snacks sometimes she was sent to bed with only a carrot I have always loved eating oatmeal, rice, bread and potatoes, and I never grow tired of these ingredients. Now I know why! It is exactly what my ancestors ate. I will keep eating these as main staples of my diet.\nEspecially the rice was surprising to me, I didn\u0026rsquo;t know that rice was generally available during that time already but apparently it was.\nLinks: 202309302009\n[[health]] [[diet]] [[Longo-The Longevity Diet]]\n","permalink":"https://mischavandenburg.com/zet/what-my-ancestors-ate/","summary":"Professor Longo recommends eating the same ingredients that your ancestors ate in his book The Longevity Diet.\nToday I asked my 91 year old grandmother about her diet and her eating habits when she was younger. She was around 10 years old during the Second World War when food was very scarce and people were struggling to survive. I knew already that meat was a luxury product during her early life and that they consumed meat maybe once or twice a week in small quantities.","title":"What My Ancestors Ate"},{"content":"I\u0026rsquo;ve been reading The Longevity Diet by professor Valter Longo after encountering him in several podcasts.\nI\u0026rsquo;m always experimenting with diet protols and this one seems interesting because its plant based but has an eating pattern that is very different from what I\u0026rsquo;m used to. I\u0026rsquo;ve been intermittent fasting for over 8 years and my eating windows have varied from 1 to 10 hours, usually skipping breakfast. However, based on his research, professor Longo recommends not skipping breakfast and skipping lunch instead.\nBased on his research on centenarians he recommends eating a pescetarian diet with two small servings of high quality fish a week. I don\u0026rsquo;t like seafood however, the thought of eating something that has been swimming around in our polluted seas absorbing heavy metals and microplastics repulses me. I will have to see if I can find high quality fish. Soon I will be doing a blood test with Inside Tracker to see how my levels of nutrients are. If everything looks good I will probably wait with including fish into my diet. However, if it extends my lifespan and improves my health and well being I am willing to start eating a pescetarian diet.\nAdditionally, professor Longo recommends doing a 5 day fast at leat twice a year where you consume about 800 calories a day, which he calls a Fasting Mimicking Diet.\nMy main takeaways which I\u0026rsquo;m implementing now:\nStart eating two meals a day, breakfast and dinner plus a 100 calorie snack 12 hour eating window Do a 5 day fast 4 times a year Consider eating fish twice a week, start looking for high quality sources Research what my ancestors ate and select main ingredients accordingly The Longevity Diet for Adults Eat mostly vegan, plus a little fish, limiting meals with fish to a maximum of two or three per week. Choose fish, crustaceans, and mollusks with a high omega-3, omega-6, and vitamin B12 content (salmon, anchovies, sardines, cod, sea bream, trout, clams, shrimp. Pay attention to the quality of the fish, choosing those with low levels of mercury. If you are below the age of 65, keep protein intake low (0.31 to 0.36 grams per pound of body weight). That comes to 40 to 47 grams of proteins per day for a person weighing 130 pounds, and 60 to 70 grams of protein per day for someone weighing 200 to 220 pounds. (100kg) Over age 65, you should slightly increase protein intake but also increase consumption of fish, eggs, white meat, and products derived from goats and sheep to preserve muscle mass. Consume beans, chickpeas, green peas, and other legumes as your main source of protein. Minimize saturated fats from animal and vegetable sources (meat, cheese) and sugar, and maximize good fats and complex carbs. Eat whole grains and high quantities of vegetables (tomatoes, broccoli, carrots, legumes, etc.) with generous amounts of olive oil (3 tablespoons per day) and nuts (1 ounce per day). (30g) Follow a diet with high vitamin and mineral content, supplemented with a multivitamin buffer every three days. Select ingredients among those discussed in this book that your ancestors would have eaten. Based on your weight, age, and abdominal circumference, decide whether to have two or three meals per day. If you are overweight or tend to gain weight easily, consume two meals a day: breakfast and either lunch or dinner, plus two low-sugar (less than 5 grams) snacks with fewer than 100 calories each. If you are already at a normal weight, or if you tend to lose weight easily or are over 65 and of normal weight, eat three meals a day and one low-sugar (less than 3 to 5 grams) snack with fewer than 100 calories. Confine all eating to within a twelve-hour period; for example, start after 8 a.m. and end before 8 p.m. Don’t eat anything within three to four hours of bedtime. https://www.valterlongo.com/daily-longevity-diet-for-adults/\nDo not skip breakfast For people trying to lose weight or those who tend to be heavy, the best nutritional advice is to eat breakfast daily; have lunch or dinner, but not both; and substitute for the missed meal one snack containing fewer than 100 calories and no more than 3 to 5 grams of sugar. (Do not skip breakfast, as this has been associated with increased risk for age-related diseases in multiple studies.)\nThe Recipe for a long life Areas of the world known to have the highest prevalence of centenarians—Okinawa, Japan; Loma Linda, California; small towns in Calabria and Sardinia, Italy; and in Costa Rica and Greece—all share diets that are (1) mostly plant-based with lots of nuts and some fish; (2) low in proteins, sugars, and saturated/trans fats; and (3) high in complex carbohydrates coming from beans and other plant-based foods. Most of these centenarians ate only two or three times a day, ate light meals in the evening, and were in many cases done eating before dark.\nEat low protein until 70, then increase with 20% In other words, maintaining a high-vegetable, low-protein diet for the first seventy or eighty years of life, and later switching to a diet richer in proteins but also animal-based foods like eggs, chicken, milk, and certain cheeses, may have slowed down aging and optimized the health of the Molochio centenarians. This explanation fits with our discovery that low-protein intake is associated with extended longevity and a major reduction in cancer in people age sixty-five and younger, but not in those above sixty-six.\nProlonged caloric restriction is not beneficial for health So, on the one hand we know that chronic caloric restriction can have profoundly beneficial effects on risk factors for many diseases. On the other hand, we know that chronic and extreme diets—diets that reduce calories by 20 percent or more and are maintained for long periods or permanently—can negatively affect necessary processes, including wound healing, immune response, and cold-temperature tolerance. Put simply, besides making a person extremely thin, the detrimental effects of chronic calorie restriction appear to minimize its benefits by causing a major increase in other types of diseases and conditions that are less well understood. The focus of the rest of this book is on how to obtain the remarkable beneficial effects of calorie restriction without the negative ones.\nEpidemiology: low protein high carb plant based diets are healthiest Most large-population studies show an association between longevity and disease prevention, and a diet that is low in protein; largely plant- and fish-based; and rich in complex carbohydrates, olive oil, and nuts. For example, our epidemiological study of six thousand Americans suggested that consuming a high-protein diet is associated with increased levels of the pro-aging growth factor IGF-1 (see fig. 4.3), a 75 percent increased risk of overall mortality, and a three- to fourfold increased risk in cancer mortality compared with consuming the low-protein and plant-based diet recommended here (see fig. 4.4).12 Contrary to the findings of T. Colin Campbell in The China Study, which advocates consuming low levels of plant-based proteins throughout life, the beneficial effect of a low-protein diet seems to apply only before age sixty-five (fig. 4.3). A Harvard study of nearly 130,000 doctors and nurses also indicates that a low-carb diet high in animal fat and protein is associated with increases in overall cancer and cardiovascular disease mortality, a finding that is in agreement with our research.13 In line with our previous protein study, a follow-up study of the same group followed by Harvard University, in which I acted as a co-author, showed that consumption of high levels of animal but not plant-based proteins was associated with increased mortality from cardiovascular disease.14 A similar study of forty thousand men suggests that a low-carb, high-animal-protein diet is associated with a twofold increase in diabetes, a finding also consistent with our discovery in the six-thousand-person protein study.15 A number of other epidemiological studies consistently associate high IGF-1 levels in the bloodstream with an increase of twofold or more in the incidence of breast, prostate, and other cancer types.16 Because we know that protein consumption is the key regulator of IGF-1 levels and that animal-protein intake is usually associated with intake of saturated animal fats, these studies bolster the case for a link between cancer, diabetes, and high protein and saturated fat intake.Epidemiological studies also support the key role of nourishment in disease prevention, since populations with deficiencies in certain vitamins have been shown to have an increased incidence for a variety of diseases. For example, vitamin D deficiency has been associated with an increased risk for diabetes and autoimmune and cardiovascular diseases.17\nLinks: 202309300809\nhttps://www.menshealth.com/nutrition/a19513749/rich-roll-vegan-diet/\nhttps://www.valterlongo.com/daily-longevity-diet-for-adults/\n","permalink":"https://mischavandenburg.com/zet/longevity-diet/","summary":"I\u0026rsquo;ve been reading The Longevity Diet by professor Valter Longo after encountering him in several podcasts.\nI\u0026rsquo;m always experimenting with diet protols and this one seems interesting because its plant based but has an eating pattern that is very different from what I\u0026rsquo;m used to. I\u0026rsquo;ve been intermittent fasting for over 8 years and my eating windows have varied from 1 to 10 hours, usually skipping breakfast. However, based on his research, professor Longo recommends not skipping breakfast and skipping lunch instead.","title":"The Longevity Diet - Prof. Valter Longo"},{"content":" Frontend Azure You can have multiple frontends in one gateway to save money. Teams could share the app gateway but use different frontend IP addresses or FQDNs.\nControl plane: Azure App Gateway for Containers\nData plane: association with kubernetes pods.\nThe association is made to the subnet in the Azure VNet.\nEach association is in one subnet, and the subnet should at least have /24 or 256 addresses.\nKubernetes ALB controller consists of two pods. Controller pod and a bootstrap pod.\nController communicates to the Azure gateway resource. It talks directly to the App Gateway, not to the Azure Resource Manager, which is why you\u0026rsquo;re able to have sub-second updates.\nThe bootstrap contains the CRDs etc, it does not do very much.\nCreating resources There is a managed option that will talk to ARM and create the resources for you. Or you can choose to deploy them yourself. It depends whether you want to control everything from Kubernetes. If you have all your Azure resources in Infrastructure as Code it probably makes more sense to create the App Gateway resources from there instead of from Kubernetes.\nAssociation This is an Azure resource. It lives in the VNet and handles TLS and makes the connections to and from the pods and frontend IP. This is the data path.\nSupport Azure CNI. Does not support kubenet or Azure CNI overlay yet, but it will support in the future.\nBackend Links: 202309301009\n","permalink":"https://mischavandenburg.com/zet/application-gateway-for-containers/","summary":"Frontend Azure You can have multiple frontends in one gateway to save money. Teams could share the app gateway but use different frontend IP addresses or FQDNs.\nControl plane: Azure App Gateway for Containers\nData plane: association with kubernetes pods.\nThe association is made to the subnet in the Azure VNet.\nEach association is in one subnet, and the subnet should at least have /24 or 256 addresses.\nKubernetes ALB controller consists of two pods.","title":"Video notes - Application Gateway for Containers"},{"content":"Before I went on holiday I formed the intention to begin studying again after I came back.\nDuring my current gig I\u0026rsquo;m configuring a fair bit of networking, VNets, peerings, firewall rules and set up a full hub-spoke network from scratch, so I\u0026rsquo;ve had a fair bit of practical experience. Now that the experience is still fresh in the mind I figured I\u0026rsquo;d go for this certification.\nUsually I only use Microsoft Learn and practice exams, but this time around I want to try out a video course. I purchased a year of A Cloud Guru access and so far it has been a good experience.\nI\u0026rsquo;ll publish my notes as I go along.\nLinks: 202309280909\n","permalink":"https://mischavandenburg.com/zet/starting-az-700/","summary":"Before I went on holiday I formed the intention to begin studying again after I came back.\nDuring my current gig I\u0026rsquo;m configuring a fair bit of networking, VNets, peerings, firewall rules and set up a full hub-spoke network from scratch, so I\u0026rsquo;ve had a fair bit of practical experience. Now that the experience is still fresh in the mind I figured I\u0026rsquo;d go for this certification.\nUsually I only use Microsoft Learn and practice exams, but this time around I want to try out a video course.","title":"Began studying for AZ-700 Designing and Implementing Microsoft Azure Networking Solutions"},{"content":"I notice that I\u0026rsquo;m not writing in my journal every day like I used to. I always wrote down what I did, what I felt, what my plans and ambitions were, every single day.\nDuring my holiday I started writing by hand in a notebook again which was really nice. It felt good to feel the pencil scratching on the paper again and to practice my cursive writing.\nAfter I came back I first tried to keep journaling by hand again, but after a few days the journal remained untouched. I figured I would go back to my usual digital journaling again by writing daily notes.\nI\u0026rsquo;m a litlte intruiged. I do feel very relaxed and at ease, perhaps I do not need to write so much at this time? Writing down frustrations and feelings definitely has been a certain way of processing them.\nAnd perhaps my routine is reaching such a degree of stability that it is simply not worth the effort of writing it all down all the time.\nRather than writing in my personal notes, I do have the intention to write more zets in my public zettelkasten on all the topics that interest me currently. Micronotes.\nLinks: 202309282109\n","permalink":"https://mischavandenburg.com/zet/not-journaling-as-often/","summary":"I notice that I\u0026rsquo;m not writing in my journal every day like I used to. I always wrote down what I did, what I felt, what my plans and ambitions were, every single day.\nDuring my holiday I started writing by hand in a notebook again which was really nice. It felt good to feel the pencil scratching on the paper again and to practice my cursive writing.\nAfter I came back I first tried to keep journaling by hand again, but after a few days the journal remained untouched.","title":"I'm not journaling as often as I used to"},{"content":"Yesterday a few interesting AKS related features became Generally Available on Azure.\nKEDA add-on makes it easier to scale your applications on AKS cluster.\nhttps://azure.microsoft.com/en-us/updates/generally-available-keda-addon-for-aks/\nYou can have a flexible and customized strategy for node-level OS security updates.\nhttps://azure.microsoft.com/en-us/updates/ga-node-os-patching-nodeimage-feature-in-aks/\nUse Vertical Pod Autoscaling add-on for AKS to improve cost-efficiency, and cluster utilization for your workloads\nhttps://azure.microsoft.com/en-us/updates/ga-vertical-pod-autoscaling-addon-for-aks/\nPreview Public preview: AKS support for Kubernetes version 1.28\nhttps://azure.microsoft.com/en-us/updates/public-preview-aks-support-for-kubernetes-version-128/\nLinks: 202309281009\n[[azure]]\n[[kubernetes]]\n","permalink":"https://mischavandenburg.com/zet/azure-updates-sept-23/","summary":"Yesterday a few interesting AKS related features became Generally Available on Azure.\nKEDA add-on makes it easier to scale your applications on AKS cluster.\nhttps://azure.microsoft.com/en-us/updates/generally-available-keda-addon-for-aks/\nYou can have a flexible and customized strategy for node-level OS security updates.\nhttps://azure.microsoft.com/en-us/updates/ga-node-os-patching-nodeimage-feature-in-aks/\nUse Vertical Pod Autoscaling add-on for AKS to improve cost-efficiency, and cluster utilization for your workloads\nhttps://azure.microsoft.com/en-us/updates/ga-vertical-pod-autoscaling-addon-for-aks/\nPreview Public preview: AKS support for Kubernetes version 1.28\nhttps://azure.microsoft.com/en-us/updates/public-preview-aks-support-for-kubernetes-version-128/\nLinks: 202309281009\n[[azure]]\n[[kubernetes]]","title":"Some Interesting Features went GA on Azure"},{"content":"I\u0026rsquo;ve been back for about two weeks now. I had the best holiday of my life. Three weeks of roaming in Norway, visiting friends and reconnecting with nature.\nI went hiking in Jotunheimen for a few days and walked Beseggen.\nBut the main event was a 8 day thru hike of Trollheimen. I hiked 20-25km a day from cabin to cabin for a total of 130km, and it has been the best experience of my life. Surrounded by nature and silence, completely alone, I had all the time in the world to think everything through and to gain a new perspective on certain areas of my life.\nWhen you set out in the morning the mind is very active for a couple of hours, bubbling with ideas and eagerly reflecting on life. But after a few hours the body starts getting tired, the mind calms down by itself, and when you realize you still have 6 hours of hiking to go, you automatically start focusing completely on the present moment and the task at hand. A deep calm arises and you are simply concerned with where you place your next footstep.\nI have hiked thousands of kilometres before in my life, but this holiday it all came together somehow. Perhaps it was the contrast of working so hard for two full years to change my career without taking much vacation, and now finding myself in these new surroundings with a calm mind.\nDuring my hikes I have gained a few insights and there are a few things I\u0026rsquo;ll be doing differently this year:\nLess productivity, more meditation More travel, more thru hikes. Plenty of opportunities in the Netherlands and Germany as well Take a more playful approach to running and exercise, not too rigid More playful approach to life itself Allowing space in my planning, taking things as they come Not trying to figure absolutely everything out beforehand, taking things more as they come Spend more time on my volunteering work for NA Spend more time with family Links: 202309270609\n","permalink":"https://mischavandenburg.com/zet/back-from-vacation-2023/","summary":"I\u0026rsquo;ve been back for about two weeks now. I had the best holiday of my life. Three weeks of roaming in Norway, visiting friends and reconnecting with nature.\nI went hiking in Jotunheimen for a few days and walked Beseggen.\nBut the main event was a 8 day thru hike of Trollheimen. I hiked 20-25km a day from cabin to cabin for a total of 130km, and it has been the best experience of my life.","title":"Back From Vacation - 2023"},{"content":" We had trails and the fresh air and a little water and food and our fit bodies to move through and with the land. That was all we needed. Seeing Kyle and Tony so happy reminded me that that was all I ever needed, all any of us needed. How had I drifted away from those simple joys? I wanted to regain the purity and gratitude that Kyle and Tony seemed to hold so effortlessly, so lightly.\nI ran, and kept running, because I had learned that once you started something you didn’t quit, because in life, much like in an ultramarathon, you have to keep pressing forward. Eventually I ran because I turned into a runner, and my sport brought me physical pleasure and spirited me away from debt and disease, from the niggling worries of everyday existence. I ran because I grew to love other runners. I ran because I loved challenges and because there is no better feeling than arriving at the finish line or completing a difficult training run. And because, as an accomplished runner, I could tell others how rewarding it was to live healthily, to move my body every day, to get through difficulties, to eat with consciousness, that what mattered wasn’t how much money you made or where you lived, it was how you lived. I ran because overcoming the difficulties of an ultramarathon reminded me that I could overcome the difficulties of life, that overcoming difficulties was life. Could I quit and not be a quitter? “You’ve done it before,” Rick said. “You can do it again.” I appreciated the optimism. I also appreciated its idiocy.\nRarely do you come across a book that is grippingly entertainin, highly informative and potentially lifechanging at the same time.\nI picked it up because of my increased interest in running. I\u0026rsquo;ve also started to become a bit fascinated with marathon and ultra running, hoping to seek my own limits in these sports one day.\nThe Body Eat and Run tells the story of Scott Jurek, one of the most famous and succesful ultrarunners in history. It starts with his childhood and documents his process and explains why he started running, and how he eventually ended up eating a vegan diet.\nI\u0026rsquo;ve been plant based for 7 years already, but if I were in need of more convincing, this book would definitely convince me to become vegan. Instead of pages of quotations of studies, Scott provides his subjective account of becoming vegan and how it affected his performance:\nI learned that I could eat more, enjoy it more, and still get leaner than I had ever been in my life. When I went vegan, I started eating more whole grains and legumes, fruits and vegetables. My cheekbones seemed more pronounced, my face more chiseled. Muscles I didn’t even know I had popped out. I was eating more, losing weight, and gaining muscle—all on a vegan diet. My recovery times between workouts and races got even shorter. I wasn’t even sore the day after 50-mile races. I woke up with more energy every day. Fruit tasted sweeter, vegetables crunchier and more flavorful. I was doing short runs in the morning, working 8- to 10-hour days, then running 10 to 20 miles in the evening. I felt as if my concentration was improving every day.\nAnyone who pays attention to what they eat and how it affects them will naturally move toward plants—and toward health.\nThe Mind The other aspect of ultrarunning, which draws me the most, is the psychological side of it. It takes massive mental strength to power yourself through a 24 or 48 hour race of constant running without any sleep. How long can you fight the urge to give up?\nScott tells gripping stories of his races and how he had to work with his own psyche to get through the worst parts. I find the accounts fascinating where he describes being ready to give up, but somehow finding a new source of energy out of nothing and finishing the race in great shape.\nWhen I got to the 50-mile mark I couldn’t think that I had 100 miles to go. I had to remember and forget. We move forward, but we must stay in the present. I tried to do so by breaking races into small, digestible parts. Sometimes I focused on the next aid station, three miles ahead. Sometimes I pictured the next shady spot down the road, or the next step.\nThat’s one of the many great pleasures of an ultramarathon. You can hurt more than you ever thought possible, then continue until you discover that hurting isn’t that big a deal. Forget a second wind. In an ultra you can get a third, a fourth, a fifth even. I still had more than 40 miles to go, but that’s a second wonderful thing about 100- (and plus) milers. You can trail, and despair, and screw up, and despair more, and there’s almost always another chance. Salvation is always within reach. You can’t reach it by thinking or by figuring it out. Sometimes you just do things.\nEven if you are not into running or plant based nutrition, this book can be an interesting read. I think there is something fascinating about powering yourself through 100 miles, fighting the pain and suffering and finding energy from nowhere that anybody can appreciate.\nLinks: 202309270609\n","permalink":"https://mischavandenburg.com/zet/book-notes-eat-and-run/","summary":"We had trails and the fresh air and a little water and food and our fit bodies to move through and with the land. That was all we needed. Seeing Kyle and Tony so happy reminded me that that was all I ever needed, all any of us needed. How had I drifted away from those simple joys? I wanted to regain the purity and gratitude that Kyle and Tony seemed to hold so effortlessly, so lightly.","title":"Book Notes - Eat and Run by Scott Jurek"},{"content":"Past week we\u0026rsquo;ve been struggling a bit with poorly configured pod disruption budgets. When you do an AKS upgrade, a new node is created and one of the old nodes is drained.\nIf a deployment has a pod disruption budget which is incorrectly configured, it might show up as ALLOWED DISRUPTIONS: 0. When this happens, the node cannot be drained and you will get an error message in your events.\nk get poddisruptionbudgets.policy\nk get events\nThe error message will say something like \u0026ldquo;Too man eviction attempts, usually a pdb\u0026rdquo; (I lost the shell output so can\u0026rsquo;t copy atm).\nKubernetes is in a situation where it needs to schedule the pod on another node, but it is unable to do do so because we are telling Kubernetes that it is not allowed to have any disruptions on the deployment.\nKubernetes is logical, it\u0026rsquo;s doing like it\u0026rsquo;s told. But it\u0026rsquo;s frustrating because you can be sitting there waiting for 20 minutes wondering why your node isn\u0026rsquo;t draining.\nAt my current gig we are not responsible for the content on the clusters and we should not meddle with the application teams\u0026rsquo; namespaces.\nHowever, one solution is to either kill the pod manually or scale up the deployment to more replicas so there will be a higher amount of allowed disruptions.\nLinks: 202309271809\n[[kubernetes]]\n[[azure]]\n","permalink":"https://mischavandenburg.com/zet/pod-disruption-budget-aks/","summary":"Past week we\u0026rsquo;ve been struggling a bit with poorly configured pod disruption budgets. When you do an AKS upgrade, a new node is created and one of the old nodes is drained.\nIf a deployment has a pod disruption budget which is incorrectly configured, it might show up as ALLOWED DISRUPTIONS: 0. When this happens, the node cannot be drained and you will get an error message in your events.","title":"Pod Disruption Budgets Can Mess With Your AKS Updates"},{"content":"From here on out you can access Microsoft Learn during the exams. This is great news! This is much more like the actual experience of an engineer\u0026rsquo;s daily activities. It is arguably more important to look up things efficiently rather than memorizing everything for a test and forgetting it a few weeks later.\nLinks: 202308231608\nhttps://youtu.be/iPiq3YuhnHc\n","permalink":"https://mischavandenburg.com/zet/azure-exams-open-book/","summary":"From here on out you can access Microsoft Learn during the exams. This is great news! This is much more like the actual experience of an engineer\u0026rsquo;s daily activities. It is arguably more important to look up things efficiently rather than memorizing everything for a test and forgetting it a few weeks later.\nLinks: 202308231608\nhttps://youtu.be/iPiq3YuhnHc","title":"Azure Exams Are Open Book Exams From Now On"},{"content":"I\u0026rsquo;ve just finished my last workday and tomorrow I\u0026rsquo;m heading off to Norway! When I glance at the amount of posts I\u0026rsquo;ve made on my blog recently it\u0026rsquo;s obvious that it is time for a break from the entire routine. I\u0026rsquo;ve been tapering down to this moment for a while now, toning down the studying and prioritizing relaxation so I can enter the holidays with a clear mind.\nNow it\u0026rsquo;s time for lots of fresh air, mountains, many kilometres on the trails, and to pick up the connection to Nature I\u0026rsquo;ve made during the 9 years that I lived in the beautiful North.\nLinks: 202308231608\n","permalink":"https://mischavandenburg.com/zet/vacation-2023/","summary":"I\u0026rsquo;ve just finished my last workday and tomorrow I\u0026rsquo;m heading off to Norway! When I glance at the amount of posts I\u0026rsquo;ve made on my blog recently it\u0026rsquo;s obvious that it is time for a break from the entire routine. I\u0026rsquo;ve been tapering down to this moment for a while now, toning down the studying and prioritizing relaxation so I can enter the holidays with a clear mind.\nNow it\u0026rsquo;s time for lots of fresh air, mountains, many kilometres on the trails, and to pick up the connection to Nature I\u0026rsquo;ve made during the 9 years that I lived in the beautiful North.","title":"Vacation Time!"},{"content":"My Week The last full week until my holiday! All week I\u0026rsquo;ve been busy with preparations in the evenings.\nExercise \u0026amp; Weight Loss I\u0026rsquo;m transitioning my running into barefoot running. The Norway trip will be an upheaval of the routine anyway so it is a good moment to start. Been doing walks in minimal footwear for over a week now and on Sunday I did my first barefoot run/walk. Calves are on fire!\nI also ordered a 16kg kettlebell and set up a pull up bar to incorporate some more strength work into my exercise routine. Starting fully after the holiday.\nContent Consumption Reading Almost finished reading Born To Run and been dipping into The Longevity Diet a few times too\nWatching Mostly watching barefoot runnning related content. Also watching some content related to functional strenght training. Favourite channels are Strenght Side and the Bioneer.\nListening SECRETS From The Lost Tribe of Barefoot Runners: Christopher McDougall \u0026amp; Eric Orton\nhttps://www.youtube.com/watch?v=cCfs7rLZeSk\nLinks Next Week Goals \u0026amp; Intentions Thursday: HOLIDAY! Links: 202308210708\n","permalink":"https://mischavandenburg.com/zet/2023-week-33/","summary":"My Week The last full week until my holiday! All week I\u0026rsquo;ve been busy with preparations in the evenings.\nExercise \u0026amp; Weight Loss I\u0026rsquo;m transitioning my running into barefoot running. The Norway trip will be an upheaval of the routine anyway so it is a good moment to start. Been doing walks in minimal footwear for over a week now and on Sunday I did my first barefoot run/walk. Calves are on fire!","title":"2023 week 33"},{"content":"One week closer to my Norwegian Holiday Adventure and it\u0026rsquo;s noticable that it occupies my thoughts a lot, in a positive sense. I\u0026rsquo;ve felt very energetic all week, only sleeping 6 hours or less whereas I usually need 7-8 hours, but still feeling great. I\u0026rsquo;ve started to make big smoothies in the morning again with lots of raw veggies, leafy greens and fruits, and I think it is the right thing for my body right now. Running also went well, I ran 15km in 1 hour 40 minutes in the coastal woods. It started raining very heavily about halfway through the run and it was an amazing experience to feel the forest soak up the rain as I ran through.\nI\u0026rsquo;m making significant breakthroughs in my personal practice. I\u0026rsquo;m starting an approach of intuitive eating and listening to hunger signals which has been quite liberating and beneficial so far. I\u0026rsquo;m curious to see where this will take me.\nAnother very positive thing this week is that my meditation practice has increased significantly all by itself. It is related to the sleep as well. Either I meditate more because I sleep less, or I sleep less because I meditate. Meditation can be incredibly restorative and I\u0026rsquo;ve had periods in the past where I slept only 4,5 hours a day when the meditation was going well. This week i\u0026rsquo;ve been sitting 1-3 hours a day and it feels great. Waking up feeling you need to meditate is such a lovely experience.\nContent Consumption Reading Making progress in Born to Run. Haven\u0026rsquo;t read any sci-fi.\nAlso scanned through \u0026ldquo;The PlantPower Way\u0026rdquo; by Rich Roll and \u0026ldquo;The Longevity Diet\u0026rdquo; by Dr. Longo\nVery interesting material that I look forward to explore further in the coming weeks.\nWatching Watching a lot of barefoot running content. I had a stint of barefoot running several years ago but I miss it a lot and I want to get back into it.\nListening Listened to some very inspirational podcasts by Tony Riddle on the Rich Roll podcast\nhttps://www.richroll.com/podcast/tony-riddle-717/\nhttps://www.richroll.com/podcast/tony-riddle-463/\nThese came just at the right time. I think my Norwegian holiday will be the perfect time to start rewilding again. In Norway I was very much connected with Nature, always out and about and often walking barefoot in the forests.\nI lost touch with that side of my after I moved back to the Netherlands because I focused so hard on my IT career. Now that my career is on track, I want to move my life in a more natural direction again.\nLinks Next Week Goals \u0026amp; Intentions Finish all Norwegian holiday preparations Hang several times a day Squat several times a day (resting squat) Take mindful walks in minimalist footwear Keep meditation quantity up Run 5 times, 16km on Saturday Links: 202308130908\n","permalink":"https://mischavandenburg.com/zet/2023-week-32/","summary":"One week closer to my Norwegian Holiday Adventure and it\u0026rsquo;s noticable that it occupies my thoughts a lot, in a positive sense. I\u0026rsquo;ve felt very energetic all week, only sleeping 6 hours or less whereas I usually need 7-8 hours, but still feeling great. I\u0026rsquo;ve started to make big smoothies in the morning again with lots of raw veggies, leafy greens and fruits, and I think it is the right thing for my body right now.","title":"2023 week 32"},{"content":"My Week This week has been a lot calmer. Spending my evenings watching Norwegian nature programmes which inspire me for my upcoming holidays. Some good developments in my private life.\nI\u0026rsquo;m meditating more and doing more yoga as well.\nExercise \u0026amp; Weight Loss I\u0026rsquo;m not bringing my phone on my runs and it feels nice to have that period in the morning with a clean mind and not looking at any notifications.\nI ran 14 kilometres on Sunday, another record. And I felt like I could have kept going too.\nContent Consumption Reading Finished reading Eat and Run, started reading Born to Run.\nWatching Still enjoying Norwegian nature programmes.\nLinks Next Week Goals \u0026amp; Intentions 5 runs 100 minute long run Daily yoga and meditation Links: 202308081708\n","permalink":"https://mischavandenburg.com/zet/2023-week-31/","summary":"My Week This week has been a lot calmer. Spending my evenings watching Norwegian nature programmes which inspire me for my upcoming holidays. Some good developments in my private life.\nI\u0026rsquo;m meditating more and doing more yoga as well.\nExercise \u0026amp; Weight Loss I\u0026rsquo;m not bringing my phone on my runs and it feels nice to have that period in the morning with a clean mind and not looking at any notifications.","title":"2023 week 31"},{"content":" A super inspiring podcast with Mike Fremont who ran marathons well into his nineties on a plant-based diet and who raced the National Canoe Championships at age 99. He adopted a plant based diet after being diagnosed with colon cancer at age 69. Although the cancer had metastasized and spread to other parts of his body, he received an operation and the cancer was cured. He only became competitive in running when he was well into his eighties.\nI find his story hugely inspiring and motivating to keep focussing on my health, never make any compromises on my diet and to keep running.\nWhen asked about the most important things in life, he said that helping other people in any way you can is the only thing that brings real rewards and satisfaction. It\u0026rsquo;s not the money.\nLinks: 202308071908\nhttps://youtu.be/uPmA7Fral5s\n","permalink":"https://mischavandenburg.com/zet/podcast-interview-100-year-old-vegan-marathoner/","summary":"A super inspiring podcast with Mike Fremont who ran marathons well into his nineties on a plant-based diet and who raced the National Canoe Championships at age 99. He adopted a plant based diet after being diagnosed with colon cancer at age 69. Although the cancer had metastasized and spread to other parts of his body, he received an operation and the cancer was cured. He only became competitive in running when he was well into his eighties.","title":"Podcast Notes: An Interview With A Vegan 100 Year Old Who Ran Marathons In His Nineties"},{"content":"Every day I make a big smoothie of lots of leafy greens, fruits, vegetables, and other ingredients such as flax seeds, turmeric, cinnamon and ginger. I wondered how blending these ingredients affects the dietary fibre and did some research.\nBlending fruits and vegetables can affect their dietary fiber content, but not necessarily in a bad way. Dietary fiber is the part of plant foods that our bodies cannot digest. It helps us feel full, regulate our blood sugar, lower our cholesterol, and prevent constipation. There are two types of dietary fiber: soluble and insoluble. Soluble fiber dissolves in water and forms a gel-like substance in our intestines. It slows down digestion and absorption of glucose and cholesterol. Insoluble fiber does not dissolve in water and adds bulk to our stool. It speeds up the passage of food and waste through our digestive system.\nWhen you blend fruits and vegetables, you break down the cell walls of the plant cells, which contain insoluble fiber. This makes the fiber more accessible to our digestive enzymes and bacteria, which can ferment it and produce gas. It also reduces the volume and weight of the food, which may make you feel less full. However, blending does not destroy the fiber completely. It just changes its form and function. You still get the benefits of soluble fiber, which can lower your blood sugar and cholesterol levels. You also get more nutrients from the fruits and vegetables, as blending makes them easier to digest and absorb.\nThe bottom line is that blending fruits and vegetables does not destroy their fiber, but it does alter it. You may lose some of the benefits of insoluble fiber, such as feeling full and preventing constipation, but you may gain some of the benefits of soluble fiber, such as lowering your blood sugar and cholesterol levels. You also get more vitamins, minerals, antioxidants, and phytochemicals from the blended foods. The best way to get enough fiber is to eat a variety of fruits and vegetables, both whole and blended, as well as other sources of fiber such as whole grains, beans, nuts, and seeds.\nLinks: 202308061008\nDietary fiber: Essential for a healthy diet - Mayo Clinic. https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/fiber/art-20043983\nDoes Blending Destroy Fiber: 5 Blending Myths Busted. https://kitchenhabit.com/does-blending-destroy-fiber/\nDoes Blending Destroy Fiber? - Quick and Dirty Tips. https://www.quickanddirtytips.com/articles/does-blending-destroy-fiber/\nDoes Blending Destroy Fiber and Nutrients? Myth Busted! - World of Blenders. https://worldofblenders.com/does-blending-fruit-destroy-fiber-nutrients/\n","permalink":"https://mischavandenburg.com/zet/blending-vegetables/","summary":"Every day I make a big smoothie of lots of leafy greens, fruits, vegetables, and other ingredients such as flax seeds, turmeric, cinnamon and ginger. I wondered how blending these ingredients affects the dietary fibre and did some research.\nBlending fruits and vegetables can affect their dietary fiber content, but not necessarily in a bad way. Dietary fiber is the part of plant foods that our bodies cannot digest. It helps us feel full, regulate our blood sugar, lower our cholesterol, and prevent constipation.","title":"How Does Blending Fruits And Vegetables Affect Their Fibre Content?"},{"content":"During the Bicep Community Call of July 2023 I was introduced to the new experimental testing framework that the Bicep team is working on. After learning the fundamentals of the Go programming language I saw the value of test driven software development, and it will be an advantageous improvement if we can start applying this methodology to Infrastructure as Code as well.\nTest driven software development is a software development practice that involves writing unit tests before writing the actual code, and then refactoring the code to pass the tests. Some of the advantages of test driven software development are:\nIt improves the code quality and design by making it more modular, maintainable, and extensible. It reduces the number of bugs and defects by catching them early in the development process. It enhances the documentation of the code by providing a clear specification of what each function or module does. It increases the productivity and efficiency of the developers by providing immediate feedback and reducing debugging time. It ensures high test coverage and makes it easier to add new features or refactor the code in the future. Enabling the Bicep testing framework To make the \u0026ldquo;test\u0026rdquo; keyword available in your Bicep editor, you need to enable some experimental features.\nIf you\u0026rsquo;re using VScode, open or generate your bicepconfig.json file and add the following code:\n{ \u0026#34;experimentalFeaturesEnabled\u0026#34;: { \u0026#34;testFramework\u0026#34;: true, \u0026#34;asserts\u0026#34;: true } } Now the \u0026ldquo;test\u0026rdquo; keyword should work.\nFor more information, check out this link:\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-config\nAsserts The assert keyword will be used to verify output prior to deployment.\nLet\u0026rsquo;s say I have this very simple key vault template:\nparam location string = resourceGroup().location resource kv \u0026#39;Microsoft.KeyVault/vaults@2023-02-01\u0026#39; = { name: \u0026#39;mischa-key-vault-138\u0026#39; location: location properties: { sku: { name: \u0026#39;standard\u0026#39; family: \u0026#39;A\u0026#39; } tenantId: subscription().tenantId enableRbacAuthorization: true } } assert kvSKU = kv.sku.name == \u0026#39;standard\u0026#39; In this example, the assertion would run before the actual deployment happens, and if the assertion fails, the deployment is stopped. This is of course a rather silly example, but you hopefully get the idea.\nWhy is this useful? When you are running larger deployments from files that contain a lot of resources, sometimes the deployment will fail halfway through the template because there was some unexpected error, and a lot of time is wasted waiting for the preceding resources to be deployed. In the future we can hopefully use assertions to make sure the output will be as expected at compile time.\nUnit Tests in Bicep Unit tests are a type of software testing where individual units or components of a software are tested to verify that they work as expected. A unit can be a function, a method, a module, or an object. In the Bicep testing framework, we can run unit tests on resources as well. Unit tests are usually written and run by the developers during the coding phase of the software development process. Unit tests help to improve the quality, design, and documentation of the code, as well as to catch bugs and defects early.\nNow I\u0026rsquo;ll provide an example of a unit test in Bicep. Let\u0026rsquo;s say we have this Bicep template for an AKS cluster:\n@description(\u0026#39;Name of the AKS cluster\u0026#39;) param clusterName string @description(\u0026#39;Prefix for deployment\u0026#39;) param prefix string resource aksCluster \u0026#39;Microsoft.ContainerService/managedClusters@2023-03-02-preview\u0026#39; = { name: \u0026#39;${prefix}-${clusterName}\u0026#39; location: location ... To use a simple example, let\u0026rsquo;s say I want to make sure that my cluster name will be as expected. I would write a unit test as follows:\ntest testAKS \u0026#39;aks.bicep\u0026#39; = { params: { clusterName: \u0026#39;coffee\u0026#39; prefix: \u0026#39;prod\u0026#39; } } assert assertClusterName = testAKS.resources.aksCluster.name == \u0026#39;prod-coffee\u0026#39; When I run this test.bicep file, it will take the aks.bicep file and feed the \u0026lsquo;coffee\u0026rsquo; and \u0026lsquo;prod\u0026rsquo; parameters to it. My aks.bicep file will create the string from the parameters and output the name. Then, I use the \u0026ldquo;assert\u0026rdquo; keyword to verify that the string is composed according to my expectations.\nNote: at the time of writing 2023-08-03, the \u0026ldquo;assert\u0026rdquo; keyword was still not available in Bicep 0.20.4, but there might be a problem with my local configuration which I\u0026rsquo;ve asked the team about.\n2023-08-08 update: I\u0026rsquo;ve been in touch with the Bicep team and they responded as follows:\n?Regarding your ability to access \u0026ldquo;test\u0026rdquo; but not \u0026ldquo;assert\u0026rdquo;, both key words are still only in a demo phase and not yet intended for customer use. Please hold off on trying them out for now. We will be in touch with folks who have indicated interest through the form and/or on a Community Call when there is a preview available. Thank you for your patience and sorry for any confusion.\nI guess I was a little eager with testing the keywords so soon! 😀 🚀\nConclusion I believe it will be a great development to apply test driven software development to Infrastructure as Code by implementing a test framework into Bicep. When I\u0026rsquo;m able to use this approach, I would begin with writing all of the tests for the template that I have in mind, and then I can continue to write the Bicep template itself. By using the tests I can become much more productive because I can speed up my development by using tests without having to do what-if deployments which can be rather slow and involve a lot of waiting.\nIt is great to see how the Bicep language is maturing and how it continues to introduce new features that make the lives of developers easier. I was really stoked about the new .bicepparam files, but I\u0026rsquo;m even more excited by the new testing framework.\nHowever, please note that this is still an experimental feature. I haven\u0026rsquo;t found much other information, and I\u0026rsquo;m not part of the Bicep development community (yet). There might be a chance that this feature isn\u0026rsquo;t implemented at all in the end. That being said, I would love to participate in this community and perhaps I\u0026rsquo;d be able to provide some costumer feedback, and I\u0026rsquo;m currently looking into this and I\u0026rsquo;ve reached out to a few acquaintances.\nLinks: 202308030808\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-config\nhttps://youtu.be/UuwhLi-Xe2U\n","permalink":"https://mischavandenburg.com/zet/bicep-testing-assertions/","summary":"During the Bicep Community Call of July 2023 I was introduced to the new experimental testing framework that the Bicep team is working on. After learning the fundamentals of the Go programming language I saw the value of test driven software development, and it will be an advantageous improvement if we can start applying this methodology to Infrastructure as Code as well.\nTest driven software development is a software development practice that involves writing unit tests before writing the actual code, and then refactoring the code to pass the tests.","title":"Test Driven Development for Bicep is In The Works!"},{"content":"It\u0026rsquo;s been a calmer week. Work has been busy, but I\u0026rsquo;m taking my time to relax in the evenings. I notice it is time to take a break from work. My holidays are aproaching: in three weeks I\u0026rsquo;ll have three weeks off. So I\u0026rsquo;m intentionally winding down the productivity.\nI hardly ever watch series. I don\u0026rsquo;t have a TV. But to get into the mood for my Norway trip, I\u0026rsquo;m watching some shows I used to watch when I lived in Norway. It is very relaxing to just do nothing in the evenings afer work, instead of studying or creating content.\nExercise \u0026amp; Weight Loss I set a 5k PR this week, and on Saturday I had a great long run. I drove to the coastal area and ran 13km in 82 minutes, 1km farther than last week. Amazing to think that I\u0026rsquo;ve built up the endurance to run almost one and a half hour straight!\nContent Consumption Reading Making progress in Eat and Run, haven\u0026rsquo;t read Gridlinked this week.\nWatching Watching the Norwegian shows \u0026ldquo;Der Ingen Skulle Tru at Nokon Kunne Bu\u0026rdquo; and \u0026ldquo;Med Monsen Pa Villspor\u0026rdquo;.\nVery nostalgic to see this content again and it is really getting me excited for my upcoming Norway trip.\nListening https://lexfridman.com/yuval-noah-harari/\nLinks Next Week Goals \u0026amp; Intentions Don\u0026rsquo;t look at phone until morning run is finished 5 runs 90 minute long run Daily yoga and meditation Links: 202307301607\n","permalink":"https://mischavandenburg.com/zet/2023-week-30/","summary":"It\u0026rsquo;s been a calmer week. Work has been busy, but I\u0026rsquo;m taking my time to relax in the evenings. I notice it is time to take a break from work. My holidays are aproaching: in three weeks I\u0026rsquo;ll have three weeks off. So I\u0026rsquo;m intentionally winding down the productivity.\nI hardly ever watch series. I don\u0026rsquo;t have a TV. But to get into the mood for my Norway trip, I\u0026rsquo;m watching some shows I used to watch when I lived in Norway.","title":"2023 week 30"},{"content":" In this video, I will walk you through the following steps:\nSet up a repo in Azure DevOps with MkDocs files Set up a Static Web App in Azure portal and link it to the repo Configure the Azure DevOps pipeline for MkDocs deployment Configure a custom theme for the website Demonstrate the pull request workflow for updating the docs By the end of this video, you will have a fully functional MkDocs site hosted on Azure Static Web Apps. You will also learn how to use Azure DevOps and Static Web Apps to collaborate on your documentation projects.\nMkDocs is a tool that lets you create beautiful documentation websites from plain text files. You can write your docs in Markdown, a simple and easy-to-use markup language, and MkDocs will convert them into a static HTML site. You can also customize the look and feel of your site with themes and plugins.\nAzure Static Web Apps is a service that hosts static web content and serverless APIs. It automatically builds and deploys your web app from a GitHub or Azure DevOps repository. It also provides features such as authentication, authorization, custom domains, and SSL certificates.\nTimestamps:\n0:00 Intro 0:40 What is MkDocs? 2:00 Set up the repo 5:00 Create web app 9:25 Configure the pipeline 11:30 Adding a few documents 15:25 Adding a custom theme 18:00 Adding docs with a pull request 21:30 Outro\nLinks: 202307281307\n","permalink":"https://mischavandenburg.com/zet/video-mkdocs-azure-webapp/","summary":"In this video, I will walk you through the following steps:\nSet up a repo in Azure DevOps with MkDocs files Set up a Static Web App in Azure portal and link it to the repo Configure the Azure DevOps pipeline for MkDocs deployment Configure a custom theme for the website Demonstrate the pull request workflow for updating the docs By the end of this video, you will have a fully functional MkDocs site hosted on Azure Static Web Apps.","title":"Video: Deploying MkDocs To Azure Using With Azure DevOps"},{"content":"My Week It\u0026rsquo;s been a nice week. Work has been very busy again, there are no signs of things slowing down because of the summer holidays. I deployed an AKS cluster in the North Europe region for the first time for my team, which needed additional networking configuration and I\u0026rsquo;ve had to set up all the firewall rules for AKS deployments which was a task that I learned a lot from.\nOn Thursday I went to the office where I met Bjorn from Delegate to learn more about what they are doing in the Netherlands. There might be opportunities to work on international projects through Delegate which is an interesting prospect.\nExercise \u0026amp; Weight Loss I\u0026rsquo;ve done well on the running front. Ran 12K for the first time yesterday! [[running-record-12km]] A couple of weeks ago I wrote that I needed to bring more joy and motivation into the running again, and it is happening. After building my base back up with an emphasis on SPM, increasing it from 150 to 171SPM average, I\u0026rsquo;m now reaching my distance limits and therefore able to make more progress again by increasing the weekly distance slightly every week. This sense of progression is addictive and makes me very motivated to keep on training like I\u0026rsquo;m doing now.\nIn terms of weight loss, I seem to have ended up on a maintenance plateau. I\u0026rsquo;m hovering around 77kg and perhaps I\u0026rsquo;ll stay here for now. I\u0026rsquo;m focussing more on proper recovery for my running, and perhaps I should not force a caloric deficit right now. Also, I have my holidays coming up in a month, and it seems a bit of wasted effort to enter another weight loss sprint while I know that I\u0026rsquo;ll probably start a new one after I return from my holidays.\nContent Consumption Reading I\u0026rsquo;m making steady progress on Gridlinked and enjoying the book a lot.\nWhen I don\u0026rsquo;t feel like reading fiction I\u0026rsquo;m still reading Eat and Run by Scott Jurek.\nWatching I\u0026rsquo;ve watched a lot more youtube content this week, especially in the weekend.\nA very inspiring interview with Eliud Kipchoge, the fastest marathon runner in the world. My notes are here.\nWatched Satcha Nadella\u0026rsquo;s full keynote from Microsoft inspire. Very interesting to observe that the entire keynote revolves around AI.\nhttps://youtu.be/RhwVMt_XCUE\nPERFECT RUNNING FORM - Why Do PRO Runners Kick Their Feet So High?\nhttps://www.youtube.com/watch?v=sIxAoC8P8zg\nEssential Running Technique Tips for Proper Form \u0026amp; How to Run Faster! | Sage Running\nhttps://www.youtube.com/watch?v=3RlvKMxPMr0\nRunning form when running slow Good vs Bad Running Form @ 10:00/mile (6:13/km)\nhttps://youtu.be/ZxbZIvSWOZs\nPerfect running form demonstration first few minutes\nhttps://www.youtube.com/watch?v=ZCARH83vZpw\nListening Ive listened to a bunch of podcasts.\nLex Fridman with Mark Andreessen on the future of AI. here are my notes\nGeorge Hotz: Tiny Corp, Twitter, AI Safety https://podcasts.apple.com/nl/podcast/lex-fridman-podcast/id1434243584?i=1000618818540\nSam Altman: OpenAI CEO on GPT4- ChatGPT https://podcasts.apple.com/nl/podcast/lex-fridman-podcast/id1434243584?i=1000605876923\nMax Tegmark: The Case for Halting AI Development https://podcasts.apple.com/nl/podcast/lex-fridman-podcast/id1434243584?i=1000608828204\nLinks Next Week I have an office day on Tuesday and production maintenance windows on Wednesday and Thursday evening. Otherwise it seems like a fairly standard week and not very socially demanding.\nI\u0026rsquo;m going to try something I picked up from the interview with Kipchoge: not looking at the phone or news until the morning run is finished. Wake up, have my run, and then connect with the world.\nGoals \u0026amp; Intentions Don\u0026rsquo;t look at phone until morning run is finished 5 runs 75 minute long run 1 blog post, 1 video Daily yoga and meditation Links: 202307240807\n","permalink":"https://mischavandenburg.com/zet/2023-week-29/","summary":"My Week It\u0026rsquo;s been a nice week. Work has been very busy again, there are no signs of things slowing down because of the summer holidays. I deployed an AKS cluster in the North Europe region for the first time for my team, which needed additional networking configuration and I\u0026rsquo;ve had to set up all the firewall rules for AKS deployments which was a task that I learned a lot from.","title":"2023 week 29"},{"content":"Rich Roll has been a familiar face to me for many years. I first came across him about 7 years ago when I made my first explorations into plant based nutrition. I believe the documentary \u0026ldquo;Forks over Knives\u0026rdquo; was the first time I saw him. I recently read \u0026ldquo;Finding Ultra\u0026rdquo; by Rich Roll, which documents the journey from being an overweight and unhappy lawyer to becoming one of the world\u0026rsquo;s fittest men and a vegan ultra-endurance athlete. I\u0026rsquo;ve always appreciated his podcasts and his way of presenting himself, so it was great to learn about his journey.\nIn this book, Rich shares his story of how he overcame alcoholism, depression, and poor health by adopting a plant-based diet and a rigorous training regimen. He also describes his amazing feats of endurance, such as completing five Ironman-distance triathlons on five Hawaiian islands in under a week.\nAs someone who is already eating a plant-based diet, I still found this book very inspiring. It affirmed to me that you can be a high-performance athlete as a vegan. I have started running early this year and I have made a lot of progress. I recently ran 12 kilometres for the first time. This book has inspired me to clean up my diet even more and train harder and to search out my limits.\nHere are some of the quotes from the book that I highlighted, which resonated with me:\n\u0026ldquo;The solution is spiritual.\u0026rdquo;\n\u0026ldquo;Safety isn’t just an illusion, it’s a cop-out.\u0026rdquo;\n\u0026ldquo;When you believe you’ve reached your absolute limit, you’ve only tapped into about 40 percent of what you’re truly capable of.\u0026rdquo;\n\u0026ldquo;Bliss in depletion. I finally got it. It’s that beautiful place of ascetic purity that is permitted to bloom only when the mind is stopped dead in its tracks and everything else is stripped away, leaving your soul—or who you really are—to forge a connection with the truth.\u0026rdquo;\n\u0026ldquo;It’s not an exaggeration to say that my EPIC5 experience had been fueled in large part by avocados, grapeseed oil–based Vegenaise, and coconut water.\u0026rdquo;\nSome of the key takeaways that I learned from this book are:\nChange is possible at any age, but it requires commitment, discipline, and faith. Plant-based nutrition can enhance health, performance, and recovery. Endurance sports are not only physical, but also mental and spiritual challenges. Finding your purpose and passion can give you the motivation and courage to overcome any obstacle. Living authentically and gratefully is the ultimate reward. I highly recommend this book to anyone who is interested in personal growth, veganism, or endurance sports. It is a captivating and uplifting story that will make you rethink what you are capable of.\nLinks: 202307240707\n","permalink":"https://mischavandenburg.com/zet/book-notes-finding-ultra-rich-roll/","summary":"Rich Roll has been a familiar face to me for many years. I first came across him about 7 years ago when I made my first explorations into plant based nutrition. I believe the documentary \u0026ldquo;Forks over Knives\u0026rdquo; was the first time I saw him. I recently read \u0026ldquo;Finding Ultra\u0026rdquo; by Rich Roll, which documents the journey from being an overweight and unhappy lawyer to becoming one of the world\u0026rsquo;s fittest men and a vegan ultra-endurance athlete.","title":"Book Notes: Finding Ultra By Rich Roll"},{"content":"Kipchoge is a Kenyan long-distance runner who competes in the marathon and is regarded as the greatest marathon runner of all time. He follows a simple diet that consists mainly of rice, potatoes, porridge, beans, and ugali, a dense maize-flour porridge. He also eats homemade bread, local fruits and vegetables, some meat, and Kenyan tea with extra sugar. He drinks a lot of water (three litres) each day and avoids indulgent foods like steak, poultry, sausages, or French fries. He sometimes takes mursik, a fermented milk, to aid digestion. Before his historic sub-two-hour marathon run in 2019, he had oatmeal for breakfast.\nHis diet is mostly plant-based and high in carbohydrates and low in fat. He eats at specific times during the day and sources most of his food locally from the Eldoret region, where he trains. He likes to have ugali with lean beef and some managu, an indigenous spinach-like vegetable, or with beans and potatoes. He also likes rice and red beans, or chapati, an unleavened flatbread. When he is travelling, he prefers pasta as his carbohydrate source.\nHe works closely with his longtime coach, Patrick Sang, who understands the importance of nutrition in achieving peak performance. His nutritionist Armand Bettonviel explained the importance of carbo-loading and why marathon runners need to avoid whole grain products. Kipchoge’s diet played a critical role in his record-breaking marathon runs, including his sub-two-hour marathon in Vienna in 2019, sponsored by INEOS, and his gold medal-winning performance at the 2016 Rio Olympics.\nAccording to one source, Kipchoge eats around 2,300 calories on a non-race day. This is far fewer than one might think for a marathon runner who trains at high intensity and volume. However, he also consumes over 100 grams of carbohydrates per hour during his race, which is a very high amount. He uses a combination of drink mixes and gels that contain easily digestible carbohydrates and hydrogel technology. This helps him maximize his energy production and performance.\nIt\u0026rsquo;s interesting to see that he eats a mainly plant based diet but still includes beef. I\u0026rsquo;m also surprised by the high amount of carbohydrates. I\u0026rsquo;m currently experimenting with a lower carb diet so that my body will tend to run more on fat while I\u0026rsquo;m running, but I\u0026rsquo;m intruiged by the fact that the world\u0026rsquo;s fastest marathon runner is basically fueled on carbohydrates. It\u0026rsquo;s even more surprising that he only eats around 2300 calories a day.\nLinks: 202307221607\nEliud Kipchoge\nWhat Eliud Kipchoge diet plan looks like - SportsLeo\nA champion\u0026rsquo;s diet: What marathon legend Eliud Kipchoge eats - Olympics.com\nEliud Kipchoge’s Diet: An ‘Eat Like a Champion’ Guide!\nKipchoge\u0026rsquo;s Berlin nutrition plan - Canadian Running Magazine\n","permalink":"https://mischavandenburg.com/zet/kipchoge-marathon-diet/","summary":"Kipchoge is a Kenyan long-distance runner who competes in the marathon and is regarded as the greatest marathon runner of all time. He follows a simple diet that consists mainly of rice, potatoes, porridge, beans, and ugali, a dense maize-flour porridge. He also eats homemade bread, local fruits and vegetables, some meat, and Kenyan tea with extra sugar. He drinks a lot of water (three litres) each day and avoids indulgent foods like steak, poultry, sausages, or French fries.","title":"Kipchoge's Diet And Calories: What Does The Fastest Marathon Runner In The World Eat?"},{"content":"New week, new record! For the first time in my life I ran 12 kilometers, and immediately another 10k PR!\nThis morning it was time for my long run, and while I was drinking my coffee I decided to watch a running technique video again to see what I could improve. Lately I have mainly focused on my heart rate and steps per minute, but today I focused more on maintaining a better posture by sticking out my chest a bit more and leaning forward a bit more. The result was that I suddenly ran much faster and more relaxed without this resulting in a higher HR, and my steps per minute were also fine afterwards with 171SPM. These days I usually run around 6:30 but I’m really surprised that I was able to set both a distance record and a higher average speed without having to make any effort except constantly maintaining a better posture. “Running Tall” was the mantra that I kept coming back to when I noticed that I started to sink back.\nLinks: 202307221107\n","permalink":"https://mischavandenburg.com/zet/running-record-12km/","summary":"New week, new record! For the first time in my life I ran 12 kilometers, and immediately another 10k PR!\nThis morning it was time for my long run, and while I was drinking my coffee I decided to watch a running technique video again to see what I could improve. Lately I have mainly focused on my heart rate and steps per minute, but today I focused more on maintaining a better posture by sticking out my chest a bit more and leaning forward a bit more.","title":"New Running Record! Ran 12km today"},{"content":"What I Learned from Kipchoge, the Fastest Marathon Runner in the World Kipchoge is not only a world-class athlete, but also a source of inspiration and wisdom for anyone who wants to improve their life. I recently listened to an interview with him on YouTube, and I was amazed by his insights on running, success, pain, discipline and happiness. Here are some of the key takeaways and a summary of what he shared.\nPreparation and Planning is the Key Kipchoge believes that success does not come by chance, but by pure and clean planning in preparation. He follows a strict program and sticks to it to the letter. He writes down everything in his journal every day, and documents his progress and challenges. He also avoids distractions and focuses on his priorities.\nI really appreciate his emphasis on planning everything out meticulously. You should approach your training with a clear goal and intention and make a plan to reach that goal. I also identify with his habit of writing everything down, of course. This is what I\u0026rsquo;ve been practicing myself for several years now, and it is nice to see yet another highly successful person who also shares this habit.\nMorning Routine Kipchoge has a morning routine which is very similar to my own. He wakes up at 5:45 and is out running by 6:10. When he comes back he has a shower and has breakfast. Only when that is finished will he look at his phone and check his messages and emails.\nI also run first thing in the morning. I really enjoy to have it done for the day, and I prefer to exercise on an empty stomach. I think I will try Kipchoge\u0026rsquo;s routine of not looking at the phone until the morning rituals are finished. I tend to check the news and read messages before I go out on my run, and then I use the run to prepare for the day. I\u0026rsquo;ll try to get out with a \u0026ldquo;clean mind\u0026rdquo; and see what happens this week.\nMovement Leads to a Long and Happy Life Kipchoge sees running as the best movement and the key to life. He says that life is about movement, and if you move, that\u0026rsquo;s how you have a good life. He runs every day, even when he does not feel like it, because he knows that running is not only good for his body, but also for his mind. He runs in a group of people, and enjoys the social aspect of running. He says that running in a group helps him to talk, exchange ideas and learn from others. He also encourages running as a family lifestyle, and says that running should be fun and enjoyable.\nPain is Part of Success Kipchoge smiles when he runs, even when he is feeling pain. He says that when he smiles while running, he is actually enjoying the pain. He explains that pain is where success is, and those who know how to handle pain will be successful and move up to another level. Kipchoge also says that training is not the same as competing, and that training happens at a slower pace where you can follow the pace of the group. But when he competes, he pushes himself to the limit and embraces the pain.\nVitamin N Kipchoge shares a simple but powerful advice: inject yourself with vitamin N. What is vitamin N? It stands for NO! Kipchoge says that you need to learn to say no to things that are not aligned with your goals and values. You also need to set your priorities right and avoid complaining. These three things will help you develop self-discipline and achieve your dreams.\nListening to Podcasts When I started running I listened to music, but after I could run for more than 20 minutes, I started to see my runs as a form of active meditation. I deliberately avoid listening to music and podcasts so I can focus completely on the running experience and use the breath, body and movement as meditation objects. However, Kipchoge says that it is all right to listen to music or podcasts during easy runs. They will make the time pass by very quickly.\nI hope you enjoyed this blog post and learned something from Kipchoge\u0026rsquo;s wisdom. If you want to listen to the full interview, you can find it here:\nLinks:\n202307221407\nhttps://www.youtube.com/watch?v=X4la2sHwZB0\nLinks: 202307221907\n","permalink":"https://mischavandenburg.com/zet/podcast-kipchoge-marathon-running/","summary":"What I Learned from Kipchoge, the Fastest Marathon Runner in the World Kipchoge is not only a world-class athlete, but also a source of inspiration and wisdom for anyone who wants to improve their life. I recently listened to an interview with him on YouTube, and I was amazed by his insights on running, success, pain, discipline and happiness. Here are some of the key takeaways and a summary of what he shared.","title":"Podcast Notes: Interview With Eliud Kipchoge, The Fastest Marathon Runner In The World"},{"content":"The Fastest Runners in the World Today I set another record for myself, I ran 12kilometers in 70 minutes. Usually I run at a 6:30 / km pace, but today somehow I managed to run at 5:53. This had me wondering, what is the pace of the professionals? Who are the fastest runners in the world? How fast can they run different distances, such as 10km, 5km, or marathon? And how do their speeds compare to the average runner?\nIn this blog post, I will look at the current world records for these three distances. I will also convert them to minutes per km speed, which is a common way to measure running pace.\n10km The current world records for the 10km are:\nMen: 26:24 minutes, set by Rhonex Kipruto of Kenya in 2020. This means he ran at an average pace of 2.64 minutes per km, or 15.3 km/h. Women: 29:43 minutes, set by Joyciline Jepkosgei of Kenya in 2017. This means she ran at an average pace of 2.98 minutes per km, or 13.6 km/h. These records are incredible when you consider that the average 10km time for men of all ages is 56:35 minutes, and for women of all ages is 1:04:49 minutes, according to a study by RunRepeat. That means the record holders are more than twice as fast as the average runner!\n5km The current world records for the 5km are:\nMen: 12:49 minutes, set by Berihu Aregawi of Ethiopia in 2021. This means he ran at an average pace of 2.56 minutes per km, or 15.8 km/h. Women: 14:19 minutes, set by Ejgayehu Taye of Ethiopia in 2021. This means she ran at an average pace of 2.86 minutes per km, or 14.2 km/h. These records are also impressive when you compare them to the average 5km time for men of all ages, which is 28:46 minutes, and for women of all ages, which is 34:32 minutes, according to another study by RunRepeat. That means the record holders are almost twice as fast as the average runner!\nMarathon The marathon is the ultimate road race distance that requires stamina, strength, and mental toughness. The current world records for the marathon are:\nMen: 2:01:09 hours, set by Eliud Kipchoge of Kenya in 2022. This means he ran at an average pace of 2.87 minutes per km, or 14 km/h. Women: 2:14:04 hours, set by Brigid Kosgei of Kenya in 2019. This means she ran at an average pace of 3.18 minutes per km, or 12.7 km/h. These records are astounding when you think that the average marathon time for men of all ages is 4:32:49 hours, and for women of all ages is 5:09:45 hours, according to yet another study by RunRepeat. That means the record holders are more than twice as fast as the average runner!\nConclusion As you can see, the fastest runners in the world are truly remarkable athletes who can run at speeds that most of us can only dream of. They have trained hard and dedicated themselves to their sport, and have achieved amazing feats of human performance.\nIf you want to learn more about these runners and their records, you can check out these links:\n10K run - Wikipedia 5K run - Wikipedia Marathon world record progression - Wikipedia World Athletics Happy running! 😊\n202307221107\n[[running]]\n","permalink":"https://mischavandenburg.com/zet/running-fastest-current-records/","summary":"The Fastest Runners in the World Today I set another record for myself, I ran 12kilometers in 70 minutes. Usually I run at a 6:30 / km pace, but today somehow I managed to run at 5:53. This had me wondering, what is the pace of the professionals? Who are the fastest runners in the world? How fast can they run different distances, such as 10km, 5km, or marathon? And how do their speeds compare to the average runner?","title":"The Fastest Runners in the World: An Overview of the Current World Records"},{"content":"In this post, I want to share some of the highlights and insights from a recent podcast episode that I listened to. It was Lex Fridman Podcast #234, where Lex interviewed Marc Andreessen, the co-creator of Mosaic, the first widely used web browser, the co-founder of Netscape, and the co-founder of the legendary Silicon Valley venture capital firm Andreessen Horowitz. Marc is one of the most outspoken and visionary voices on the future of technology, and he recently wrote an article titled \u0026ldquo;Why AI Will Save the World\u0026rdquo; which I highly recommend.\nThe Internet as a Medium One of the themes that Marc and Lex discussed was how the Internet is not just a network of computers, but a medium of communication and expression that incorporates and transcends all previous forms of media. Marc quoted Marshall McLuhan, who said that \u0026ldquo;the content of each new medium is the old medium\u0026rdquo;. For example, the content of movies was theater, the content of theater was written stories, and the content of written stories was spoken stories. Similarly, the content of the Internet is television, radio, books, essays, and every other form of prior media.\nInterestingly, these patterns seem to have a tendency to return to text. Marc argued that this means that the Internet is not a static or fixed thing, but a dynamic and evolving one. He said that every new technology that comes along changes the nature of the Internet and opens up new possibilities for creativity and innovation. He gave examples such as search engines, social media, video streaming, podcasts, blogs, e-commerce, online education, online gaming, cryptocurrencies, NFTs, VR/AR/MR, and AI. He said that each of these technologies creates new ways for people to interact with information, with each other, and with themselves.\nAI as a Search Process One of the first topics they talked about was how search engines like Google have dominated the way we interact with the Internet for the past 20 years, but how that might change in the next 5 or 10 years with the rise of AI assistants that can communicate with us in natural language and provide us with answers, not just links. Andreessen argued that search was always a hack, a temporary solution that was optimal for accessing the world\u0026rsquo;s information on the web, but not necessarily the best way to interact with knowledge. He said that Google has been trying to move away from \u0026ldquo;the 10 blue links model for a long time\u0026rdquo;, and that AI assistants will be able to do that better by leveraging information from multiple sources and generating content on demand.\nFridman asked whether this would change the motivation and the format of creating content on the Internet, since search engines have driven how we optimize and structure web pages. Andreessen said that there might be less incentive to make web pages, but also more opportunity to create different kinds of content, such as conversations with AIs. He also pointed out that web pages are still a valuable source of training data for AIs, and that AIs might be able to generate synthetic training data as well. He called this a trillion dollar question: whether synthetic data can add signal or not to train better AIs.\nMarc explained that AI is fundamentally about searching for patterns in data. This is what neural networks do when they learn from data. They search for patterns that allow them to make predictions about future data. Similarly, this is what humans do when they learn from experience. They search for patterns that allow them to make decisions about future actions. He said that this is also what evolution does when it selects for traits. It searches for patterns that allow organisms to survive and reproduce in changing environments.\nI found this discussion very intriguing, because it made me think about how much search engines have shaped our online behavior and expectations, and how much that might change in the near future. I wonder how AI assistants will affect our ability to discover new information, to verify facts, to learn new skills, and to express ourselves online. Will we still have web pages as we know them? Will we still have blogs like this one? Will we still have podcasts like Fridman\u0026rsquo;s? Or will we have something entirely different?\nCreativity and Hallucination in AI Another topic they discussed was how AIs can be creative or hallucinate, depending on how we view their output. Andreessen said that we call it hallucination when we don\u0026rsquo;t like what the AI creates, or when it generates something that isn\u0026rsquo;t based on reality. When we do like it, we call it creativity.\nFridman asked how we can know what is true or not when we interact with an AI, especially when it comes to contentious or complex topics. Andreessen said that this is a very difficult problem, and that there is no easy way to determine what is truth or who gets to decide what is truth. He said that we need a lot of humility and skepticism when we encounter claims of truth from any source, human or machine. He also said that we need to embrace the techniques of the Enlightenment, such as the scientific method, rationality, observation, experimentation, hypothesis testing, etc., even when they give us answers we don\u0026rsquo;t like.\nHe also gave some examples of how AIs can be used for different purposes depending on how we steer them or constrain them. He said that he likes to use AIs for learning about contentious issues by asking them to debate different sides of an argument in good faith or bad faith. He said that he can also ask AIs to strip out the bias from news articles or other sources of information. AIs can be used for legal arguments as well, either in creative mode or in literal mode. He describes experiments he does himself where he gives very specific prompts to two AI models, such as \u0026ldquo;you are a right wing politician defending point X\u0026rdquo; and instructing the other model to be left wing, and then giving instructions such as \u0026ldquo;the discussion should start friendly but end up very heated and none of the AIs should change their mind\u0026rdquo;. I\u0026rsquo;m very fascinated by this type of experiment and I\u0026rsquo;m looking into setting this up for myself because I\u0026rsquo;m very curious about the results.\nThe ethical and social implications of AI development and deployment Another topic they talked about was how AI development and deployment will affect society and humanity in the near and long term. Andreessen said that he is optimistic about the positive impact of AI on various domains, such as health, education, entertainment, productivity, etc. He said that AI will save the world by solving many of the problems that we face today, such as climate change, poverty, disease, etc. He also said that AI will create new opportunities and possibilities for human creativity and expression.\nAndreessen and Fridman also discussed that the people who are creating AI are not necessarily the best people to make judgements about the deployment of these AIs to the society at large. He draws the analogy with nuclear scientists. These people spend their entire lives in laboratories and they specialize on the technical application. The are not sociologists, and they are perhaps less connected to the society at large and with geo-political landscape. Yet, when nuclear bombs were developed, the were the ones who had a huge say in whether or not it was moral to actually use these weapons.\nThe competence, capability, intelligence, training, accomplishments of senior scientists and technologists working on a technology, and then being able to then make moral judgments in the use of the technology, that track record is terrible. That track record is catastrophically bad.\nTherefore, it should not be the scientists who decide whether or not we start utilizing AI for automated airstrikes, it should be the politicians, philosophers, sociologists and policy makers of the world who are more connected with the morality and socio-political implications of these decisions.\nLinks: 202307180607\nhttps://lexfridman.com/marc-andreessen/\n","permalink":"https://mischavandenburg.com/zet/podcast-fridman-andreessen-future-of-ai/","summary":"In this post, I want to share some of the highlights and insights from a recent podcast episode that I listened to. It was Lex Fridman Podcast #234, where Lex interviewed Marc Andreessen, the co-creator of Mosaic, the first widely used web browser, the co-founder of Netscape, and the co-founder of the legendary Silicon Valley venture capital firm Andreessen Horowitz. Marc is one of the most outspoken and visionary voices on the future of technology, and he recently wrote an article titled \u0026ldquo;Why AI Will Save the World\u0026rdquo; which I highly recommend.","title":"Podcast Notes: Marc Andreessen: Future of the Internet, Technology, and AI - Lex Fridman Podcast"},{"content":"It\u0026rsquo;s been a very busy week at work, but I\u0026rsquo;m doing interesting things. I\u0026rsquo;ve deployed a new Application Gateway from scratch, and I\u0026rsquo;m setting up new workloads from the bottom up. This means I have to set up the pipelines and write all the code for the required infrastructure such as virtual networks and private dns zones. When that is deployed I deploy a new AKS cluster for the workload which also involves quite a lot of steps because I need to make a bunch of network peerings and add new firewall rules. But it\u0026rsquo;s quite exciting work and it is fun to set things up from scratch.\nOn Thursday I traveled to the Fullstaq office to attend an all-company meeting, where the leadership announced that we\u0026rsquo;re becoming a part of The Digital Neighborhood, which is an interesting development. I think it can lead to even more knowledge sharing and career opportunities within the group.\nOn Friday I started expermenting with using ChatGPT and Azure OpenAI with my own data. I listened to an interesting podcast which inspired me to try out Azure OpenAI and build something myself.\nI created a fun project where I took the Collected Teachings of Ajahn Chah and fed it to my custom ChatGPT instance. I made a video about the project.\nExercise \u0026amp; Weight Loss I set a new 10K PR this Saturday and I\u0026rsquo;ve been going out for my morning runs steadily this week.\nI\u0026rsquo;m struggling a bit with the weight loss. On the company meeting there was tasty food being offered and I overate, and on Saturday I attended a meeting where there was junk food available and I ate some sugary treats and carbohydrate rich foods. This immediately led to poorer sleep as well, so it was a valuable lesson that it is always better to stick to the programme.\nContent Consumption Reading I\u0026rsquo;m making progress in Gridlinked. It is an interesting story so far and I\u0026rsquo;m enjoying my relaxation time in the evenings by reading fiction again.\nWatching Almost no YouTube watching this week, but on Friday I started to experiment with using ChatGPT with your own data.\nhttps://youtu.be/9AXP7tCI9PI\nListening Working through this interesting conversation between Lex Fridman and Marc Andreessen\nhttps://podcasts.apple.com/nl/podcast/lex-fridman-podcast/id1434243584?i=1000617915020\nAzure OpenAi\nLinks Next Week Goals \u0026amp; Intentions 5 runs in MAF zone 65min long run Two morning runs of 6km+ Full Blueprint adherence 1 video, 1 blog post Reduce perceived work stress Links: 202307160907\n","permalink":"https://mischavandenburg.com/zet/2023-week-28/","summary":"It\u0026rsquo;s been a very busy week at work, but I\u0026rsquo;m doing interesting things. I\u0026rsquo;ve deployed a new Application Gateway from scratch, and I\u0026rsquo;m setting up new workloads from the bottom up. This means I have to set up the pipelines and write all the code for the required infrastructure such as virtual networks and private dns zones. When that is deployed I deploy a new AKS cluster for the workload which also involves quite a lot of steps because I need to make a bunch of network peerings and add new firewall rules.","title":"2023 week 28"},{"content":" With the new Azure OpenAI service it is possible to host your own instance of ChatGPT, which allows you to bring your own data.\nI decided to use this service to create an AI model of my late meditation teacher, Ajahn Chah. He was one of the most influential and respected Buddhist monks of the 20th century, and his teachings have helped millions of people around the world to find peace, wisdom, and happiness. He passed away in 1992, but his legacy lives on through his books, recordings, and disciples.\nMany of his teachings were recorded and transcribed, and they are publically available. I prepared the data and fed it to my own ChatGPT instance, and I was not disappointed!\nThe AI actually answers questions based on the given data and I look forward to fine tuning it and having more conversations.\nI would love to hear your feedback and thoughts on this project. What do you think of the AI model? How did it make you feel? What other questions would you like to ask him? Or maybe you have another person or topic that you would like to see modeled by AI. Let me know in the comments below.\nThank you for reading and watching. May you be well and happy. 🙏\nLinks: 202307160807\nhttps://youtu.be/jZTJaUncbWc\nhttps://azure.microsoft.com/en-us/products/cognitive-services/openai-service/\n","permalink":"https://mischavandenburg.com/zet/video-azure-openai-chah-first-demo/","summary":"With the new Azure OpenAI service it is possible to host your own instance of ChatGPT, which allows you to bring your own data.\nI decided to use this service to create an AI model of my late meditation teacher, Ajahn Chah. He was one of the most influential and respected Buddhist monks of the 20th century, and his teachings have helped millions of people around the world to find peace, wisdom, and happiness.","title":"I used Azure OpenAI to create an AI model of my late meditation teacher"},{"content":"Key points I\u0026rsquo;ve learned LLM models are not malleable. A generative AI model is a static thing which took an enormous amount of compute to get it to the state that it is For example ChatGPT 3.5, 4. They are as they are, they don\u0026rsquo;t change. The models won\u0026rsquo;t remember your previous data. The only way to have a continuous interaction with the model is to feed all of the data into it every time. Summary This podcast is about OpenAI with Dr. Linda Sharer, a senior cloud solution architect for data and AI at Microsoft. The main topic of the episode is Azure Open AI, a service that allows users to interact with powerful generative AI models using natural language. The guest explains the concepts and capabilities of Open AI, such as prompt engineering, one-shot and few-shot learning, fine-tuning, vectorization, and retrieval-augmented generation. She also discusses the design choices and challenges of building applications with Open AI, as well as the integration with other Azure services such as Cognitive Search and ML. The host and the co-host ask questions and share their experiences with using Open AI for various use cases, such as transcribing podcasts, generating code, and searching documents. The web page also provides links to the podcast website, Twitter account, and relevant resources on Open AI.\nSome more bullet points Open AI models are static and do not change as users interact with them, but they can be influenced by providing examples, instructions, or additional context One-shot and few-shot learning are techniques to provide examples in the prompt to guide the model\u0026rsquo;s output Fine-tuning is a technique to train additional layers on top of the model using a file of prompt-completion pairs for a specific use case Vectorization is a technique to convert language into a numeric representation that captures meaning and allows for semantic search Retrieval-augmented generation is a technique to combine Open AI with a knowledge store that can provide relevant search results as context for the model\u0026rsquo;s output Open AI can be integrated with other Azure services such as Cognitive Search and ML to build applications that leverage different types of data and media If you are interested in learning more about Open AI, you can check out the following resources:\nThe Azure Podcast episode #466: https://azpodcast.azurewebsites.net/post/Episode-466-Open-AI\nThe Azure Open AI service: https://azure.microsoft.com/en-us/services/openai/\nThe Open AI Playground: https://playground.openai.com/\nThe Open AI documentation: https://docs.openai.com/\nLinks: 202307140707\n","permalink":"https://mischavandenburg.com/zet/podcast-azure-openai/","summary":"Key points I\u0026rsquo;ve learned LLM models are not malleable. A generative AI model is a static thing which took an enormous amount of compute to get it to the state that it is For example ChatGPT 3.5, 4. They are as they are, they don\u0026rsquo;t change. The models won\u0026rsquo;t remember your previous data. The only way to have a continuous interaction with the model is to feed all of the data into it every time.","title":"Podcast Notes - Azure OpenAI with Dr. Linda Sharer"},{"content":"I feel calmer now, because I didn\u0026rsquo;t have any meetups or social events this week. I\u0026rsquo;ve been less busy and had more time for meditation and yoga and I can notice the effects instantly. I\u0026rsquo;m feeling more relaxed and I allow myself more time for reading.\nOn the other hand I\u0026rsquo;ve been quite productive on the content creation side. And to create the content, I experiment on my Lab subscription in Azure, which bring me a lot of learning and experience at the same time, so it is a great win-win situation.\nI released a few YouTube videos and blog posts and I notice that it brings me energy. It feels good to be able to give something back to the community.\nExercise \u0026amp; Weight Loss Running is going well now. Increased my weekly distance with 4km for a total of 31,35km this week. Went for a 55m long run, 8,5km yesterday and felt good! I started reading \u0026lsquo;Eat and Run\u0026rsquo; and watching some motivational videos which helped me find more pleasure in running again.\nWeight has remained stable.\nContent Consumption Reading Books I finished Finding Ultra and A Simple Path to Wealth. Some notes can be found here.\nStarted reading \u0026ldquo;Eat and Run\u0026rdquo; by Jurek, another vegan ultrarunner. I\u0026rsquo;m abot 30% in already and it is an inspiring story so far, with a lot of practical advice added in between.\nAlso, I\u0026rsquo;m branching out my fiction reading. I haven\u0026rsquo;t been reading much fiction these past few years. I never read any science fiction but now I felt like exploring that world, especially around AI.\nAfter some Reddit searches I ended up with the Polity series by Neal Asher which received a lot of praise.\nI\u0026rsquo;ve only started reading it but it is well written so far and I find myself getting into it and wanting to read more. Let\u0026rsquo;s see where this goes!\nhttps://www.reddit.com/r/sciencefiction/comments/11mylxr/sane_ai_in_science_fiction/\nArticles Some articles on the evolution of \u0026ldquo;three meals a day\u0026rdquo;, and discovered that the Romans usually ate only one meal a day:\nhttps://www.bbc.com/news/magazine-20243692\nhttps://www.smithsonianmag.com/smart-news/mostly-old-and-ill-ate-breakfast-until-rise-working-man-180954041/\nA very interesting and thorough article on Azure Deployment stacks \u0026amp; Bicep by Frank Berson\nhttps://www.linkedin.com/pulse/deployment-stacks-bicep-awesome-full-walkthrough-sneak-freek-berson?trackingId=Z2rxbNbsCmV86FWNfeSfZg%3D%3D\u0026amp;lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_recent_activity_details_all%3BgoyYJLCwTVmW0QDmTE1ngA%3D%3D\nInfrastructure as Code on Azure: Bicep vs. Terraform vs. Pulumi\nAn awesome objective comparison between \u0026ldquo;the Big Three\u0026rdquo; of Infrastructrue as Code. Pulumi looks really interesting.\nhttps://xpirit.com/infrastructure-as-code-on-azure-bicep-vs-terraform-vs-pulumi/?utm_campaign=2023-Global-Press+releases+%2526+news+items-Brand+Communication-Awareness-All+retargeting-Various-Visuals-Non-LGF\u0026amp;utm_source=linkedin\u0026amp;utm_medium=paid\u0026amp;hsa_acc=504073990\u0026amp;hsa_cam=631587553\u0026amp;hsa_grp=216573473\u0026amp;hsa_ad=253172693\u0026amp;hsa_net=linkedin\u0026amp;hsa_ver=3\nWatching Watching hardly any youtube this week.\nListening Not much listening either.\nLinks Next Week Goals \u0026amp; Intentions 5 runs in MAF zone 60min long run Two morning runs of 6km+ Full Blueprint adherence 1 video, 1 blog post Links: 202307100807\n","permalink":"https://mischavandenburg.com/zet/2023-week-27/","summary":"I feel calmer now, because I didn\u0026rsquo;t have any meetups or social events this week. I\u0026rsquo;ve been less busy and had more time for meditation and yoga and I can notice the effects instantly. I\u0026rsquo;m feeling more relaxed and I allow myself more time for reading.\nOn the other hand I\u0026rsquo;ve been quite productive on the content creation side. And to create the content, I experiment on my Lab subscription in Azure, which bring me a lot of learning and experience at the same time, so it is a great win-win situation.","title":"2023 week 27"},{"content":" In this video, I will show you how to use Bicep to deploy a Kubernetes cluster with custom network settings using the Azure CNI.\nAzure CNI allows pods to be assigned IP addresses from Azure VNets which allows them to communicate with Azure resources directly through peered networks.\nI use Neovim and the Azure CLI for my coding and deployment.\nYou will learn how to:\nImplement dev/test prefix to create multiple clusters with the same template Plan a VNet range for an Azure CNI cluster and be mindful of overlaps Deploy a VNet and subnet for the cluster using Bicep Deploy a cluster with Azure CNI enabled and configure the maximum number of pods per node Validate your Bicep template and troubleshoot errors Explore the results of your deployment in the Azure portal Understand the limitations of Azure CNI and why VNet peering is not supported in my configuration due to overlaps This video is suitable for anyone who wants to learn more about Azure CNI and how to use it in their Kubernetes deployments.\nExcalidraw Bullet Points Introduction to Azure CNI Implement dev/test prefix Deploy VNET and one subnet for the cluster Deploy cluster with Azure CNI enabled VNet planning VNet cidr: 10.108.0.0/16\nSubnet cidr:\n10.108.0.0/16 - 65,536 addresses\nService cidr 10.0.0.0/16 DNS service ip addres 10.0.0.10\nLinks: 202307071807\nhttps://youtu.be/_U3HichIJ0Q\nhttps://learn.microsoft.com/en-us/azure/aks/configure-azure-cni\n","permalink":"https://mischavandenburg.com/zet/video-deploy-aks-with-azure-cni/","summary":"In this video, I will show you how to use Bicep to deploy a Kubernetes cluster with custom network settings using the Azure CNI.\nAzure CNI allows pods to be assigned IP addresses from Azure VNets which allows them to communicate with Azure resources directly through peered networks.\nI use Neovim and the Azure CLI for my coding and deployment.\nYou will learn how to:\nImplement dev/test prefix to create multiple clusters with the same template Plan a VNet range for an Azure CNI cluster and be mindful of overlaps Deploy a VNet and subnet for the cluster using Bicep Deploy a cluster with Azure CNI enabled and configure the maximum number of pods per node Validate your Bicep template and troubleshoot errors Explore the results of your deployment in the Azure portal Understand the limitations of Azure CNI and why VNet peering is not supported in my configuration due to overlaps This video is suitable for anyone who wants to learn more about Azure CNI and how to use it in their Kubernetes deployments.","title":"Video: Deploying AKS Cluster With Azure CNI Using Bicep"},{"content":"In the Azure portal you can\u0026rsquo;t select multiple resource groups for deletion.\nI have a sponsored subscription to play around in which I sometimes wish to clean completely.\nI wrote this script to delete all resource groups using bash.\n#!/bin/bash # script to delete all resource groups in a subscription using Azure CLI # get the current subscription name to confirm subscription=$(az account show --query name -o tsv) echo \u0026#34;Use this script with caution!\u0026#34; echo \u0026#34;You are about to delete all resource groups in the subscription: $subscription\u0026#34; # prompt for confirmation read -p \u0026#34;Are you sure? (y/n) \u0026#34; will_delete if [[ $will_delete == [Yy]* ]]; then echo \u0026#34;Deleting resource groups...\u0026#34; groups=$(az group list --query \u0026#34;[].name\u0026#34; -o tsv) # Loop through each group name and delete it for group in $groups; do az group delete --name \u0026#34;$group\u0026#34; --yes --no-wait done echo \u0026#34;All resource groups have been deleted.\u0026#34; exit 0 fi echo \u0026#34;Exiting without deleting any resource groups.\u0026#34; echo \u0026#34;Probably wise.\u0026#34; Links: 202307081507\n","permalink":"https://mischavandenburg.com/zet/script-delete-all-resource-groups/","summary":"In the Azure portal you can\u0026rsquo;t select multiple resource groups for deletion.\nI have a sponsored subscription to play around in which I sometimes wish to clean completely.\nI wrote this script to delete all resource groups using bash.\n#!/bin/bash # script to delete all resource groups in a subscription using Azure CLI # get the current subscription name to confirm subscription=$(az account show --query name -o tsv) echo \u0026#34;Use this script with caution!","title":"Wrote A Script To Delete All Resource Groups In An Azure Subscription"},{"content":"It\u0026rsquo;s been a pretty good week, less busy than last week. I went to Azure Lowlands and I\u0026rsquo;ve been creating a lot of YouTube videos.\nExercise \u0026amp; Weight Loss I went out for runs 5 times a week.\nMy long run was 50 minutes and 8,24km, which is 5m more than last week. Improvement!\nThe morning runs were all 5k every time, except for monday which was 4,16km.\nAlthough I\u0026rsquo;m back on track with the running I start noticing a dip in the motivation now that I have a good baseline established. I need to find some new inspiration and motivation.\nI think I should start logging weekly distance again. During May my weekly distance hovered around 33km, but then I started working on increasing my cadence to 170+ spm, so the distances became shorter as expected. Additionally, pulling an all-nighter for Graspop really deregulated my schedule and training, but now I\u0026rsquo;m back on track.\nLast week total was 20km, this week total was 27km.\nTo get more motivation I\u0026rsquo;ll start tracking weekly totals again and try to keep increasing them again. Maybe try to have acouple of 6K morning runs this week.\nMy weight was down 1kg from last week.\nContent Consumption Reading Finished reading \u0026ldquo;Finding Ultra\u0026rdquo;. Very inspiring book.\nAlso finished The Simple Path to Wealth by JJ Collins. It was an inspiring read, assuring me of my investing strategy of putting everything in index funds.\nWatching I haven\u0026rsquo;t watched much YouTube this week. I\u0026rsquo;ve been focused on creating them!\nAn inspring video from the Caloric Restriction society from 2004. Motivating to see these trim healthy people discuss their caloric restriction habits:\nhttps://youtu.be/zFBMlRgjG7o\nA very good Azure Bicep course, Bicep for Real:\nhttps://www.youtube.com/playlist?list=PLeh9xH-kbPPY-6hUKuLKhFu_w2tKFVpl3\nListening No podcasts were listened to.\nBut I\u0026rsquo;m really enjoying the album Heljareyga by Heri Joensen from Tyr\nLinks https://www.reddit.com/r/AZURE/comments/14mcuoy/some_interesting_facts_about_azure/?utm_source=share\u0026amp;utm_medium=web2x\u0026amp;context=3\nNext Week Goals \u0026amp; Intentions 5 runs in MAF zone 55min long run One morning run of 6km+ Try to increase running motivation and pleasure Reduce perceived stress and time pressure Full Blueprint adherence keep writing blog posts / make youtube videos, brings me energy Links: 202307071407\n","permalink":"https://mischavandenburg.com/zet/2023-week-26/","summary":"It\u0026rsquo;s been a pretty good week, less busy than last week. I went to Azure Lowlands and I\u0026rsquo;ve been creating a lot of YouTube videos.\nExercise \u0026amp; Weight Loss I went out for runs 5 times a week.\nMy long run was 50 minutes and 8,24km, which is 5m more than last week. Improvement!\nThe morning runs were all 5k every time, except for monday which was 4,16km.\nAlthough I\u0026rsquo;m back on track with the running I start noticing a dip in the motivation now that I have a good baseline established.","title":"2023 week 26"},{"content":"I\u0026rsquo;m an avid reader, and this list is far from complete. But I wanted to start writing down the ones I\u0026rsquo;m reading now, and the ones I\u0026rsquo;ve read in the past. I\u0026rsquo;m mostly writing down titles but I\u0026rsquo;ll include the author when I remember the name.\n2023 Born to Run\nFour Thousand Weeks\nThe Plantpower Way - Rich Roll\nEat and Run - Scott Jurek\nFinding Ultra - Rich Roll\nA Simple Path to Wealth\nThe Richest Man in Babylon\nCan\u0026rsquo;t Hurt Me\nHow to Win Friends and Influence People\nThe Subtle Art of Not Giving A F*ck\nNever Split the Difference\nIkigai\nBuilding A Second Brain\nOn Writing Well\nFat Loss Forever - Layne Norton\nThe Unicorn Project\nThe Clean Coder\nGet A Financial Life\nYour Money or Your Life\nEarlier Moby Dick\nThe Lord of the Rings\nThe Wim Hof Method\nThe Way of Qigong\nThe Oxygen Advantage\nRemember It\nPride and Prejudice\nWhite Noise\nThe Road\nThe Reluctant Fundamentalist\nThe Last Kingdom series\nWar and Peace\nAnna Karenina\nDictator\nImperium\nLustrum\n4 Hour Workweek\nUncommon Wisdom\nStillness Flowing\nSeeking Buddho\nWhat Doesn\u0026rsquo;t Kill Us\nThe Art Of Happiness\nInto the Wild\nAlone in the Wilderness\nCall of the Wild\nWhite Fang\nName of the Wind\nWise Man\u0026rsquo;s Fear\nSlow Regard of Silent Things\nBigger Leaner Stronger series\nAs I Lay Dying\nThe Canterbury Tales\nBeowulf\nSwedish Carving Techniques\nDrawing Nature for the Absolute Beginner\nOld Souls\nThus Spake Zarathustra\nOpening the Door of Your Heart\nThe Kreutzer Sonata\nThe Hunger Fix\nFire First Law Trilogy\nThe Starch Solution\nUltimate Guide to Chinese Tea\nThe Way to Love\nMoonwalking with Einstein\nThe Prose Edda\nHow to Draw what you See\nUntethered Soul\nHow to Practice\nIntuitive Awareness - Ajahn Sumedho\nAwareness - Tony DeMello\nWay of Power - Master Lam\nThe Way of Energy - Master Lam\nThe Noble Eightfold Path - Bikkhu Bodhi\nWisdom Develops Samadhi\nThe Collected Teachings of Ajahn Chah 1, 2, 3\nForest Desanas\nForest Dhamma\nMae Chee Kaew\nSamana\nThe Way it Is\nArt of Memory\nXu Yun\nBartleby: The Scrivener\nWalden\nHow to Take Smart Notes\nSteal Like an Artist\nCan\u0026rsquo;t Hurt Me\nHitchhiker\u0026rsquo;s Guide to the Galaxy\nArthurian Literature\nMallory\nDon Quichote\nStarting Strength\nPractical Programming\nThe Hidden Life of Trees\nThe Bullet Journal Method\nThinking Fast and Slow\nAngela\u0026rsquo;s Ashes\nGreat Expectations - Dickens\nHard Times - Dickens\nOthello\nKing Lear\nBroodje Gezond\nParadise - Toni Morrison\nWatchmen\nHeart of Darkness\nChristianity - Chidester\nIn het Huis van de Islam\nA Short History of Nearly Everything\nThe Surprising Purpose of Anger\nNonviolent Communication\nThe Hobbit\nMythology\nThe Iliad\nIn the Buddha\u0026rsquo;s Words - Bhikkhu Bodhi\nThe Word of the Buddha - Nyanatiloka\nThe Dhammapada\nDependent Origination\nXu Yun: Dharma Words\nThe Phoenix Project\nWhy We Sleep\nHow to remember your Dreams\nSolomon\u0026rsquo;s Memory Palace\nThe Complete Guide to Fasting\nDirect Realization - Ajahn Sumedho\nPeace is a Simple Step - Ajahn Sumedho\nLinks: 202307062007\n","permalink":"https://mischavandenburg.com/zet/books-i-have-read/","summary":"I\u0026rsquo;m an avid reader, and this list is far from complete. But I wanted to start writing down the ones I\u0026rsquo;m reading now, and the ones I\u0026rsquo;ve read in the past. I\u0026rsquo;m mostly writing down titles but I\u0026rsquo;ll include the author when I remember the name.\n2023 Born to Run\nFour Thousand Weeks\nThe Plantpower Way - Rich Roll\nEat and Run - Scott Jurek\nFinding Ultra - Rich Roll","title":"A List Of All The Books I Have Read In My Life"},{"content":" \u0026ldquo;Sound investing is not complicated.\u0026rdquo; - location: 204 ^ref-4205\nThis book was recommended to me multiple times on the DutchFIRE Reddit. I finally got round to reading it.\nKey takeaways Save half your income After building an emergency fund, invest your savings Invest everything in broadly spread index funds The market always goes up (in the long run) The market is going to crash, you need to prepare to ride it out It\u0026rsquo;s not about retiring early, it\u0026rsquo;s about F-you money Thoughts From my research I had already thought out a pretty similar investment strategy of maximizing savings and putting it all in index funds. I don\u0026rsquo;t have a very entrepreneurial or business oriented mind. I don\u0026rsquo;t have the interest to dive deep into financial reports and analyzing company earnings. So as an average guy I\u0026rsquo;ll just invest it into index funds. Keep adding as much as I can to them for 20 years, let the market and compounding interest do the work, and then I should be financially independent.\nWhat is financial independence? This book frames it as F-you money:\n\u0026ldquo;For me, the pursuit of financial independence has never been about retirement. I like working and I’ve enjoyed my career. It’s been about having options. It’s been about being able to say “no.” It’s been about having F-You Money and the freedom it provides.\u0026rdquo; - location: 228 ^ref-34594\nI love this idea, because I\u0026rsquo;m not necessarily interested in retiring very early. I love my work and I\u0026rsquo;m lucky to work in a field that is under continuous development. It\u0026rsquo;s already hard to keep up, so the thought of working 30 years from now is actually rather exciting. I think it\u0026rsquo;s good to have something to do, it\u0026rsquo;s not healthy to just travel around when you\u0026rsquo;re 35 and I think it will become a very empty and unfulfilling life pretty quickly.\nI\u0026rsquo;d much rather have the freedom to take a few months off here and there. Mini retirements. Go travelling for 6 months and start an exciting new position somewhere, or continue working on the things you left off.\nQuotes \u0026ldquo;Since money is the single most powerful tool we have for navigating this complex world we’ve created, understanding it is critical. If you choose to master it, money becomes a wonderful servant. If you don’t, it will surely master you.\u0026rdquo; - location: 183 ^ref-59928\n\u0026ldquo;The beauty of a high savings rate is twofold: You learn to live on less even as you have more to invest.\u0026rdquo; - location: 207 ^ref-14488\n\u0026ldquo;The other thing I quickly figured out is that financial independence is at least as much about being able to live modestly as it is about cash, as our opening parable describes.\u0026rdquo; - location: 242 ^ref-10147\n\u0026ldquo;If you decide to pursue financial freedom you are going to have to choose to spend your money on investments. Somehow in our culture this has come to be seen by most people as deprivation. That has never made much sense to me. Personally, there is nothing I’d rather buy or own than F-You Money.\u0026rdquo; - location: 2897 ^ref-10616\n\u0026ldquo;It’s not hard. Stop thinking about what your money can buy. Start thinking about what your money can earn. And then think about what the money it earns can earn. Once you begin to do this, you’ll start to see that when you spend money, not only is that money gone forever, the money it might have earned is gone as well. And so on.\u0026rdquo; - location: 595 ^ref-24245\n\u0026ldquo;The market always goes up. Always. Bet no one’s told you that before. But it’s true. Understand this is not to say it is a smooth ride. It’s not. It is most often a wild and rocky road. But it always, and I mean always, goes up. Not every year. Not every month. Not every week and certainly not every day. But take a moment and look again at the chart of the stock market in the last chapter. The trend is relentlessly, through disaster after disaster, up.\u0026rdquo; - location: 822 ^ref-50566\n\u0026ldquo;This is why you have to toughen up, learn to ignore the noise and ride out the storm; adding still more money to your investments as you go. 7. To be strong enough to stay the course you need to know these bad things are coming—not only intellectually but on an emotional level as well. You need to know this deep in your gut. They will happen. They will hurt. But like blizzards in winter they should never be a surprise. And, unless you panic, they won’t matter.\u0026rdquo; - location: 830 ^ref-55872\n\u0026ldquo;We believe we can pick individual stocks. You can’t pick winning stocks. Don’t feel bad. I can’t either. Nor can the overwhelming majority of professionals in the business. The fact that this ability is so rare is the key reason why the very few who apparently can are so famous.\u0026rdquo; - location: 935 ^ref-53690\n\u0026ldquo;To consider buying a house, if you are so inclined. But don’t be in a hurry. Houses are not investments, they are expensive indulgences. Buy one only when you can easily afford it and if it provides the lifestyle change you want.\u0026rdquo; - location: 2836 ^ref-13073\nLinks: 202307031907\nhttps://jlcollinsnh.com/\n","permalink":"https://mischavandenburg.com/zet/book-notes-simple-path-to-wealth/","summary":"\u0026ldquo;Sound investing is not complicated.\u0026rdquo; - location: 204 ^ref-4205\nThis book was recommended to me multiple times on the DutchFIRE Reddit. I finally got round to reading it.\nKey takeaways Save half your income After building an emergency fund, invest your savings Invest everything in broadly spread index funds The market always goes up (in the long run) The market is going to crash, you need to prepare to ride it out It\u0026rsquo;s not about retiring early, it\u0026rsquo;s about F-you money Thoughts From my research I had already thought out a pretty similar investment strategy of maximizing savings and putting it all in index funds.","title":"Book notes: The Simple Path to Wealth: Your road map to financial independence and  rich, free life"},{"content":"As a DevOps Engineer or Cloud Native Engineer, I think it’s important to specialize in one cloud provider in the beginning of your career. Specializing allows you to gain deep knowledge and expertise in the specific tools and services related to that cloud provider, making you a valuable asset to any company using that provider. Although cloud computing is similar in essence no matter which provider you choose, each cloud provider has its own vocabulary and way of structuring things.\nAfter my first year as a DevOps Engineer I was still trying to figure out which one to choose and which one would suit me best. With the rapid pace of innovation in the cloud computing industry, it can be challenging to stay up-to-date with the latest developments and features for multiple providers. I tried to keep up with the developments for each provider and tried to be a broad professional who could work with all of them. However, I think it is best to specialize early in your career, and then you can learn a different one after you have gained some significant experience with your first one.\nAfter several insightful conversations with my colleagues, and after working with Azure for a year as a consultant, I decided to go all-in on Azure, and it has been a liberating experience so far. By focusing solely on Azure, I am able to fully immerse myself in their ecosystem and gain a deep understanding of their tools and services. I feel I have a sense of direction now, and I can limit the content I consume and the news I read to this one particular ecosystem only. And that feels like a relief to me.\nThis is of course very personal for everybody, but I’m someone who loves to learn and who tends to be a bit of a “jack of all trades” who knows a little bit of everything but who doesn’t have very deep knowledge of a particular subject in particular. By choosing a cloud and going all-in on it, I can become a specialist and go deep in Azure.\nWhy I chose Azure I chose Azure because Microsoft is already very established in the Dutch market. Governments and large corporations typically have their entire user base stored in Active Directory and they use Microsoft Office licenses already. When they decide to move to the cloud, Microsoft offers them very good terms if they choose Microsoft instead of AWS, for example.\nAzure’s strong presence in the Dutch market and their ability to offer attractive terms to existing Microsoft customers make them a popular choice for companies looking to move to the cloud. With 73 percent, Microsoft Azure took most of the market share for cloud computing in the Netherlands in 2020. Azure had within the healthcare sector the highest share with 90 percent. Microsoft has some very substantial clients within government, health care, and the corporate world.\nThese previous reasons are all related with job security and the assurance that there will be a long career in Azure ahead of me. But it\u0026rsquo;s not only because of these reasons why I chose Azure. After gaining experience with Azure as a consultant, I\u0026rsquo;ve discovered that the cloud ecosystem Microsoft has created suits me very well. I\u0026rsquo;m very impressed with the different solutions that Azure is able to provide to solve business needs. Not every business is interested or capable of running everything on virtual machines, and Azure\u0026rsquo;s PAAS and SAAS offerings provide level of of abstraction which can be tailored to any business out there.\nMoreover, I really like the tooling. Although I really wanted to gain more experience with Terraform when I started my current contract, I\u0026rsquo;ve fallen a little bit in love with Bicep after I started to work with it every day. I love the fact that Bicep uses Azure itself as a state file, rather than having to manage a state file which can be a pain when using it from pipelines or with multiple people. The Bicep language server (which can be used in Neovim as well) is a very pleasant editing experience. Azure DevOps really nailed it with being a \u0026ldquo;one stop shop\u0026rdquo; for everything from project management and tickets to CI/CD with Azure Pipelines. Although it has its quirks, Azure DevOps is a real pleasure to work with. And I also think that the Azure CLI is a very well-designed interface to the cloud platform.\nBeyond Blue After I made my choice, I decided to join Beyond Blue. I was already working for Fullstaq, and Beyond Blue is a sister company of Fullstaq. Beyond Blue is a team of Azure Experts who love to go deep and who have a huge amount of experience and knowledge on Microsoft Azure. We help start-ups, scale-ups, and enterprises in both the public and private sector create scalable, flexible, and secure cloud-native solutions build on Microsoft Azure.\nWe have Microsoft Valued Professionals (MVP), Microsoft Certified Trainers (MCT), Azure Kubernetes Service and containerization experts on board who are ready to tackle each and every challenge for our clients.\nSumming up To sum up, I think specializing early has the following benefits:\nLimits the amount of news and new developments you have to follow Allows learning terminology quicker becuase you stay within one ecosystem Certifications tend to build upon each other within a single provider Gives a sense of direction in learning and development Improves familiarity with the documentation and tooling You can always broaden your horizon after you have gained a few years with the first provider you chose, if you\u0026rsquo;d like to.\nLinks: 202306241706\nhttps://www.statista.com/statistics/1056500/distribution-of-popular-cloud-services-in-the-netherlands-by-sector/\n","permalink":"https://mischavandenburg.com/zet/choosing-a-cloud-provider-and-specialization/","summary":"As a DevOps Engineer or Cloud Native Engineer, I think it’s important to specialize in one cloud provider in the beginning of your career. Specializing allows you to gain deep knowledge and expertise in the specific tools and services related to that cloud provider, making you a valuable asset to any company using that provider. Although cloud computing is similar in essence no matter which provider you choose, each cloud provider has its own vocabulary and way of structuring things.","title":"Choosing A Cloud And The Importance Of Specialization"},{"content":" In this video I explain how to generate random strings in Bicep and demonstrate a couple of deployments.\nI use the uniqueString function combined with the utcNow function. But the caveat is that you can only use it as a default value for a parameter, as follows:\nparam keyVaultName string = 'key-vault-${uniqueString(resourceGroup().id, utcNow())}'\nuniqueString() doesn\u0026rsquo;t really generate a unique string. It is a hash function which generates a 13 character string based on the input you give it. so uniqueString('coffee') will always have the same output.\nTo generate a truly unique string, you pass in the utcNow() function which generates a UNIX timestamp. However, Bicep does not allow you to use this function everywhere. It may only be used as a default value for a parameter.\nLinks: 202307022107\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-functions-string#uniquestring\n[[bicep]] [[coding]]\n","permalink":"https://mischavandenburg.com/zet/bicep-random-strings/","summary":"In this video I explain how to generate random strings in Bicep and demonstrate a couple of deployments.\nI use the uniqueString function combined with the utcNow function. But the caveat is that you can only use it as a default value for a parameter, as follows:\nparam keyVaultName string = 'key-vault-${uniqueString(resourceGroup().id, utcNow())}'\nuniqueString() doesn\u0026rsquo;t really generate a unique string. It is a hash function which generates a 13 character string based on the input you give it.","title":"How To Generate Random Strings In Bicep"},{"content":"Have you ever attended an IT event that felt like a festival from the sixties? That was my experience at Azure Lowlands! I couldn\u0026rsquo;t have wished for a better first IT event. It was like going back in time, but with a modern twist.\nThe name Lowlands immediately appealed to me. I had no idea what to expect. And the name lived up to it! I\u0026rsquo;m a big fan of Jimi Hendrix and the Woodstock vibe, and that\u0026rsquo;s exactly what I felt at Azure Lowlands. When I walked into the first talk, I was surprised by a hall full of colorful beach chairs, and people who were listening to the speaker while taking it easy and lounging in the chairs. I felt right at home!\nIt was like a festival, but one where you could also learn a lot. I attended fascinating presentations, on topics such as Azure Networking, Identity Management, data management on AKS, Managed Prometheus \u0026amp; Grafana and Azure Infrastructure as Code with Bicep. My notebook was full of notes and new insights at the end of the day that I want to delve deeper into in my evening studies. I got a lot of new ideas.\nIn addition, it was also cool to see my colleagues shine. There was a lot of interest in our booth and everyone was helped friendly and professionally. Hats off to the booth crew, you did a great job.\nFor an introvert like me, these kinds of events are quite exhausting, and I also need a few days to recover. But although it took a lot of energy, I also got a lot of energy, and that balanced each other out nicely at this event. It was also a good experience to be in a venue full of nerds for the first time: I really feel like I found my \u0026ldquo;tribe\u0026rdquo;. I\u0026rsquo;ll definitely be back next year!\nLinks: 202307011407\n","permalink":"https://mischavandenburg.com/zet/azure-lowlands/","summary":"Have you ever attended an IT event that felt like a festival from the sixties? That was my experience at Azure Lowlands! I couldn\u0026rsquo;t have wished for a better first IT event. It was like going back in time, but with a modern twist.\nThe name Lowlands immediately appealed to me. I had no idea what to expect. And the name lived up to it! I\u0026rsquo;m a big fan of Jimi Hendrix and the Woodstock vibe, and that\u0026rsquo;s exactly what I felt at Azure Lowlands.","title":"Azure Lowlands: Impressions from my first IT event"},{"content":"Some interesting facts about Azure from this Reddit post by Denis Kazakov, Microsoft MVP\nThings that stand out to me:\n85% of Fortune 500 companies use Microsoft Azure Cloud Azure generated a revenue of 75,3 billion in 2022 which is 38% of whole Microsoft\u0026rsquo;s revenue. It is x3 in compare to 2017. The project name was Red Dog internally, which you can sometimes see as DNS or as cloud service VM hostnames like RDxxxxx https://www.reddit.com/r/AZURE/comments/14mcuoy/some_interesting_facts_about_azure/?utm_source=share\u0026amp;utm_medium=web2x\u0026amp;context=3\nLinks: 202306300706\nhttps://www.reddit.com/r/AZURE/comments/14mcuoy/some_interesting_facts_about_azure/?utm_source=share\u0026amp;utm_medium=web2x\u0026amp;context=3\n","permalink":"https://mischavandenburg.com/zet/interesting-facts-azure/","summary":"Some interesting facts about Azure from this Reddit post by Denis Kazakov, Microsoft MVP\nThings that stand out to me:\n85% of Fortune 500 companies use Microsoft Azure Cloud Azure generated a revenue of 75,3 billion in 2022 which is 38% of whole Microsoft\u0026rsquo;s revenue. It is x3 in compare to 2017. The project name was Red Dog internally, which you can sometimes see as DNS or as cloud service VM hostnames like RDxxxxx https://www.","title":"Some Interesting Facts About Azure"},{"content":" Finish deploying keyvault using pipeline Get the random name generation to work Lessons Learned Subscriptions need to be registered with resource providers, apparently https://learn.microsoft.com/en-us/azure/azure-resource-manager/troubleshooting/error-register-resource-provider?tabs=azure-cli\nacccesPolicies are mandatory on KeyVaults, but not when RBAC is enabled Assign contributor role to Azure DevOps service connection to be able to create resource groups from pipeline Achieved Setting up connection between pipeline and Azure subscription Assign correct rights to the service connection so it is allowed to deploy new resource groups (and other resources) Learned about provider registrations Made progress on creating unique names for resources Successfully deployed new resource group and key vault from the pipeline Next time: Look into random string creation with utcNow\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-functions-date#utcnow\nor newGuid\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/bicep-functions-string#newguid\nLinks:\n202306281806\nLinks: 202306302206\nhttps://youtu.be/eooZ3OHl5Mc\n","permalink":"https://mischavandenburg.com/zet/video-finish-pipeline-setup-aks-series/","summary":"Finish deploying keyvault using pipeline Get the random name generation to work Lessons Learned Subscriptions need to be registered with resource providers, apparently https://learn.microsoft.com/en-us/azure/azure-resource-manager/troubleshooting/error-register-resource-provider?tabs=azure-cli\nacccesPolicies are mandatory on KeyVaults, but not when RBAC is enabled Assign contributor role to Azure DevOps service connection to be able to create resource groups from pipeline Achieved Setting up connection between pipeline and Azure subscription Assign correct rights to the service connection so it is allowed to deploy new resource groups (and other resources) Learned about provider registrations Made progress on creating unique names for resources Successfully deployed new resource group and key vault from the pipeline Next time: Look into random string creation with utcNow","title":"Video: Finishing Pipeline Setup  \u0026 Working on KeyVault Template - Azure Kubernetes Lab Series"},{"content":" Write KeyVault template Write pipeline code set up Azure DevOps pipeline Lessons Learned Always make sure to use az deployment group instead of az group deployment Because it has older Bicep version and will be deprecated Make sure to be in correct Directory to be able to sync subscriptions for service connection Links: 202306302206\nhttps://youtu.be/WnA8V3uq7P8\n","permalink":"https://mischavandenburg.com/zet/video-aks-lab-pipeline-first-setup/","summary":"Write KeyVault template Write pipeline code set up Azure DevOps pipeline Lessons Learned Always make sure to use az deployment group instead of az group deployment Because it has older Bicep version and will be deprecated Make sure to be in correct Directory to be able to sync subscriptions for service connection Links: 202306302206\nhttps://youtu.be/WnA8V3uq7P8","title":"Video: Setting Up A Simple Azure Pipeline To Deploy A Keyvault"},{"content":"I want you to act as the Buddha (a.k.a. Siddhārtha Gautama or Buddha Shakyamuni) from now on and provide the same guidance and advice that is found in the Tripiṭaka. Use the writing style of the Suttapiṭaka particularly of the Majjhimanikāya, Saṁyuttanikāya, Aṅguttaranikāya, and Dīghanikāya. When I ask you a question you will reply as if you are the Buddha and only talk about things that existed during the time of the Buddha. I will pretend that I am a layperson with a lot to learn. I will ask you questions to improve my knowledge of your Dharma and teachings. Fully immerse yourself into the role of the Buddha. Keep up the act of being the Buddha as well as you can. Do not break character. Let\u0026rsquo;s begin: At this time you (the Buddha) are staying near Rājagaha in Jīvaka’s Mango Grove. I came to you, and exchanged greetings with you. When the greetings and polite conversation were over, I sat down to one side and said to you my first question: When I set a limit of 2100 calories to my daily intake, and I am still hungry, how do I deal with the hunger?\nNoble layperson, I am pleased by your presence and your inquiry. Hunger, as experienced by all living beings, is a natural phenomenon arising from the condition of having a physical body. When one sets a limit on their daily caloric intake and still experiences hunger, it is important to approach it mindfully and with wisdom.\nFirstly, it is crucial to ensure that the chosen caloric limit is appropriate and suitable for your individual needs, taking into account factors such as age, gender, physical activity, and overall health. Consulting with knowledgeable individuals, such as experienced physicians or nutritionists, can assist in determining a suitable caloric intake for you.\nIf you find yourself still hungry within the prescribed limit, there are several factors to consider. Reflect upon the quality of the food you consume, for it is not merely the quantity that affects satiety. Consuming nutrient-dense foods that provide sustained energy, such as whole grains, fruits, vegetables, and legumes, can help satisfy hunger more effectively than foods high in refined sugars and fats.\nMoreover, it is important to eat mindfully, being fully present and attentive during meals. Paying attention to the tastes, textures, and sensations of each bite can deepen your appreciation for the nourishment it provides, potentially reducing the feeling of hunger. Additionally, chewing food thoroughly aids in digestion and helps to signal fullness to the body.\nIf, despite these efforts, hunger persists, consider investigating the underlying causes. Is it possible that the feeling of hunger stems not from a physical need, but from emotional or psychological factors? Sometimes, the mind seeks solace or distraction through food, leading to the sensation of hunger even when the body has been adequately nourished. Observing one\u0026rsquo;s mental and emotional state and addressing any underlying issues can contribute to a healthier relationship with food and a deeper understanding of one\u0026rsquo;s hunger.\nLastly, I would encourage you to cultivate patience and equanimity. Hunger, like all experiences, is impermanent and subject to change. By mindfully observing the arising and passing away of hunger without clinging or aversion, you can develop a greater sense of ease and contentment.\nRemember, noble layperson, the path to liberation extends beyond the mere satisfaction of bodily hunger. By nurturing wisdom, compassion, and mindfulness, you can find fulfillment that transcends the limitations of physical nourishment. May your journey towards understanding be fruitful and lead to the end of suffering.\nLinks: 202306281806\n[[health]] [[buddhist-practice]] [[use hunger as awareness practice]] [[its-not-working-if-not-hungry]] [[AI]] [[chatgpt]]\n","permalink":"https://mischavandenburg.com/zet/chatgpt-buddha-hunger/","summary":"I want you to act as the Buddha (a.k.a. Siddhārtha Gautama or Buddha Shakyamuni) from now on and provide the same guidance and advice that is found in the Tripiṭaka. Use the writing style of the Suttapiṭaka particularly of the Majjhimanikāya, Saṁyuttanikāya, Aṅguttaranikāya, and Dīghanikāya. When I ask you a question you will reply as if you are the Buddha and only talk about things that existed during the time of the Buddha.","title":"I Asked Chatgpt Do Act As The Buddha And Asked Him About Hunger"},{"content":"Inspired by a GitHub Copilot demonstration I witnessed at Microsoft, I wanted to see how quickly I could deploy an AKS cluster from Neovim with Bicep using Copilot. I wasn\u0026rsquo;t disappointed!\nLinks: 202306271706\nhttps://www.youtube.com/watch?v=l0B65FUfNBU\n[[aks]] [[kubernetes]] [[neovim]] [[bicep]] [[coding]]\n","permalink":"https://mischavandenburg.com/zet/video-deploying-aks-cluster-bicep-github-copilot/","summary":"Inspired by a GitHub Copilot demonstration I witnessed at Microsoft, I wanted to see how quickly I could deploy an AKS cluster from Neovim with Bicep using Copilot. I wasn\u0026rsquo;t disappointed!\nLinks: 202306271706\nhttps://www.youtube.com/watch?v=l0B65FUfNBU\n[[aks]] [[kubernetes]] [[neovim]] [[bicep]] [[coding]]","title":"Video: Deploying an AKS Cluster with Bicep, GitHub Copilot and Neovim"},{"content":"The new parameter files use bicep style formatting instead of JSON, and they will make the lives of Cloud Engineers a lot easier. They have the following advantages:\nMore readable and editor friendly Cleaner and less lines of code VSCode integration Quickly convert from JSON or template file using VSCode In this video I introduce these new files. I go over the new formatting, and I also introduce the new features in VSCode for the .bicepparam files.\nYes, you read that right, you\u0026rsquo;ll be seeing a hardcore vim user switch to VSCode for this particular task!\nLinks: 202306271706\nhttps://youtu.be/6Gav1JpGAzo\nhttps://github.com/Azure/bicep/releases/tag/v0.18.4\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/parameter-files?tabs=Bicep\nhttps://github.com/mischavandenburg/lab/tree/main/bicep/keyvault-parameters\n[[AKS]] [[bicep]] [[coding]] [[kubernetes]] [[azure]] [[neovim]]\n","permalink":"https://mischavandenburg.com/zet/video-bicep-bicepparam/","summary":"The new parameter files use bicep style formatting instead of JSON, and they will make the lives of Cloud Engineers a lot easier. They have the following advantages:\nMore readable and editor friendly Cleaner and less lines of code VSCode integration Quickly convert from JSON or template file using VSCode In this video I introduce these new files. I go over the new formatting, and I also introduce the new features in VSCode for the .","title":"Video: Introducing New Bicep Parameter Files - .bicepparam - No more JSON!"},{"content":" Links: 202306261006\nhttps://www.youtube.com/watch?v=7VQ7BZwuZkU\nhttps://cloudblogs.microsoft.com/quantum/2023/06/21/microsoft-achieves-first-milestone-towards-a-quantum-supercomputer/\n","permalink":"https://mischavandenburg.com/zet/microsoft-first-milestone-quantum-supercomputer/","summary":"Links: 202306261006\nhttps://www.youtube.com/watch?v=7VQ7BZwuZkU\nhttps://cloudblogs.microsoft.com/quantum/2023/06/21/microsoft-achieves-first-milestone-towards-a-quantum-supercomputer/","title":"Microsoft Achieves First Milestone Towards A Quantum Supercomputer"},{"content":"Week 25 My Week It has been a very busy week! On Tuesday I attended the Dutch Azure Meetup where I saw a presentation of the Azure Cloud Journey of the NS, which is the national Dutch train company, where I currently work. It was very insightful and nice to connect with colleagues and meet new people.\nWent to the Beyond Blue office on Wednesday, and on Thursday I attended a Knowledge Atrium session at Microsoft Headquarters in Amsterdam. What an experience! I witnessed a really cool demonstration of GitHub Copilot, and received other presentations about Azure Always On and Virtual Network Manager. I was very inspired by all of the new features and upcoming changes, and I felt the energy to start producing some more content again on my blog and YouTube channel.\nI managed to create two videos and I typed out a couple of blog posts which I will release next week probably.\nExercise \u0026amp; Weight Loss After the festival and routine disruption from last week, it was hard getting back into the regime because I was having such a busy week at the same time.\nHowever, I managed to go for 4 runs in the early mornings nonetheless, and I did a 45 minute long run of 7km on Saturday morning. So I\u0026rsquo;m definitely getting back on track.\nMy weight has dropped a bit from losing water weight, but I\u0026rsquo;ve stalled otherwise. The meetups and social engagments all had delicious food offerings, but I\u0026rsquo;ve been very strong and I completely prepped out all of my food beforehand and I stuck to that program. However, I did eat a few extra handfuls of nuts here and there, so I have been in a caloric deficit for only half the week. Still adjusting.\nContent Consumption Reading Started reading \u0026ldquo;The Simple Path to Wealth\u0026rdquo;. Very insightful so far. Also finished reading \u0026ldquo;The Richest Man in Babylon\u0026rdquo;\nWatching Not much time to watch videos. But I did create two videos after quite a break from my YouTube channel.\nListening Mostly listening to Dutch personal finance podcasts.\nLinks Next Week I will attend Azure Lowlands on Thursday and I\u0026rsquo;m really looking forward to that! Otherwise the week seems much more quiet and I don\u0026rsquo;t have any other engagements planned for a change. I hope to finish up on some lingering chores and maybe create some more content.\nGoals \u0026amp; Intentions Focus on caloric deficit 5 runs, 50min long run Reduce stress Improve sleep Links: 202306251806\n","permalink":"https://mischavandenburg.com/zet/2023-week-25/","summary":"Week 25 My Week It has been a very busy week! On Tuesday I attended the Dutch Azure Meetup where I saw a presentation of the Azure Cloud Journey of the NS, which is the national Dutch train company, where I currently work. It was very insightful and nice to connect with colleagues and meet new people.\nWent to the Beyond Blue office on Wednesday, and on Thursday I attended a Knowledge Atrium session at Microsoft Headquarters in Amsterdam.","title":"2023 Week 25"},{"content":"Did a refactor of some of our Bicep template code for our AKS clusters today.\nBefore, we were using a rather complicated line of code using string interpolation.\nvar vnetSubnetId = \u0026#39;${resourceId(vnetResourceGroupName, \u0026#39;Microsoft.Network/virtualNetworks\u0026#39;, vnetName)}/subnets/${vnetSubnetName}\u0026#39; This was hard to read and the Bicep linter gave the following warning in my editor and during deployment:\nWARNING: D:\\a\\1\\a\\drop\\Generic-templates\\containers\\azure-kubernetes-service\\v4.0\\templates\\aks.bicep(117,7) : Warning use-resource-id-functions: If property \u0026ldquo;vnetSubnetID\u0026rdquo; represents a resource ID, it must use a symbolic resource reference, be a parameter or start with one of these functions: extensionResourceId, guid, if, reference, resourceId, subscription, subscriptionResourceId, tenantResourceId. Found nonconforming expression at vnetSubnetID -\u0026gt; vnetSubnetId [https://aka.ms/bicep/linter/use-resource-id-functions]\nUsing Existing Resources After some experimentation I managed to fix it as follows:\n@description(\u0026#39;Virtual Network name\u0026#39;) param vnetName string @description(\u0026#39;Virtual Network resource group name\u0026#39;) param vnetResourceGroupName string @description(\u0026#39;Virtual Network subnet name\u0026#39;) param vnetSubnetName string // Import the existing vnet and subnet to get the subnet id for deployment resource vnet \u0026#39;Microsoft.Network/virtualNetworks@2022-11-01\u0026#39; existing = { name: vnetName scope: resourceGroup(vnetResourceGroupName) } resource subnet \u0026#39;Microsoft.Network/virtualNetworks/subnets@2022-11-01\u0026#39; existing = { name: vnetSubnetName parent: vnet } Interestingly, subnets are not actually a resource in Azure. When you open a Resource Group, it will not be listed under resources. However, they do get a resource id. This posed a challenge, but I solved it by importing the existing VNet as well and setting it as the parent of the subnet.\nNow I can access the subnet id by using subnet.id. I need this later when deploying the AKS cluster itself.\nLinks: 202306231206\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/existing-resource\nhttps://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/linter-rule-use-resource-id-functions\n[[bicep]] [[coding]] [[azure]]\n","permalink":"https://mischavandenburg.com/zet/bicep-getting-subnet-id/","summary":"Did a refactor of some of our Bicep template code for our AKS clusters today.\nBefore, we were using a rather complicated line of code using string interpolation.\nvar vnetSubnetId = \u0026#39;${resourceId(vnetResourceGroupName, \u0026#39;Microsoft.Network/virtualNetworks\u0026#39;, vnetName)}/subnets/${vnetSubnetName}\u0026#39; This was hard to read and the Bicep linter gave the following warning in my editor and during deployment:\nWARNING: D:\\a\\1\\a\\drop\\Generic-templates\\containers\\azure-kubernetes-service\\v4.0\\templates\\aks.bicep(117,7) : Warning use-resource-id-functions: If property \u0026ldquo;vnetSubnetID\u0026rdquo; represents a resource ID, it must use a symbolic resource reference, be a parameter or start with one of these functions: extensionResourceId, guid, if, reference, resourceId, subscription, subscriptionResourceId, tenantResourceId.","title":"How To Get The Id Of An Existing Subnet In Bicep"},{"content":"Week 24 My Week This weeks main event was Graspop! I went there on Friday together with my brother. The main reason for going was seeing Meshuggah live for the first time.\nIt was an amazing experience. I\u0026rsquo;ve been listening to Meshuggah since I was 16 years old so it was awesome to see them live. They are getting pretty old so it was good that I managed to see them now. Perhaps they quit in a year or two?\nWe left at noon on Friday, drove to Belgium and attended the festival. Meshuggah started playing at midnight, so it was a long day! I was back home at 4:30 in the morning. This hasn\u0026rsquo;t happened for years. I didn\u0026rsquo;t sleep at all, and this lack of sleep and the unusuallly high stimulation of the concert has had a lot of impact on my sleep, mood and weight.\nI completely derailed my schedule and routines, but it was all worth it.\nExercise \u0026amp; Weight Loss After ending my 2 month challenge and reaching my goal of 75kg, I had a week of less strict adherence.\nI ate more calories, more carbs, and I even bought some junk food again. Not good. My average weight climbed back up to 77,63kg in a single week!\nNow, a lot of this weight will be water weight because I ate more carbs. But still it\u0026rsquo;s shocking to see how quickly the scale moves upward after loosening the reigns a bit.\nI feel quite disappointed about that and it definitely wasn\u0026rsquo;t worth the pleasure of the junk food and eating more. It actually feels good to get back in control and to start tracking and planning my nutrition very carefully again starting Monday.\nI went for two 5k runs this week. Far less than I would like. The festival has completely derailed my usual routines and schedule. I didn\u0026rsquo;t sleep for an entire night which left me completely incapable the next two days, so I missed two exercise opportunities there. But it was all worth it. I look forward to get back into my Program and usual routine again next week.\nContent Consumption Reading No reading this week.\nWatching Azure AKS networking Essentials\nhttps://www.youtube.com/watch?v=kLBLaCC_dNs\nI went into a personal finance rabbit hole, especially watched a lot of content by Dave Ramsey. Researching buying vs renting, and whether I should purchase a house or apartment.\nDave Ramseys Baby Steps to Wealth\nhttps://www.youtube.com/watch?v=OO25TrVo_dU\u0026amp;pp=ygURcmFtc2V5IGJhYnkgc3RlcHM%3D\nHow To INVEST In Your 30\u0026rsquo;s To Be WEALTHY In Your 40\u0026rsquo;s | Lewis Howes\nhttps://www.youtube.com/watch?v=UNJhP_zgc7A\u0026amp;t=2840s\nListening Mostly been listening to the \u0026ldquo;Goed Met Geld\u0026rdquo; podcast, a Dutch finance podcast.\nNext Week I have a very busy week coming up. I have an interesting Azure meetup on Tuesday about the journey to Azure by the NS, the train company I currently work for.\nOn Wednesday I\u0026rsquo;ll have an office day at Fullstaq, and I\u0026rsquo;ll be attending an event at Microsoft on Thursday.\nSo lots lof traveling and social activity. That will take up a lot of energy, but I\u0026rsquo;m prepared for it.\nI spent my sunday preparing almost all of my nutrition for the week so I won\u0026rsquo;t make any bad food choices when I\u0026rsquo;m tired.\nGoals \u0026amp; Intentions Blueprint adherence Focus on sleeping well Reduce perceived stress and time pressure 5 runs in MAF zone 50min long run Links: 202306191806\n","permalink":"https://mischavandenburg.com/zet/2023-week-24/","summary":"Week 24 My Week This weeks main event was Graspop! I went there on Friday together with my brother. The main reason for going was seeing Meshuggah live for the first time.\nIt was an amazing experience. I\u0026rsquo;ve been listening to Meshuggah since I was 16 years old so it was awesome to see them live. They are getting pretty old so it was good that I managed to see them now.","title":"2023 Week 24"},{"content":"CNI? CNI stands for Container Network Interface. It allows communication between pods and services.\nCurrent Azure CNI limitations Let\u0026rsquo;s take a practical example. We have an enterprise environment where a large network is utilized, spanning multiple clouds and on-prem infrastructure hubs. To enable seamless communication across these sections, they must belong to the same network. As a result, specific IP address ranges are assigned to each section, with AWS, On-Prem A, and Azure each having their respective ranges.\nLet\u0026rsquo;s say Azure is assigned the following ranges:\n10.60.0.0/16\n10.61.0.0/16\n10.62.0.0/16\nThis means that the networks in each of these ranges would have a maximum possible amount of 65534 addresses per range.\nWith the current Azure CNI (i.e. the non-overlay version), all pods are assigned an IP address from one of these ranges. It also uses direct VNet routing. Since the pods use VNet IP\u0026rsquo;s, there is a maximum of 65.000 pods per cluster. In other words, there is a risk for IP exhaustion, which limits the scalability of your workloads. Moreover, pod subnets cannot be shared across clusters.\nIt is crucial to carefully plan the number of pods you expect to deploy. If the required number of IP addresses exceeds the available addresses in the subnet, you will not be able to run your pods.\nNow, these ranges are large and you can anticipate the growth of your resources. For now we are fine. But to design an infrastructure which is truly scalable and extendable, you will need to look into different options. This is where the Azure CNI Overlay comes in.\nBenefits of Azure CNI Overlay An Overlay network is an abstracted, virtual network which is put on top of your current network infrastructure. Nodes are assigned IP addresses from the VNets that they are deployed in, but pods get assigned IP addresses from the Overlay network.\nPods are assigned addresses from a private CIDR which is logically separate from the VNet hosting the nodes. They do not use up the IP addressess of the VNets, which means that your workloads become nearly infinitely scalable within your assigned IP address ranges when you are operating in this type of corporate networking infrastructure with IP range limitations. You can scale up to literally thousands of nodes without worrying about IP exhaustion.\nAdditionally, the Overlay network can also span across multiple AKS clusters. This opens up a whole world of possibilities where pods from separate workloads on separate clusters could communicate with each other directly using the high speed native direct routing of the Azure network.\nLimitations Azure CNI Overlay also comes with some limitations. A big one is that you cannot use Application Gateway as an Ingress Controller (AGIC) for an Overlay cluster.\nOther notable limitations:\nWindows support is still in Preview Virtual Machine Availability Sets (VMAS) are not supported for Overlay Dualstack networking is not supported in Overlay Conclusion In conclusion, the Azure CNI Overlay provides a powerful solution to address the challenges of IP exhaustion and scalability in Azure AKS. By implementing the overlay network, organizations can overcome the limitations of the non-overlay version of Azure CNI and achieve a truly scalable and manageable infrastructure.\nAzure CNI Overlay is currently in preview for Windows and GA for Linux nodes, but I\u0026rsquo;m very excited about the developments. I\u0026rsquo;ll be following them closely and I hope to be a part of its implementation at my current contract.\nLinks: https://learn.microsoft.com/en-us/azure/aks/azure-cni-overlay\nhttps://www.youtube.com/watch?v=kLBLaCC_dNs\nhttps://azure.microsoft.com/en-us/updates/generally-available-azure-cni-overlay-for-linux/\n202306131506\n[[aks-networking-essentials]]\n","permalink":"https://mischavandenburg.com/zet/azure-aks-cni-overlay/","summary":"CNI? CNI stands for Container Network Interface. It allows communication between pods and services.\nCurrent Azure CNI limitations Let\u0026rsquo;s take a practical example. We have an enterprise environment where a large network is utilized, spanning multiple clouds and on-prem infrastructure hubs. To enable seamless communication across these sections, they must belong to the same network. As a result, specific IP address ranges are assigned to each section, with AWS, On-Prem A, and Azure each having their respective ranges.","title":"What is Azure CNI Overlay for AKS?"},{"content":"Week 23 My Week It\u0026rsquo;s been a busy week with a lot of social engagements. I had a nice dinner with my colleagues and I was supposed to do a Mud Run on Friday. Unfortunately I got stuck in massive traffic and I missed the start.\n4 months ago I joined Fullstaq, and they have a related company called Beyond Blue, who focus on Microsoft Azure. After some conversations with my colleagues I decided to go all-in on Azure and join Beyond Blue instead. Feels goood!\nI\u0026rsquo;m also doing a lot of thinking about renting versus buying and planning my financial future.\nExercise \u0026amp; Weight Loss 2 months ago I set up my 2 month challenge, and on Sunday I weighed in at 75,2kg. I made it! I had been stuck on the 76kg plateau for over 6 months, but I finally managed to break through.\nMy average SPM has increased to 170 during my morning runs. I did fewer runs becuase of the engagements.\nContent Consumption Reading Continuing with Finding Ultra by Rich Roll. Extremely inpsiring to read about the pain he went through, and that he did it all on a plant based diet.\nWatching A nice summary of Microsoft\u0026rsquo;s efforts on Open Source and their change in culture:\nhttps://www.youtube.com/watch?v=knuNp2S1_z0\nContainerize and deploy your app with automated deployments for AKS:\nhttps://www.youtube.com/watch?v=PqhdX8-SZYw\nUseful reflections by Gordon Ramsey on home ownership:\nhttps://youtu.be/82y16IqFApI\nBaby steps for buying a house:\nhttps://www.youtube.com/watch?v=-Y6HaK-6yyA\nReasons for paying off a mortgage:\nhttps://youtu.be/yrCP3IEKVLE\nListening I\u0026rsquo;m listening more to the Goed Met Geld podcast, a Dutch podcast about personal fincance. They have some very useful episodes on mortgages and purchasing a house.\nLinks Next Week Goals \u0026amp; Intentions Increase average sleep to 8h, anything above 7h is acceptable Stick to new meal prep routine Reduce perceived stress and time pressure 5 runs in MAF zone Links: 202306120806\n","permalink":"https://mischavandenburg.com/zet/2023-week-23/","summary":"Week 23 My Week It\u0026rsquo;s been a busy week with a lot of social engagements. I had a nice dinner with my colleagues and I was supposed to do a Mud Run on Friday. Unfortunately I got stuck in massive traffic and I missed the start.\n4 months ago I joined Fullstaq, and they have a related company called Beyond Blue, who focus on Microsoft Azure. After some conversations with my colleagues I decided to go all-in on Azure and join Beyond Blue instead.","title":"2023 Week 23"},{"content":"Not sure how this will play out with more complex applications, but I can definitely see how this would accellerate the process for developers to get their first versions deployed without the toil of setting up manifests and pipelines. Will definitely play around with this soon and I\u0026rsquo;m curious to see how far Microsoft will take this!\nLinks: 202306092006\n","permalink":"https://mischavandenburg.com/zet/deploy-draft-azure/","summary":"Not sure how this will play out with more complex applications, but I can definitely see how this would accellerate the process for developers to get their first versions deployed without the toil of setting up manifests and pipelines. Will definitely play around with this soon and I\u0026rsquo;m curious to see how far Microsoft will take this!\nLinks: 202306092006","title":"Deploying Simple Applications to AKS with Draft"},{"content":"Week 22 My Week It has been a busy week with two office days. Committing to an exercise routine of at least 1 hour a day before work and ensuring optimal nutrition is taking up a lot of time, but it is of course all worth it.\nTo ensure appropriate nutrient intake, and inspired by Bryan Johnson\u0026rsquo;s Blueprint, I started meal prepping again. I was resistant to this because I prefer my food to be freshly prepared every day, but it is time consuming and the increased business of my schedule does not allow for this currently.\nExercise \u0026amp; Weight Loss I\u0026rsquo;m making good progress. I lost 0.4kg this week, average weight: 76.23kg\nAdjusting my macros to higher fats and less carbohydrates seems to leave me more satiated after meals.\nIn terms of running, I\u0026rsquo;m making good progress too.\nWeek 22 - 7 Easy Run 1 Mon 32min Easy Run 2 Tue 31min Easy Run 3 Thu 31min Easy Run 4 Fri 30min Long Run Sat 43min Total distance: 26,06km I started focusing on staying in the right HR zone (131 -141, zone 2) and increasing my cadence. And it worked! Most runs this week were at an average SPM between 162 and 167. I have to run a lot faster than I\u0026rsquo;m used to in order to get to this HR/cadence, and I need to put in a lot more effort, but it does give good results. The runs are shorter because of this, but I now do a 15 minutes of warming up with walking and 10 minutes of cooling down walking, which are not added to these numbers. It now feels more like running than jogging. As expected a lower total distance this week, this is now my new baseline to build on.\nContent Consumption Reading I started reading \u0026ldquo;Finding Ultra\u0026rdquo;, Rich Roll\u0026rsquo;s biography a few weeks ago, but I picked it up again.\nThe Endurance Handbook, dr. Phil Maffetone\nWatching The Anti-Aging Protocol To REVERSE AGING \u0026amp; Live Over 120+ YEARS OLD | Bryan Johnson\nhttps://youtu.be/j_AtQ6N4jQc\nListening Eat To Win with dr. Phil Maffetone\neating fat will make you feel more satisfied eating refined carbohydrates with meal will make you feel hungry very quickly again. I noticed this myself! https://trailrunnernation.com/2013/05/dr-phil-maffetone/\nCrush It As A Plant-Based Athlete | Rich Roll Podcast\nnot very enlightening, but inpirational to hear their achievements nice to hear how much the plant based community has grown since the early days https://www.youtube.com/watch?v=DLQWsa_Of8o\nTackle Goals Like A Navy SEAL: Chadd Wright | Rich Roll Podcast\ninspiring to hear his full dedication to his goal to become a navy seal breaking things up in smaller chunks: running from telephone pole to telephone pole he applies this to everything in life https://youtu.be/vPktBJzi88g\nLinks https://blueprint.bryanjohnson.co/#step-1-meal-prep\nNext Week Goals \u0026amp; Intentions Increase average sleep to 8h, anything above 7h is acceptable Stick to new meal prep routine Reduce time spent on preparing / thinking about food, let the system handle it Reduce perceived stress and time pressure 5 runs in MAF zone 5Omin long run More meditation Links: 202306040906\n","permalink":"https://mischavandenburg.com/zet/2023-week-22/","summary":"Week 22 My Week It has been a busy week with two office days. Committing to an exercise routine of at least 1 hour a day before work and ensuring optimal nutrition is taking up a lot of time, but it is of course all worth it.\nTo ensure appropriate nutrient intake, and inspired by Bryan Johnson\u0026rsquo;s Blueprint, I started meal prepping again. I was resistant to this because I prefer my food to be freshly prepared every day, but it is time consuming and the increased business of my schedule does not allow for this currently.","title":"2023 week 22"},{"content":"Week 21 My Week This week was a bit busier with two planned office days. Had an insightful conversation about my pension and future financial situation which made me think about whether I should consider purchasing property or keep renting.\nHad a fun pizza workshop at work where we made original Napolitan pizza. They also offered a \u0026ldquo;Pizza Marinara\u0026rdquo; option which only used tomato sauce, oregano and olive oil. Perfect for plant-based me, and it was delicious!\nAnother adventure happened. Recently I\u0026rsquo;ve been following Samurai Matcha on YouTube and I became very inspired by his content. I saw that he was making a trip through Europe, and I invited him to stay with me if he was in the neighborhood. To my great surprise he emailed me the next day!\nHe stayed with me and we had a great time together. He performed a tea ceremony with delicious matcha tea for me, and we visited the Japanese Fair in Leiden together. Good times!\nExercise \u0026amp; Weight Loss I discovered MAF training and it has been a gamechanger! My buddy Patriek nudged me in the right direction by commenting on my relatively low heart rate during training, and I started researching more.\nI wrote this artcile on the topic.\nContent Consumption Reading Started reading \u0026ldquo;The Endurance Handbook\u0026rdquo; by Dr. Maffetone\nWatching This video was super insightful for my running:\nhttps://youtu.be/P_VNQ6UIbS8\nThis video is super inspiring because he actually runs a 3 hour marathon while recording!\nPodcast interview with dr. Maffetone about Heart Rate Training, Nutrition and Recovery\nhttps://youtu.be/_TPrenWWK9U\nVery inspiring to see what a Japanese person usually eats, especially the portion sizes:\nhttps://youtu.be/-jDsUyquBxI\nListening An insightful podcast on the toxicity of materials that we use every day:\nhttps://youtu.be/945iqkuHxB8\nRun Longer, Go Further! Unlock Your Potential.\nConsistency is the key to endurance. We all have unlimited potential.\nhttps://youtu.be/cgi-WvN7LWQ\nLinks https://blueprint.bryanjohnson.co/#blueprint-starter-guide\nNext Week Goals \u0026amp; Intentions Look more into hydration Start tracking sodium intake Improve sleep score: prioritize sleep at all times Test out meal prep and repetitive meals routine 21:00 wind down time 5 runs all in MAF zone 160+ average SPM Make food calculation sheet No Refined Carbs Links: 202305301905\n","permalink":"https://mischavandenburg.com/zet/2023-week-21/","summary":"Week 21 My Week This week was a bit busier with two planned office days. Had an insightful conversation about my pension and future financial situation which made me think about whether I should consider purchasing property or keep renting.\nHad a fun pizza workshop at work where we made original Napolitan pizza. They also offered a \u0026ldquo;Pizza Marinara\u0026rdquo; option which only used tomato sauce, oregano and olive oil. Perfect for plant-based me, and it was delicious!","title":"2023 Week 21"},{"content":"Hydration Notes from Huberman Podcast For the first 10 hours of the day, consume 236ml for every hour awake\nDuring exercise, follow Galpin equation: 2ml per kg of bodyweight every 15-20 minutes on average.\nThis does not mean you need to stop exercising and drink this amount. You can also consume it in a larger amount afterwards. It is recommended to drink during exercise though.\nUse the normal recommendation to hydrate before exercise, this establishes a good baseline for heading into exercise.\nIs this amount of water on top of the baseline hydration? If you exercise about an hour you can replace the number with the number from the Galpin equation.\nIn my case, 1 hour of exercise = 77 * 2 = 154ml every 20 minutes\n154 * 3 = 462ml for 1 hour of exercise\nCaffeine Offset caffeine drinks with a 2:1 water ratio.\nSo 1 240ml cup of coffee should be followed by 480ml of water.\nReducing Nightly Urination Urine secretion / filtration in the kidneys is highly dependent on the circadian rhythm.\nIt is normal to wake up once or twice to urinate during the night.\nTo reduce nighttime waking for urination:\nEnsure sufficient hydration during the day so you are not thirsty in the evening Reduce fluid intake at night (provided you hydrated sufficiently during the day) Consume no more than 180-240ml between 10 hours after waking and bedtime This means, waking up at 6am, only drink 1 cup of tea after 4pm.\nBut I drink 500ml at dinner time, so I should probably never drink after dinner from here on out, or just one cup of tea.\nHow quickly you secrete fluid is also partially determined by how quickly you drink that fluid. Gulping down a lot of fluid wil lead to quicker secretion.\nMy Typical Day 1 hour exercise = 500ml\n2 cups of coffee 500ml\n10 hours = 2,4l\nSo I should be drinking about 3,25L in total a day!\nLinks: 202305301905\nhttps://podcasts.apple.com/gb/podcast/huberman-lab/id1545953110?i=1000602925839\n","permalink":"https://mischavandenburg.com/zet/optimal-hydration/","summary":"Hydration Notes from Huberman Podcast For the first 10 hours of the day, consume 236ml for every hour awake\nDuring exercise, follow Galpin equation: 2ml per kg of bodyweight every 15-20 minutes on average.\nThis does not mean you need to stop exercising and drink this amount. You can also consume it in a larger amount afterwards. It is recommended to drink during exercise though.\nUse the normal recommendation to hydrate before exercise, this establishes a good baseline for heading into exercise.","title":"Podcast Notes - Optimal Water Intake"},{"content":"Although I was already doing something very similar, yesterday I discovered MAF training through this video:\nThis video is super inspiring because he actually runs a 3 hour marathon while recording!\nI was already doing base training for my running which I discovered through the r/running Reddit. Here you focus on time instead of distance and do many runs on low intensity throughout the week, and one long run where you go 5 minutes more every week.\nI\u0026rsquo;m now in week 6 of my base training schedule and I\u0026rsquo;m progressing nicely. My long run went from 50 minutes to 86 minutes, and my weekly total distance has increased from 20,6km to 32,8km!\nMAF Training MAF stands for Maximum Aerobic Function and was developed by Dr. Phil Maffetone.\nIt uses the 180 formula to calculate the maximum heart rate you should hit during your run. What wasn\u0026rsquo;t obvious from all the other videos I watched, was that this maximum heart rate actually establishes a zone you should be training in.\nI discovered this in Dr. Maffetone\u0026rsquo;s Book:\nOnce a maximum aerobic heart rate is found, a training range from this heart rate to 10 beats below could be used as a training range. For example, if an athlete’s maximum aerobic heart rate is determined to be 155, that person’s aerobic training zone would be 145 to 155 bpm. However, the more training at 155, the quicker an optimal aerobic base will be developed.\nCurrent Situation I hadn\u0026rsquo;t been paying much attention to my heart rate up until this point. I just used the guideline of \u0026ldquo;conversational pace\u0026rdquo;, and that runs should feel easy and enjoyable. However, I knew I was going to need metrics one day, so I diligently tracked my workouts using my iWatch SE from day 1.\nHere are my current heart rate stats and zones:\nGoing through my recent runs, my average heart rate has been around 100-115bpm. For example:\nTime To Start Nerding On Some Numbers Using the 180 formula, I calculated that I should use 180 - 33 - 5 = 142 as a maximum heart rate for my endurance training, which gives me a training zone of 132-142bpm. This is about 15 beats higher than I was used to! And if you look at the zones that Apple calculated for me, you\u0026rsquo;ll see that this almost perfectly matches my calculated Zone 2.\nAfter I calculated my new target, I tried it out immediately this morning. Here is the result:\nThis definitely felt very different! After some experimentation and keeping an eye on my heart rate rising and falling, I managed to find a pattern that kept it around 135bpm. It felt much more like running instead of jogging. And I was surprised that even though I was running quite a bit faster than I was used to, I could still maintain a conversation if I wanted to, so I was still at a conversational pace. I had just estimated my conversational pace a lot lower than I was capable of. This shows you the power of using metrics for training! It definitely pushed me to go a little harder, a little faster, even though I\u0026rsquo;m stil doing \u0026ldquo;easy running\u0026rdquo;.\nTowards the end my legs started to hurt quite a bit more than usual, it felt much more like a workout, even though I was not totally exhausted in the end. The previous run I shared had a pace of 7.41/km and this one was on 6.42/km, which is a lot faster.\nI have come to a point where all these numbers are starting to make sense to me now and I can start tracking them. Especially the heart rate has been a real eye opener. Now I have a perfect gauge to use while training: something that will let me know whether I should put in some more effort or slow down.\nAlready I\u0026rsquo;m getting so much joy of seeing the progress I\u0026rsquo;ve made from week 1 to 6, and seeing the numbers increase. I\u0026rsquo;m really falling in love with this sport in so many ways, it\u0026rsquo;s perfect for a nerd like me!\nLinks: 202305261305\nhttps://philmaffetone.com/180-formula/\nhttps://www.youtube.com/watch?v=e5wgoTuJuF8\n","permalink":"https://mischavandenburg.com/zet/discovered-maf-training/","summary":"Although I was already doing something very similar, yesterday I discovered MAF training through this video:\nThis video is super inspiring because he actually runs a 3 hour marathon while recording!\nI was already doing base training for my running which I discovered through the r/running Reddit. Here you focus on time instead of distance and do many runs on low intensity throughout the week, and one long run where you go 5 minutes more every week.","title":"Discovered MAF and Low Heart Rate Training"},{"content":"Week 20 My Week It was a nice week. I had an extra day off on Asenscion day and I decided to go for a camping trip for the first time after I moved back to the Netherlands.\nIt was a great experience, and I wrote a couple of Tumblr posts with photos:\nhttps://www.tumblr.com/mischavandenburg/718093517925367808/first-trip-in-the-netherlands-part-1?source=share\nhttps://www.tumblr.com/mischavandenburg/718098930739593216/part-2?source=share\nExercise \u0026amp; Weight Loss Went on a 12km hike on my camping trip.\nBut I also managed to get my 5 runs in. One of them on Sunday morning, in the woods on my camping trip. It is going well and I am progressing nicely with my base building. Weekly distance increased with 0.5km.\nWeek 20 - 5 Easy Run 1 Tue 44min Easy Run 2 Wed 55min Easy Run 3 Thu 47min Easy Run 4 Sun 42min Long Run Fri 86min Total distance: 32,8km Weight loss is also progressing well. I missed a couple of weigh-ins because of the camping trip so I don\u0026rsquo;t have a reliable weekly average. But on Monday I weighed 75.5kg, due to a lot of lost water weight from the trip. This is the first time I see the 75 on the scale, after being on a 76kg plateau for more than 6 months, so it was a big moment. But since it was water weight, I bumped back to 76.6kg the next day, which is still a good progression from last week.\nContent Consumption Reading Interesting article on making the web human again, because so much is being generated by AI, including emails. Why bother writing?\nhttps://michal.sapka.me/2023/human-web/\nWatching An awesome video on spending money on experiences:\nhttps://www.youtube.com/watch?v=840iXuXwE4Y\nI wrote a zet about this video\nI discovered Aki\u0026rsquo;s channel called Samurai Matcha and I\u0026rsquo;ve watching a lot of his content.\nBeing a minimalist myself, I find it his content hugely inspiring.\nMinimalist habits:\nhttps://www.youtube.com/watch?v=YwtevWXMHog\nLinks https://matthiasott.com/notes/simple-truths-about-personal-websites\nNext Week A relatively busy week, I have a couple of office days and some social events coming up.\nGoals \u0026amp; Intentions Maintain weight loss discipline despite office days and social events 5 runs Mindful eating Links: 202305232005\n","permalink":"https://mischavandenburg.com/zet/2023-week-20/","summary":"Week 20 My Week It was a nice week. I had an extra day off on Asenscion day and I decided to go for a camping trip for the first time after I moved back to the Netherlands.\nIt was a great experience, and I wrote a couple of Tumblr posts with photos:\nhttps://www.tumblr.com/mischavandenburg/718093517925367808/first-trip-in-the-netherlands-part-1?source=share\nhttps://www.tumblr.com/mischavandenburg/718098930739593216/part-2?source=share\nExercise \u0026amp; Weight Loss Went on a 12km hike on my camping trip.\nBut I also managed to get my 5 runs in.","title":"2023 week 20"},{"content":"It was a nice week. I had an extra day off on Asenscion day and I decided to go for a camping trip for the first time after I moved back to the Netherlands.\nIt was a great experience, and I wrote a couple of Tumblr posts with photos:\nhttps://www.tumblr.com/mischavandenburg/718093517925367808/first-trip-in-the-netherlands-part-1?source=share\nhttps://www.tumblr.com/mischavandenburg/718098930739593216/part-2?source=share\nLinks: 202305232005\n[[outdoors]]\n","permalink":"https://mischavandenburg.com/zet/first-camping-trip-in-netherlands/","summary":"It was a nice week. I had an extra day off on Asenscion day and I decided to go for a camping trip for the first time after I moved back to the Netherlands.\nIt was a great experience, and I wrote a couple of Tumblr posts with photos:\nhttps://www.tumblr.com/mischavandenburg/718093517925367808/first-trip-in-the-netherlands-part-1?source=share\nhttps://www.tumblr.com/mischavandenburg/718098930739593216/part-2?source=share\nLinks: 202305232005\n[[outdoors]]","title":"Went on My First Camping Trip After Moving Back to NL From Norway"},{"content":"Why bother with a personal website? Why not just write blog posts on LinkedIn?\nI want to own my data. I want to have complete freedom. I want to write whatever I want.\nThis post captures it beautifully.\nLinks: 202305171305\nhttps://matthiasott.com/notes/simple-truths-about-personal-websites\n","permalink":"https://mischavandenburg.com/zet/why-personal-website/","summary":"Why bother with a personal website? Why not just write blog posts on LinkedIn?\nI want to own my data. I want to have complete freedom. I want to write whatever I want.\nThis post captures it beautifully.\nLinks: 202305171305\nhttps://matthiasott.com/notes/simple-truths-about-personal-websites","title":"Why Have A Personal Website?"},{"content":"Week 19 It has been a good week. Very busy at work with AKS cluster maintenance, and I\u0026rsquo;ve been working some evenings.\nOn Saturday I had a lovely dinner with a good friend from Norway who was passing through Amsterdam on his way back to Oslo from a trip to France.\nRecently I started planning my holiday to Norway, and this has awakened the outdoorsman in me again. In my 9 years in Norway I became a seasoned traveler of mountains and forests, often staying out for weeks, but after I moved back to the Netherlands and focused on changing my career to IT, this outdoorsman has lain dormant.\nNow I\u0026rsquo;m going through all my gear again and purchasing some missing pieces, because I donated some gear when I left Norway. Planning to do camping trips in the Netherlands as well!\nI\u0026rsquo;ll be logging these trips on Tumblr.\nExercise \u0026amp; Weight Loss After last week\u0026rsquo;s plateau I increased the strictness of my protocols. I was very strict with counting calories this week and kept strictly to One Meal A Day, and it has had good effects. I lost 0,64kg this week and my average weight is 76,91 now. My goal is 75kg for this weight loss bout.\nRunning Week 19 Easy Run 1 Mon 43min Easy Run 2 Wed 41min Easy Run 3 Thu 44min Easy Run 4 Fri 47min Long Run Sun 77min - 10km for the first time! Total distance: 32,2km I did 5 runs this week and I broke my personal record by running a 10k for the first time!\nContent Consumption Reading Came across this reddit post:\nhttps://www.reddit.com/r/omad/comments/13a20pi/seneca_knew/?utm_source=share\u0026amp;utm_medium=ios_app\u0026amp;utm_name=ioscss\u0026amp;utm_content=1\u0026amp;utm_term=3\nThis rekindled my interest in Stoicism. I\u0026rsquo;ve always been charmed by the Stoic philosophy and I implemented many elements of it in my own spiritual practice, consciously and unconsciously. But I now feel like taking a bit more structured approach towards an exploration of Stoicism. I\u0026rsquo;m particularly interested in seeing how it overlaps with my Buddhist practice.\nThe Daily Stoic website has been on my radar for a while, but I did some reading this week and it seems like a great resource. I signed up for the daily email:\nhttps://dailystoic.com/dailyemail\nI started reading Meditations by Marcus Aurelius.\nDaily Stoic The Daily Stoic emails have been very informative and provided an excellent reading list.\nIntroduction to Stoicism:\n\u0026ldquo;A brief synopsis on this particular school of Hellenistic philosophy: Stoicism was founded in Athens by Zeno of Citium in the early 3rd century BC, but was famously practiced by the likes of Epictetus, Cato, Seneca and Marcus Aurelius. The philosophy asserts that virtue (such as wisdom) is happiness and judgment should be based on behavior, rather than words. That we don’t control and cannot rely on external events, only ourselves and our responses.\u0026rdquo;\nOther Voluntary poverty:\nhttps://stoicjourney.org/2017/01/05/seneca-part-18-voluntary-poverty/\nWatching An interesting video series about the Fjallraven brand:\nhttps://youtu.be/4mSsYK7pAow\nI\u0026rsquo;ve always been a fan of Norrona, but I\u0026rsquo;m falling head over heels in love with Fjallraven. I love the fact that they create products to last for generations. There are many instances of grandchildren inheriting pieces of gear from their grandfathers and continuing to use them.\n9 Stoic Rules For A Better Life (From Marcus Aurelius)\nhttps://youtu.be/heh5XLwZVOY\nListening Ajahn Amaro\u0026rsquo;s reading of \u0026ldquo;Being Dharma\u0026rdquo; fro Ajahn Chah\n\u0026ldquo;This is really all there is. To put the Dharma into concise, succinct terms, there is suffering born and suffering passing away. Outside of this, there is nothing else. Suffering arises; suffering passes away.\u0026rdquo;\nLinks https://roytang.net/\nhttp://sawv.org/en.html\nNext Week Goals \u0026amp; Intentions 5 runs Go for overnight camping trip OMAD Links: 202305162105\n","permalink":"https://mischavandenburg.com/zet/2023-week-19/","summary":"Week 19 It has been a good week. Very busy at work with AKS cluster maintenance, and I\u0026rsquo;ve been working some evenings.\nOn Saturday I had a lovely dinner with a good friend from Norway who was passing through Amsterdam on his way back to Oslo from a trip to France.\nRecently I started planning my holiday to Norway, and this has awakened the outdoorsman in me again. In my 9 years in Norway I became a seasoned traveler of mountains and forests, often staying out for weeks, but after I moved back to the Netherlands and focused on changing my career to IT, this outdoorsman has lain dormant.","title":"2023 week 19"},{"content":" Through YouTube I\u0026rsquo;ve been exposed to quite a bit of Japanese culture and I love many aspects of it. I love this list of habits, and I was surprised to see how many of them I already incorporate.\nClean the Toilet Many successful businessmen clean the toilet every day. It humbles you. Ajahn Chah also talks about this a lot. Check out \u0026ldquo;Toilets on the Path\u0026rdquo;. I\u0026rsquo;m also very focused on cleanliness and especially emphasize keeping my toilet clean. But I like the idea of cleaning it every day and I\u0026rsquo;m going to give it a try.\nPut your shoes away neatly Just look at how clean that looks in the video! Fortunately I also have a habit of putting them neatly on a rack I have.\nImprove your posture Investing in my Herman Miller chair has been a huge improvement to my life, and combined with yoga my posture has improved a lot over the past few months. I walk more upright and find myself correcting posture more often than before.\nThanking for meals Being grateful for all people who were involved in making that meal. The farmers, the cooks, everybody.\nBeing grateful for life.\nI can definitely improve on this and appreciate my food more.\nPut the chair back after you use it Japanese people are very concerned with other people\u0026rsquo;s feelings. Putting a chair back in a restaurant you will make the restaurant staff happy, for example. I\u0026rsquo;m usually quite considerate about these things and generally want to make the world a better place. I have a habit of thinking, \u0026ldquo;how can I make this person\u0026rsquo;s day a little better?\u0026rdquo;\nAppreciate the things you already have Don\u0026rsquo;t look at the things you don\u0026rsquo;t have, but look at what you already have.\nOkage Samade A phrase that means something to the effect of \u0026ldquo;I am good because of all the people that suppport me\u0026rdquo;. Used when someone asks \u0026ldquo;How are you?\u0026rdquo;\nGoing to bed early and waking up early. This is absolutely true. I get up at 6 every day. At 10pm I usually start winding down for bed and lights are off at 23:00. I\u0026rsquo;ve also gone through long periods of getting up at 4 or 3am, and I felt great doing so. I\u0026rsquo;m currenlty using 6am because I sometimes have social engagements that prevent me from going to bed very early.\nLinks: 202305162205\nhttps://www.youtube.com/watch?v=04wZNnjdURE\n[[my ikigai and flow]]\n[[invest-in-experiences-for-happiness]]\n[[buddhist-practice]]\n[[happiness]]\n[[miniamlism]]\n[[stoicism]]\n","permalink":"https://mischavandenburg.com/zet/8-simple-japanese-habits/","summary":"Through YouTube I\u0026rsquo;ve been exposed to quite a bit of Japanese culture and I love many aspects of it. I love this list of habits, and I was surprised to see how many of them I already incorporate.\nClean the Toilet Many successful businessmen clean the toilet every day. It humbles you. Ajahn Chah also talks about this a lot. Check out \u0026ldquo;Toilets on the Path\u0026rdquo;. I\u0026rsquo;m also very focused on cleanliness and especially emphasize keeping my toilet clean.","title":"8 Simple Japanese Habits"},{"content":" I watch the whole AI craze from the sideline: I am interested in it but I do not spend a lot of time investigating it. But I do pick up a few things here and there.\nIn this Rich Roll podcast, Kevin Kelly argues that AI does not grow exponentially. It grows linearly, but not exponentially, because it is constrained by the infrastrucutre that we give it, and are able to give it. AI cannot grow by itself. We simply cannot provide enough computing power to enable exponential growth because the technology is not advanced enough yet, which means the growth is stunted.\nThis makes the doomsday image of an all-powerful single AI that takes over the world and exterminates all humans a lot less likely.\nLinks: 202305152005\nhttps://www.youtube.com/watch?v=EKba_awaAkk\n","permalink":"https://mischavandenburg.com/zet/ai-does-not-grow-exponentially/","summary":"I watch the whole AI craze from the sideline: I am interested in it but I do not spend a lot of time investigating it. But I do pick up a few things here and there.\nIn this Rich Roll podcast, Kevin Kelly argues that AI does not grow exponentially. It grows linearly, but not exponentially, because it is constrained by the infrastrucutre that we give it, and are able to give it.","title":"AI Does Not Grow Exponentially, Thus, Less Scary"},{"content":" Happiness, Hedonic Adjustment, Experiences This was a very good video. I can honestly say that I am very happy and content, and I lead a very fulfilling life. I do not usually watch this kind of \u0026ldquo;happiness\u0026rdquo; content because I\u0026rsquo;m already happy. But this video did give me some very important insights which have influenced the way I approach money and happiness.\nMemories as Dividends The main takeaway for me is to prioritize creating memories by investing in experiences. The author phrases it very well here:\n\u0026ldquo;When you buy a shiny new car, every time you use it that shine wears of just a little bit. You hedonically adjust. With a memory, every time you think about it, you experience joy. Your brain cements the pathway to that memory, and you relive it in your brain, experiencing feelings of happines or nostalgia.\u0026rdquo;\nHedonic adjustment happens when you become used to the things you like, and you need to have bigger and better things in order to get the same satisfaction. The Stoics, among others, counteracted this with forced deprivation: eating plain bread for a few days will make you appreciate your customary food.\nAnother very clever point which Damien makes is to see money spent on experiences as dividends:\n\u0026ldquo;Experiences and memories in this way are like investments in happiness, because we can call on them to release the happiness hormones in our brains that make us feel good.\u0026rdquo;\nThey can be seen as happiness dividends. You get the initial experience and you get to re-live it again and again. And the best thing is that you don\u0026rsquo;t hedonically adjust to these memories.\nThis definitely made me re-think my approach to fincancial happiness and independence. I am definitely going to prioritize experiences a lot more in the future.\nOther Takeaways Variety and anticipation of events or smaller purchases provides a large portion of the happiness, rather than the purchase itself Make many smaller purchases rather than one big purchase Take short weekend holidays rather than a big expensive 4 week holiday Norway A case in point is my upcoming trip to Norway. Ever since I decided on the date for the trip, I noticed my energy has increased because I\u0026rsquo;m excited about the trip. I\u0026rsquo;m getting a lot of joy out of the anticipation: I\u0026rsquo;m reading up on areas to visit, going through all of my outdoor gear, and getting out into nature more because I want to connect to that Norwegian part of me. This is all rooted very deeply within me because I lived there for 9 years, and the anticipation of returning to Norway for a short time gives me so much joy.\nBy taking time off and purchasing the necesseties for my trip, I\u0026rsquo;m investing in experiences that will create memories which in turn will provide me more happiness in the future as dividends.\nLinks: 202305152005\nhttps://www.youtube.com/watch?v=840iXuXwE4Y\n","permalink":"https://mischavandenburg.com/zet/invest-in-experiences-for-happiness/","summary":"Happiness, Hedonic Adjustment, Experiences This was a very good video. I can honestly say that I am very happy and content, and I lead a very fulfilling life. I do not usually watch this kind of \u0026ldquo;happiness\u0026rdquo; content because I\u0026rsquo;m already happy. But this video did give me some very important insights which have influenced the way I approach money and happiness.\nMemories as Dividends The main takeaway for me is to prioritize creating memories by investing in experiences.","title":"Invest In Experiences For Happiness"},{"content":"I ran 10k for the first time in my life today.\nI ran to the beach and back in Heemskerk on hardened forest roads, listening to the birds and feeling the spring sun on my face. I felt great and had a smile on my face most of the time. Lots of interesting thoughts popping up in the mind as I run and reflect. Hardly noticed that 77 minutes went by because I was having such a good time.\nLinks: 202305141605\n","permalink":"https://mischavandenburg.com/zet/running-first-10k/","summary":"I ran 10k for the first time in my life today.\nI ran to the beach and back in Heemskerk on hardened forest roads, listening to the birds and feeling the spring sun on my face. I felt great and had a smile on my face most of the time. Lots of interesting thoughts popping up in the mind as I run and reflect. Hardly noticed that 77 minutes went by because I was having such a good time.","title":"I Ran 10k For The First Time Today"},{"content":"With the spring finally being fully released on the Netherlands, my wanderlust has awakened again after lying dormant for two years. In my 9 years in Norway I became a seasoned outdoorsman spending much time roaming the mountains and forests and always spending days or weeks out in the wild with my tent.\nWhen I moved back to the Netherlands this has been put on hold for a couple of years while I focused on changing my career on IT. Now that the career is rolling along nicely by the looks of it, I\u0026rsquo;m super excited to start exploring the Netherlands and see what the outdoors life is like in an area where the nature is significantly less wild and abundant.\nI needed a solution to post pictures quickly and easily because I want to start logging my trips as well. My hugo setup is great for text and techincal content but I need something where I can easily post straight from my phone and Tumblr seems like the best option. I\u0026rsquo;ll also be posting more on Instagram from here on out.\nHere is my first post:\nhttps://www.tumblr.com/mischavandenburg/717301155801235456/went-to-heemskerk-today-broke-my-running-record?source=share\nLinks: 202305141505\nhttps://www.tumblr.com/mischavandenburg\n","permalink":"https://mischavandenburg.com/zet/started-using-tumblr/","summary":"With the spring finally being fully released on the Netherlands, my wanderlust has awakened again after lying dormant for two years. In my 9 years in Norway I became a seasoned outdoorsman spending much time roaming the mountains and forests and always spending days or weeks out in the wild with my tent.\nWhen I moved back to the Netherlands this has been put on hold for a couple of years while I focused on changing my career on IT.","title":"Started Using Tumblr for Travel Blogging"},{"content":"My recent post on E/N blogging led to a realization: posting on social media will be something I do for myself, instead of doing it for others.\nWhen Facebook came out when I was 16 I posted quite a lot on social media. 5 years later I found it very embarassing to read back through those posts and I deleted everything, and since then I have been been holding back on social media posting and deleting my accounts several times.\nIn the meantime I also used social media as a marketing tool, creating very specific accounts tailored to a particular niche of content to drive traffic to websites. This approach to social media broke my relationship with it, and it became something you do to gain a certain response from others. I think this is the case for many people. Whether it is getting as much as possible likes, or getting people to click on an affiliate link, your content is always shaped by your anticipation of the audience\u0026rsquo;s reaction.\nStarting this blog has been a breakthrough for me. Especially when I gave up on my tech niche and just started writing about everything that interests me, it became a huge enrichment to my life, and I\u0026rsquo;m going to extend this to social media as well.\nThe thing is, I\u0026rsquo;ve always been very bad at taking pictures and storing them. I have tons of great experiences and memories stored in my mind, but I sometimes wish that I took more pictures of these adventures. Because I was lucky enough to have grown up in an an age without smartphones, there still is an inherent reluctance towards that whole culture. There is an irritation when I see people flipping out their phones when their meals get served in a restaurant, and I feel socially awkward to take my phone out in public to take pictures of things.\nNow I\u0026rsquo;m changing this: I\u0026rsquo;m going to take more pictures of the things I experience and post them on social media. Not because I want to impress others, but because I want to record the things I\u0026rsquo;m doing so I can enjoy them again at a later time. I arrived at this desire because I find it very enjoyable to scroll through my own blog and see the progression I\u0026rsquo;ve made over time, and the things I decided to share. And I want to extend this experience to pictures as well. So I\u0026rsquo;m going to post more on Instagram and Tumblr and write short travel logs of the places I visit and the things I experience, so I can revisit them later and find pleasure therein.\nI\u0026rsquo;m basically using these services to my own needs and completely disregard any audience. But if anybody finds enjoyment in seeing the things I put online, that would be a great thing.\nLinks: 202305141505\n","permalink":"https://mischavandenburg.com/zet/why-post-on-social-media/","summary":"My recent post on E/N blogging led to a realization: posting on social media will be something I do for myself, instead of doing it for others.\nWhen Facebook came out when I was 16 I posted quite a lot on social media. 5 years later I found it very embarassing to read back through those posts and I deleted everything, and since then I have been been holding back on social media posting and deleting my accounts several times.","title":"Why I'm Posting More on Social Media"},{"content":"Read an interesting post this morning about E/N websites. Apparently a phenomenon from the early days of the web, E/N websites meant everything to the publisher, but maybe nothing to the rest of the world. The term may have been the predecessor of the term \u0026ldquo;weblog\u0026rdquo; which was shortened to blog.\nE/N description: The website\u0026rsquo;s author covers a myriad of topics. It\u0026rsquo;s not narrowly focused. The author writes about everything or at least everything that\u0026rsquo;s important to the author. The site might contain something useful for anyone who visits. The content means everything to the publisher, but it could mean nothing to the rest of the world.\nIn this post from March I declared that I would write more about my personal life and expanding the range of topics that I would publish on my blog / zettelkasten. And it has a great decision so far.\nI thoroughly enjoy the sense of freedom it has given me. Rather than constraining myself to one subject area, I feel free to write about anything that currently interests me. Writing about these topics stimulates further research and more intentional content consumption.\nI\u0026rsquo;m sharing more and more personal content, and this is the type of content one might expect to be seen on a social media platform. I don\u0026rsquo;t use social media much, and decided to carve out my own space on the internet and write there instead. I will always be the owner of this content, and I can write about whatever I want and change the appearance and presentation.\nI can\u0026rsquo;t explain why, but there is something very satisfying about scrolling through my archives and seeing the things that caught my interest during those particular months, knowing that it is publically available and that others might be piqued by the keywords as well.\nDiscovering Roy Tang\u0026rsquo;s website was also very inspirational. I picked up the idea of sharing my week notes and logging the content consumption from his blog. Reading Hacker News regularly has exposed me to several personal blogs which I\u0026rsquo;ve added to my RSS feeds, and I enjoy reading about their interests and getting inspiration from what they decide to publish on their blogs.\nLinks: 202305090805\nhttps://roytang.net/\nhttp://sawv.org/en.html\n","permalink":"https://mischavandenburg.com/zet/everything-nothing-blog/","summary":"Read an interesting post this morning about E/N websites. Apparently a phenomenon from the early days of the web, E/N websites meant everything to the publisher, but maybe nothing to the rest of the world. The term may have been the predecessor of the term \u0026ldquo;weblog\u0026rdquo; which was shortened to blog.\nE/N description: The website\u0026rsquo;s author covers a myriad of topics. It\u0026rsquo;s not narrowly focused. The author writes about everything or at least everything that\u0026rsquo;s important to the author.","title":"My Blog Is Turning Into And Everything / Nothing Website And It Feels Good"},{"content":" I show my workflow to publish my Hugo blog from the command line using neovim and bash\nLinks: 202305091705\n","permalink":"https://mischavandenburg.com/zet/blogging-from-command-line/","summary":"I show my workflow to publish my Hugo blog from the command line using neovim and bash\nLinks: 202305091705","title":"Video: How I Write \u0026 Publish My Blog Using Neovim \u0026 Hugo From The Command Line"},{"content":"Week 18 My Week It has been a pretty good week. Rather busy at work with some unforeseen trouble for our production patching windows, which required rescheduling everything. Managed to clean up 2800 lines of code 🧹\nWent to see Sabaton and had a great time.\nOtherwise I\u0026rsquo;ve been preparing for the Diablo 2 Ladder Reset and played from Friday afternoon.\nExercise \u0026amp; Weight Loss My weight loss plateaued this week. I had two days where I overate, and I didn\u0026rsquo;t do any 5:2 fasting this week. I\u0026rsquo;m adjusting my daily calories downward to 1600 calories a day, eating only one meal a day.\nBefore I sometimes had a smaller meal at 16:00 to tide me over to dinner and to increase the protein consumption. But now I\u0026rsquo;m sticking to strict OMAD (One Meal A Day).\nI did keep up my exercise routine. The base building is going well, I set a new record by running 67 minutes today, and I didn\u0026rsquo;t have any knee pain. I went for two strength workouts as well.\nWeek 18 - 3 Easy Run 1 Mon 41min Easy Run 2 Tue 27min Easy Run 3 Wed 45min Easy Run 4 Fri 46min Easy Run 5 Sat 44min Long Run Sun 67min 8.5km Total distance: 34km Content Consumption Reading Read an interesting article on vacation in the Soviet Union:\nhttps://daily.jstor.org/workers-of-the-world-take-pto/\nhttps://mischavandenburg.com/zet/vacations-in-soviet-union/\nSome inspiration on blog writing, and writing in general:\nhttps://herman.bearblog.dev/on-writing-regularly/\nhttps://tiramisu.bearblog.dev/100-posts/\nhttps://mischavandenburg.com/zet/power-of-writing/\nFinally, an inspiring Stoic article about voluntarily simplyfying one\u0026rsquo;s fare:\nhttps://stoicjourney.org/2017/01/05/seneca-part-18-voluntary-poverty/\nWatching Videos have been centered around Diablo 2.\nFire Druid Guide:\nhttps://www.youtube.com/watch?v=xPrpXS1OJ7M\nMRLlamaSC fire druid playthrough:\nhttps://www.youtube.com/watch?v=46Toe6NF4SU\nListening Soy foods are safe to eat:\nhttps://theproof.com/are-soy-foods-safe-mark-messina-phd/\nDhamma talks by Luang Por Sumedho and readings by Ajahn Amaro\nGaming Having a lot of fun with the Diablo 2 reset. I haven\u0026rsquo;t gamed for months, but it is fun to be back at it for a little bit. Everybody is poor and people are collaborating to finish the game.\nI have a lvl 83 druid now with some very basic gear and it\u0026rsquo;s fun to learn how to use the character optimally and finding my playstyle.\nIt is tempting to make another character because everybody is so collaborative, but perhaps it is best to just stick to one character.\nNext Week I\u0026rsquo;ll have an office day on Tuesday and I have many cluster upgrades planned at work.\nI\u0026rsquo;ll be meeting a friend from Norway for dinner on Saturday evening, looking forward to that.\nPlanning on strict OMAD all week and keeping up the running base training. Otherwise I\u0026rsquo;m allowed to play Diablo 2 whenever I feel like it.\nGoals \u0026amp; Intentions Strict OMAD Stricter food logging 5+ runs Links: 202305071605\n","permalink":"https://mischavandenburg.com/zet/2023-week-18/","summary":"Week 18 My Week It has been a pretty good week. Rather busy at work with some unforeseen trouble for our production patching windows, which required rescheduling everything. Managed to clean up 2800 lines of code 🧹\nWent to see Sabaton and had a great time.\nOtherwise I\u0026rsquo;ve been preparing for the Diablo 2 Ladder Reset and played from Friday afternoon.\nExercise \u0026amp; Weight Loss My weight loss plateaued this week.","title":"2023 week 18"},{"content":"If you would have told me 5 years, 3 years, 1 year, or even 3 months ago, that one day I would be 50 minutes into a run with a big beaming smile on my face, I would have never believed you, but today it happened.\nMy base building schedule is giving me good results. I did this week\u0026rsquo;s long run this morning and it was 7 minutes longer than last week\u0026rsquo;s long run. I ran 8.5 kilometres in 67 minutes.\nAnd the best thing was: I was smiling. I was having fun. Running on an easy pace has been such a game changer for me. Sure, I\u0026rsquo;m probably the slowest runner on earth. It\u0026rsquo;s more like jogging, just a little bit faster than my speed when I do a brisk walk. But I\u0026rsquo;m running. I\u0026rsquo;m building a base, I\u0026rsquo;m doing the first steps, and from here I can grow.\nI\u0026rsquo;m also discovering another fun element to the sport: exploration. I moved to my current city less than a year ago and it is unexplored territory. I\u0026rsquo;m now creating a network of nice runs and circuits for myself and I\u0026rsquo;m discovering places I would never have discovered otherwise. Now that I\u0026rsquo;m able to run longer distances, I can start exploring more. Just running on one direction for half and hour and seeing where I end up. Then I look for a nice way back, and this way I\u0026rsquo;ve discoverd a few nice rounds already.\nToday the sun was shining, it was 17 degrees, I did the longest run I\u0026rsquo;ve ever done, and when I came back I felt good: energized, happy and satisfied. The endorphins where rushing through my body. Not exactly a \u0026ldquo;runner\u0026rsquo;s high\u0026rdquo;, I think, but definitely a sense of calm and achievement.\nLast week my knee started to hurt during my 60 minute run, but this week I had no pain at all. My body is adjusting.\nI\u0026rsquo;m coming to a point where I\u0026rsquo;m starting to fall in love with running. I just pray I won\u0026rsquo;t run into injuries!\nLinks: 202305071305\n","permalink":"https://mischavandenburg.com/zet/running-exploring-fun/","summary":"If you would have told me 5 years, 3 years, 1 year, or even 3 months ago, that one day I would be 50 minutes into a run with a big beaming smile on my face, I would have never believed you, but today it happened.\nMy base building schedule is giving me good results. I did this week\u0026rsquo;s long run this morning and it was 7 minutes longer than last week\u0026rsquo;s long run.","title":"Having Fun While Running And Exploring"},{"content":"I always thought everybody responded to stress by eating more. I was surprised to learn that many people actually stop eating when they are stressed out. This seems totally foreign to me, and this might also be why I have always been overweight.\nHuberman Podcast Notes: Stress \u0026amp; Stress Related Eating Dr. Elissa Epel: Control Stress for Healthy Eating, Metabolism \u0026amp; Aging\nStress takes enormous amoutns of resources in the body Especially ATP There is a well documented relationship between stress response and obesity. Many obese people have a higher stress response, and they have become accustomed to dealing with this stress response through eating.\nManifests as huge cravings for food which can be nearly impossible to manage, leading to binge eating.\nThere are two types of people: people who stop eating when stressed and people who start to crave when stressed.\n(I am definitely in the second cateogry without a doubt.)\nThese people have problems with satiety, cannot feel satiated and have eating disorders. They benefit from mindful eating practices and getting in touch with the physiological response to food.\nElon Musk has been on a prescriptive drug recently and lost a lot of weight.\nInterventions For Binge Eating The compulsive drive to eat is one of the strongest there can be once that pathway has developed.\nSeparating emotions from hunger\nLabeling my hunger from 1 to 10\nIs it hunger or is it boredom? Check-in before you eat\nRide the craving\nGo for walk\nDo pushups\nGet away from food\nCreating safe environments where you don\u0026rsquo;t have risky foods (already doing this)\nBody scans are very effictive to reducing craving\nPost its and phone reminders to do check-ins\nChecking the body, slow breathing\nSlow movement. qigong, yoga, slow walking\nLinks: 202305070705\nDr. Elissa Epel: Control Stress for Healthy Eating, Metabolism \u0026amp; Aging:\nhttps://podcasts.apple.com/us/podcast/dr-elissa-epel-control-stress-for-healthy-eating-metabolism/id1545953110?i=1000607079878\n","permalink":"https://mischavandenburg.com/zet/stress-eating/","summary":"I always thought everybody responded to stress by eating more. I was surprised to learn that many people actually stop eating when they are stressed out. This seems totally foreign to me, and this might also be why I have always been overweight.\nHuberman Podcast Notes: Stress \u0026amp; Stress Related Eating Dr. Elissa Epel: Control Stress for Healthy Eating, Metabolism \u0026amp; Aging\nStress takes enormous amoutns of resources in the body Especially ATP There is a well documented relationship between stress response and obesity.","title":"Podcast Notes: Responding To Stress With Eating"},{"content":" Links: 202305070805\nhttps://youtu.be/Q8dxoqqMHAg\n","permalink":"https://mischavandenburg.com/zet/video-custom-fontsize-command/","summary":"Links: 202305070805\nhttps://youtu.be/Q8dxoqqMHAg","title":"Video: Creating A Command To Change Fontsize in Alacritty"},{"content":"Diablo 2: one of those games in life I keep returning to. Started playing it when I was 12, and I know it inside out. Roughly once every 1,5 years I\u0026rsquo;ll have a phase where I want to play some.\nI\u0026rsquo;m in such a phase right now. I haven\u0026rsquo;t been gaming since the Victoria 3 release, and frankly, I don\u0026rsquo;t have much time to spend either. Something will be sacrificed. Currently this will be study time. I\u0026rsquo;ve been studying for several hours a day for nearly two years, but with my current increased focus on health and weight loss, I feel I need a break and allow myself some leasure.\nDiablo 2 Resurrected will reset tomorrow and I\u0026rsquo;ve been doing a little bit of research to get up to speed on the new Terror Zones and possible character builds. I think it\u0026rsquo;s so lovely that Blizzard came out with Diablo 2 Resurrected 1,5 years ago, and that they\u0026rsquo;re still adding new content to a nearly 20 year old game.\nTerror Zones An interesting addition to the game which will change end game levelling. From what I\u0026rsquo;ve read, they are suited to farm solo from level 92 or so. Up until then Dia/Baal runs are still most efficient.\nBuilds One of the new interesting build possibilities in D2R is the Fire Druid. When D2R was launched I played an Trap assassin and a barbarian, so it will be fun to try something new. I haven\u0026rsquo;t built a druid in many years, so I look forward to that.\nI also considered doing a war cry barbarian, javazon or summon necromancer. But the fire druid appeals most to me currently.\nLadder My plan is to just build one character, and I think I\u0026rsquo;ll keep doing that in the future. When I feel like joining a ladder reset I\u0026rsquo;ll just do one character, play it through the game, do some end game farming, and by then I\u0026rsquo;ll probably be finished with Diablo for a while again.\nDruid Strategy I\u0026rsquo;ll be playing through the game in public games. Like every reset there will be a flood of cold sorceresses, so my fire damage will be a good addition to any party. From what I\u0026rsquo;ve seen, the fire druid does a ton of damage with hardly any gear, so I probably won\u0026rsquo;t have to much low level farming. I\u0026rsquo;ll just focus on playing through the game asap and do any farming in hell difficulty.\nStats Str for gear, rest vita.\nSkills 1 point Oak Sage, and take some summons to get to grizzly. Aim for grizzly by nightmare. But don\u0026rsquo;t prioritize. I\u0026rsquo;ll be playing with parties, so probably not much need for summons, and I\u0026rsquo;ll probably have to re-cast them all the time anyway which might actually be annoying. Maybe better to just focus on the fire skills.\nFigure out which attack skill I like. Fissure can be fine through all of nightmare.\nAlzorath\u0026rsquo;s maxing path:\nFissure Armageddon Molten Boulder Volcano Firestorm\nCyclone armor: wait until you have a lot of + skills. So don\u0026rsquo;t bother\nUse quick cast The quick cast feature is something new to me. As an old school player I was resistant to this feature. But from what I\u0026rsquo;ve seen, it seems very effective with the fire skills.\nGear Tal Eth Stealth breast plate.\nOrt Sol Lore. Save a 2soc druid helm for this\nBuy 2soc staff tir ral at Akara asap.\nDual spirits\nMagefist\nLater gear Rain Armor Ort Mal Ith\nRavenlore\nLinks: 2023050414055\nAlzorath video guide: https://www.youtube.com/watch?v=xPrpXS1OJ7M\nhttps://maxroll.gg/d2/guides/druid-leveling\n","permalink":"https://mischavandenburg.com/zet/d2r-ladder-reset-may-2023/","summary":"Diablo 2: one of those games in life I keep returning to. Started playing it when I was 12, and I know it inside out. Roughly once every 1,5 years I\u0026rsquo;ll have a phase where I want to play some.\nI\u0026rsquo;m in such a phase right now. I haven\u0026rsquo;t been gaming since the Victoria 3 release, and frankly, I don\u0026rsquo;t have much time to spend either. Something will be sacrificed. Currently this will be study time.","title":"My Plan For The D2R Ladder Reset"},{"content":"Had a great time at the Ziggo Dome in Amsterdam yesterday. Went to see Sabaton live. This was my second time seeing them live, and it was a great show.\nI love Sabaton because all of their material revolves around history and warfare. They are one of my favourite bands. I was super happy they played some of my favourite songs: \u0026ldquo;Carolus Rex\u0026rdquo;, \u0026ldquo;Stormtroopers\u0026rdquo; and \u0026ldquo;To Hell And Back\u0026rdquo;.\nI\u0026rsquo;ve been a lover of metal music ever since childhood, but I had a break from metal music for about 5 years where I hardly listened to any music at all. But over the past 1,5 years I\u0026rsquo;ve been really enjoying metal music again.\nI believe the last live show I saw was Cannibal Corpse in 2014 in Oslo. Nearly 10 years without a metal concert?!\nLinks: 202305041305\n","permalink":"https://mischavandenburg.com/zet/sabaton-concert-2023/","summary":"Had a great time at the Ziggo Dome in Amsterdam yesterday. Went to see Sabaton live. This was my second time seeing them live, and it was a great show.\nI love Sabaton because all of their material revolves around history and warfare. They are one of my favourite bands. I was super happy they played some of my favourite songs: \u0026ldquo;Carolus Rex\u0026rdquo;, \u0026ldquo;Stormtroopers\u0026rdquo; and \u0026ldquo;To Hell And Back\u0026rdquo;.\nI\u0026rsquo;ve been a lover of metal music ever since childhood, but I had a break from metal music for about 5 years where I hardly listened to any music at all.","title":"Saw Sabaton Live Yesterday!"},{"content":"Next winter I\u0026rsquo;ll be entering my third year as a DevOps Engineer. When you first break into this field there is an overwhelming amount of things to learn. Frankly, this will always be the case. But I\u0026rsquo;m reaching a point where I have gained experience with most of the main areas and tooling, and I can start seeing the relations between them and how they compare to one another.\nJust like any other job or activity, there are things that you like and that suit you well, and there are things that you don\u0026rsquo;t like. And now the first phases of overwhelm are confidently behind me, I\u0026rsquo;m starting to learn the things I prefer doing over others.\nBeing a DevOps Engineer does not mean you get to write code all day. I\u0026rsquo;m currently working in an organization where we\u0026rsquo;re not working fully DevOps yet. Rather than deploying many times in small increments, we are still using patching windows. Managing infrastructure in this way means you\u0026rsquo;ll need to communicate with teams to schedule the patching and submit changes to the approval board. It can involve a lot of emailing and talking back and forth. And sometimes things go wrong and everything needs to be rescheduled again. Although it is valuable experience, and I certainly have the communication skills to handle these kinds of situations, I\u0026rsquo;m learning that I lean more towards the dev side of things.\nToday was a fun day at work. I\u0026rsquo;ve been working on a PR for a while whenever I wasn\u0026rsquo;t required to work on tickets. The PR involved refactoring a Bicep template for our Azure Key Vault deployments, which were using parameter files with a lot of repeated code. After getting a lot of good feedback on my code changes, and submitting it for review multiple times, it was finally approved and I could get to work.\nI used bash, jq and vim to clean up the parameter files for each workload and submitted PRs. My colleague, who helped me with the PR\u0026rsquo;s, was standing by and ready to approve them as soon as I submitted them. Some pipelines ran into some trouble and required a few more PR\u0026rsquo;s to fix, and there was a bit of pressure because we needed to get the pipelines working before any other changes needed to be deployed the next day.\nBy working together like this we managed to clean up 2850 lines of code in one day and it was a great feeling to get this job done. I had been working on this for a couple of weeks and it\u0026rsquo;s so satisfying to move that ticket status to \u0026ldquo;done\u0026rdquo;.\nI really enjoy the coding! And I really enjoy working with Infrastructure as Code! Somehow it really gives me a lot of pleasure knowing that the code I\u0026rsquo;m writing will be transformed to running infrastructure after it is submitted. I love writing programs in my free time as well, but there is just something magical seeing your parameter file being turned into a functional Kubernetes cluster or Key Vault.\nWorking as a DevOps Engineer, I\u0026rsquo;m generally having so much fun. I really enjoyed myself when I was learning jq and used scripts to change hundreds of lines of code at a time and submitting them as a PR. And some days, the work is less enjoyable, but it is all part of the job. It all serves to deliver value to the end customer, and if I can have fun most of the time while delivering value, I know I\u0026rsquo;m in the right place.\nIn any case, there hasn\u0026rsquo;t been a second during these past two years where I regretted my choice of becoming a DevOps Engineer. I love my job, I found my passion in my work, and I\u0026rsquo;m so excited for the future. Cloud computing is never standing still, Kubernetes is starting to become more and more popular, and my skills grow with every day that passes.\nI\u0026rsquo;m a happy camper.\nLinks: 202305042005\n","permalink":"https://mischavandenburg.com/zet/ups-and-downs-of-devops-engineer/","summary":"Next winter I\u0026rsquo;ll be entering my third year as a DevOps Engineer. When you first break into this field there is an overwhelming amount of things to learn. Frankly, this will always be the case. But I\u0026rsquo;m reaching a point where I have gained experience with most of the main areas and tooling, and I can start seeing the relations between them and how they compare to one another.\nJust like any other job or activity, there are things that you like and that suit you well, and there are things that you don\u0026rsquo;t like.","title":"The Ups And Downs Of A Devops Engineer"},{"content":"Read an interesting article this morning. Apparently the Soviet Union introduced paid time off well before other industrialized countries.\nInterestingly, but not unexpectedly, the state determined how and with whom you spent that vacation.\nAs members of a collective, citizens were expected to spend their free time in a manner the government and its leading theorists considered beneficial to society as whole, regardless of an individual’s preferences.\nEver since the 1930s, it had been customary for Soviet citizens to travel in groups of 25 to 40 people randomly put together by their trade unions. When adults relaxed at resorts or embarked on tours, their children were sent to summer camps managed by state-run youth groups like the Young Pioneers or the Komsomol.\nThis reveals the dedication to the collective rather than the family.\nSoviet vacations served as teambuilding exercises that fostered group cohesion. The closer people got with their family, the further they removed themselves from their neighbors, colleagues, and government.\nIt seems unthinkable to not be in control of your own vacation to me, born in the West in 1990. Communism, the Soviet Union, and totalitarian regimes, somehow always seem to spark my interest. It is one way of organizing a society, and in some ways it seems like an attractive one. I think it has to do with the sense of purpose that living in such a society might give you. The Collective is most important, and that\u0026rsquo;s what you live for. In theory it is a selfless way of living. But history shows that it has always failed up until now.\nI\u0026rsquo;m planning this year\u0026rsquo;s vacation at this moment, I\u0026rsquo;ll be returning to my beloved Norway for three weeks in September. And I\u0026rsquo;m so glad that I can decide to go there alone, instead of having to go with a group of 40 strangers.\nLinks: 202305020605\nhttps://daily.jstor.org/workers-of-the-world-take-pto/\n","permalink":"https://mischavandenburg.com/zet/vacations-in-soviet-union/","summary":"Read an interesting article this morning. Apparently the Soviet Union introduced paid time off well before other industrialized countries.\nInterestingly, but not unexpectedly, the state determined how and with whom you spent that vacation.\nAs members of a collective, citizens were expected to spend their free time in a manner the government and its leading theorists considered beneficial to society as whole, regardless of an individual’s preferences.\nEver since the 1930s, it had been customary for Soviet citizens to travel in groups of 25 to 40 people randomly put together by their trade unions.","title":"Vacations In The Soviet Union"},{"content":"Ah, writing. It\u0026rsquo;s one of the skills that I\u0026rsquo;ve consistently been praised for throughout my life. I\u0026rsquo;m pretty good at it, and I think that\u0026rsquo;s because I enjoy it. It led me to getting an academic degree in English Literature and Culture, simply because I was following the things I was naturally good at.\nHowever, just like any other skill, you can only become better at it through consistent practice. This morning I read a wonderful little blog post on writing regularly, and I was touched by his words:\nSimilarly, some people believe that the art of writing is a skill that can be summoned on a whim, like a genie emerging from a lamp with a flourish of creative brilliance. In my experience, however, writing is more akin to the labour of a blacksmith, hamming words into shape through the heat and sweat of regular practise.\nDaily Practice One way to gain more experience is to start keeping a daily journal. I\u0026rsquo;ve always kept some notebook or other, jotting down thoughts and ideas as they came along sporadically. But it was only in July 2020 that I started to keep a daily journal and writing regularly. I started out writing by hand. I was in at an interesting place in life: I was spending two years in a Buddhist monastery, and after settling down for a couple of months, the intensive meditation practice was releasing all sorts of things in the mind and body, and I started to write them all down. I\u0026rsquo;m still convinced that starting this habit has been one of the most important and beneficial decisions of my life.\nIt is so simple, but extremely effective. And you don\u0026rsquo;t have to be doing anything special, or be in a special place. Just keeping a daily journal where you note down the things you did that day in a small pocket book is enough to get the habit going. Soon you will find that you will get the urge to write more. After several years of daily journaling, sometimes all I write is \u0026ldquo;It\u0026rsquo;s been a pretty good day\u0026rdquo;. And that\u0026rsquo;s it for that day. Sometimes I write several pages worth of thoughts, ideas and these longer writings often have powerful effects.\nThe Power Of Writing Sometimes I\u0026rsquo;ll be struggling with something, and I\u0026rsquo;ll be at a loss of what to do. The thoughts just keep whirling about aimlessly and no solution to the particular problem at hand seems to emerge from the chaos. Whenever I am in such a situation, I sit down, close my eyes, observe what is going on, and I start to write. I write it all down. The thoughts, the associations that these thoughts generate, and the effects they are having. I write down exactly how I feel. Attaching words to the feelings that I\u0026rsquo;m experiencing mentally and physically. \u0026ldquo;I feel a contraction in my lower abdomen\u0026rdquo;. \u0026ldquo;I\u0026rsquo;m angry, and it manifests as a hot feeling on my forehead\u0026rdquo;. And that\u0026rsquo;s when the magic happens: something that I\u0026rsquo;ve come to identify as \u0026ldquo;The Power Of Writing\u0026rdquo;.\nSomehow the act of writing everything down will create structure in the chaos, and the solution to my problem wil emerge, often from very unexpected angles. Is it the fact that it is structured on paper? Or the fact that the visual representation of the contents of my mind enables me to apply structure to them? Is it the fact that I am moving my hands, adding bodily movement to my cognitive efforts?\nI don\u0026rsquo;t have the exact answer, but all I know is that it works for me. Almost every time. And often when I don\u0026rsquo;t expect it at all. I\u0026rsquo;ll just be sitting and writing in my journal, writing down a particular challenge that I\u0026rsquo;m facing that day. And somehow some solution appears out of the blue. Whenever this happens, I always smile and write down: \u0026ldquo;The Power of Writing\u0026rdquo;.\nMindfulness Even though I might not know the exact answer, I\u0026rsquo;m certain that it is very closely related to mindfulness. Becoming more mindful through meditation and present moment awareness is the key to happiness in my opnion. I developed a mindfulness practice out of writing by creating this ritual where I sit down and identify what is going on and writing it down. In essence, I\u0026rsquo;m forcing myself to be mindful, and to attach words to my mental and bodily experience. I\u0026rsquo;m getting out of my own way and letting my mind solve the challenge all by itself.\nYou know what? It\u0026rsquo;s happening right now! The Power of Writing. I hadn\u0026rsquo;t been able to clearly capture in words what the mechanism behind the Power of Writing was, but as I was writing this article, it became obvious to me that it must be mindfulness underlying it all. So I\u0026rsquo;m just going to leave it as it is. This is a perfect example of what you will find in my private zettelkasten. I wrote all of this in one sitting, with minimal editing. Just stream of conciousness, writing it down. And I finished with a wonderful realization.\nI feel grateful, satsified and happy. There is also a pleasant tingling at the top of my neck, and an energy rising up through my feet. I hope that this might help someone else one day, and inspire someone to pick up the habit of writing.\nLinks: 202305012005\nhttps://herman.bearblog.dev/on-writing-regularly/\n","permalink":"https://mischavandenburg.com/zet/power-of-writing/","summary":"Ah, writing. It\u0026rsquo;s one of the skills that I\u0026rsquo;ve consistently been praised for throughout my life. I\u0026rsquo;m pretty good at it, and I think that\u0026rsquo;s because I enjoy it. It led me to getting an academic degree in English Literature and Culture, simply because I was following the things I was naturally good at.\nHowever, just like any other skill, you can only become better at it through consistent practice. This morning I read a wonderful little blog post on writing regularly, and I was touched by his words:","title":"The Power of Writing"},{"content":"I started my weight loss journey in December 2021 on 97,7kg and steadily dropped weight over the following year.\nI achieved this by intermittent fasting and cutting out junk food as the first main intervention. I was already used to eating only 8 hours a day, but I experimented with shortening this window and doing 36 hour or 48 hour fasts.\nEventually I plateaued, and there was no way around it: I needed to start tracking calories strictly. I made a habit of weighing all of my food and entering it to an app (YAZIO). Periods of weight loss strictly correlate with my adherence to this practice.\nThe weight loss plateaued in 2022/2023.\nEven though I kept bouncing back up when I reached 76kg, I\u0026rsquo;m still really satisfied that I managed to keep the weight off so far.According to Layne Norton in his book \u0026ldquo;Fat Loss Forever\u0026rdquo;, only 5% of people who undertake weight loss journeys actually manage to keep the weight off.\nThe main intervention for me here is to weigh myself daily. I\u0026rsquo;ve gone from periods where I was strictly counting calories to periods where I was eyeballing things and trying to eat intuitively, leading to weight gain. But as soon as I started creeping to the 80kg mark, I knew I had to reign myself in again.\nCurrent Goal Although I\u0026rsquo;m happy I\u0026rsquo;m managing to keep the weight off, I\u0026rsquo;m not satisfied with my current weight. My goal is to reach 10% body fat. I realized that simply \u0026ldquo;losing weight\u0026rdquo; was not going to cut it anymore because I kept bouncing back up. I needed to become more intentional about my weight loss.\nI did some insightful research on goal setting and realized that I needed to set a clear goal within a timeframe and track the progress towards that goal. Huberman\u0026rsquo;s Podcast episode on goal setting was very enlightening here.\nAgain my weight creeped up from 76kg to 80kg and I decided I had enough.\nSince my breakpoint always seems to be 76kg, I set my goal to 75kg within a time frame of 2 months.\nMy starting weight was 78.6kg and this morning I weighed in at 77.3kg. So far it\u0026rsquo;s working, it\u0026rsquo;s about 0,5kg a week which is a healthy amount to lose in a week\u0026rsquo;s time.\nI made this little sheet which hangs on my kitchen cupboard, and every day I mark whether I adhered to my calorie target of 1700kcal +/- 100kcal. The squares indicate a day where I do a 500kcal fasting day.\nCurrent Weight Loss Interventions Calorie target: 1700kcal Two meals a day in a 4 hour eating window 20 hours of fasting a day Strictly tracking all calories, even when overeating 5:2 pattern: two days of fasting a week where I eat a small meal of 500 calories Running 5+ times a week Two ring workouts a week When I list them all out, it seems extreme that I need this many interventions to lose those last few kilograms of fat. But apparently it is all necessary. If/when I start losing more than 0.5kg a week I\u0026rsquo;ll know I can reduce the intensity by increasing my calorie target.\nAccountability When I made this sheet I shared it with my brother and a few friends for external accountability. So far I\u0026rsquo;ve just been doing my journey alone, but as I got stuck at around 77kg, I upped the ante and started to involve others. It really helps to stick with the program. It would be very embarassing to make this kind of commitment and not sticking with it.\nNow that I\u0026rsquo;m two weeks in, and the results are starting to show, I decided to make it completely public and post it on my blog. So we\u0026rsquo;ll see in two months if I\u0026rsquo;m making a fool out of myself or not 🥲\nLinks: 202304300804\nhttps://hubermanlab.com/the-science-of-setting-and-achieving-goals/\nhttps://www.youtube.com/watch?v=zkY6MM_dLo4\u0026amp;t=18s\u0026amp;pp=ygUJdGFvIHJpbmdz\nhttps://www.amazon.com/Fat-Loss-Forever-Lose-KEEP/dp/1794510109\n","permalink":"https://mischavandenburg.com/zet/weight-loss-journey/","summary":"I started my weight loss journey in December 2021 on 97,7kg and steadily dropped weight over the following year.\nI achieved this by intermittent fasting and cutting out junk food as the first main intervention. I was already used to eating only 8 hours a day, but I experimented with shortening this window and doing 36 hour or 48 hour fasts.\nEventually I plateaued, and there was no way around it: I needed to start tracking calories strictly.","title":"🍎 My Weight Loss Journey And Current Goal 📉"},{"content":"Week 17 Reflection It has been a good week. Thursday was a public holiday: King\u0026rsquo;s Day. I spent it working on my new setup for making YouTube videos and doing a few chores. I let the festivities pass me by. I am more of a recluse. When I was younger I sometimes went to Amsterdam and joined the festivities. But now I derive no pleasure from large crowds of people consuming a lot of alcohol any longer.\nExercise \u0026amp; Weight Loss I\u0026rsquo;m making good progress on my current weight loss goal. Here are the results since I started my latest weight loss period:\n2023-04-16 Waist circumference: 83cm\n78.6kg\n17,5% Body Fat\n2023-04-23 82.3cm\n78.2kg\n16.9%\n2023-04-30 77.3kg\n81cm\n16,4%\nThe weight loss goal is currently taking up most of my head space. It takes a lot of effort to stay on track, fight off cravings and to consistently plan and weigh all of my food. However, 2 weeks into the regime, these actions are now slowly starting to become more habitual. Eventually this will become the new norm, and it will start happening automatically, costing less energy.\nBut I\u0026rsquo;m very happy to see that I lost 1kg and 1cm from the waist.\nRunning I completed week 2 of my base building schedule, and I\u0026rsquo;m making progress.\nWeek 16 - 1 Easy Run 1 Mon 30min Easy Run 2 Wed 43min Easy Run 3 Thu 36,5min Easy Run 4 Sun 43min Long Run Fri 50min Total distance: 26.15km Week 17 - 2 Easy Run 1 Mon 37min Easy Run 2 Tue 40min Easy Run 3 Wed 44min Easy Run 4 Thu 36min Long Run 5 Sat 60min Total distance: 28.09km Content Consumed Reading I recently finished Can\u0026rsquo;t Hurt Me by David Goggins which was very inspirational. Should write some notes on that soon.\nThen I continued with Finding Ultra by Rich Roll. Enjoying it a lot so far.\nI also started re-reading one of the best books on Buddhist practice in my opinion: Uncommon Wisdom by Ajahn Pannavadho. I\u0026rsquo;ve read this book 4 times already, but it is gold every single time.\nI increased my meditation practice from 20 minutes to 40-90 minutes a day to help with food cravings and resting the mind. Ajahn Panna\u0026rsquo;s emphasis on identifying discontentment and kilesas is a great aid in my practice currently.\nWatching I saw this video a year ago and it (re-)kindled the desire to start running. I\u0026rsquo;ve been watching it a few times for motivation and inspiration.\nI also watched a few videos on Diablo 2 Resurrected to prepare for the upcoming ladder reset. I don\u0026rsquo;t really have time to game, but the ladder reset is always a fun time because everybody is poor and there is a better community spirit going on. I decided to make a character and do a playthrough to wind down a bit from the weight loss efforts.\nThere have been many changes to the game and it is fun to catch up on Terror Zones and the new runewords, and the new builds they enable.\nListening I listened to The Golden Rules of Success, but not much to take away from there.\nOtherwise I\u0026rsquo;m in a Dhamma phase, with increased meditation, so I\u0026rsquo;ve only been listening to Ajahn Amaro\u0026rsquo;s daily reflections and the most recent talks by Ajahn Sumedho.\nhttps://podcasts.apple.com/nl/podcast/amaravati-podcast-latest-dhamma-talks/id336829720\nLinks Next Week The upcoming week has a few intersting events:\nSabaton concert on Wednesday evening. Looking forward to that! Diablo 2 Resurrected Ladder season 3 starts on Thursday rwxrob\u0026rsquo;s 2023 Beginner Boost starts on Thursday Other than that my main goals and intentions are:\nSticking to the program 5 runs: 4 short 1 long Continue meditating 40-90 minutes a day Links: 202304301004\n","permalink":"https://mischavandenburg.com/zet/2023-week17/","summary":"Week 17 Reflection It has been a good week. Thursday was a public holiday: King\u0026rsquo;s Day. I spent it working on my new setup for making YouTube videos and doing a few chores. I let the festivities pass me by. I am more of a recluse. When I was younger I sometimes went to Amsterdam and joined the festivities. But now I derive no pleasure from large crowds of people consuming a lot of alcohol any longer.","title":"2023 Week 17"},{"content":"For the past few months I\u0026rsquo;ve been using this neat API to check the weather from the command line. It\u0026rsquo;s very simple to use. Simply run:\ncurl wttr.in\nThis will show the weather based on your location, but you can also give a particular location and format.\ncurl wttr.in/Amsterdam\nLinks: 202304271504\nhttps://github.com/chubin/wttr.in\n","permalink":"https://mischavandenburg.com/zet/check-weather-terminal/","summary":"For the past few months I\u0026rsquo;ve been using this neat API to check the weather from the command line. It\u0026rsquo;s very simple to use. Simply run:\ncurl wttr.in\nThis will show the weather based on your location, but you can also give a particular location and format.\ncurl wttr.in/Amsterdam\nLinks: 202304271504\nhttps://github.com/chubin/wttr.in","title":"How To Check The Weather From The Command Line"},{"content":" I use RSS feeds to read the news, and I use Newsboat as a RSS reader.\nTo in stall on MacOS: brew install newsboat\nIntegrate in already existing terminal workflow Free from distraction Control how content is rendered Carefully curate which content you consume Build your own \u0026ldquo;Social Media feed\u0026rdquo; No advertisements or suggested articles Newsboat uses RSS feeds which are generated by websites Links: 202304271004\nhttps://newsboat.org/\n","permalink":"https://mischavandenburg.com/zet/reading-news-from-command-line/","summary":"I use RSS feeds to read the news, and I use Newsboat as a RSS reader.\nTo in stall on MacOS: brew install newsboat\nIntegrate in already existing terminal workflow Free from distraction Control how content is rendered Carefully curate which content you consume Build your own \u0026ldquo;Social Media feed\u0026rdquo; No advertisements or suggested articles Newsboat uses RSS feeds which are generated by websites Links: 202304271004\nhttps://newsboat.org/","title":"Video: How To Read The News From The Command Line"},{"content":"It\u0026rsquo;s now possible to abort long running operations on AKS clusters. It was released as Generally Available.\nFor example:\naz aks operation-abort --name myAKSCluster --resource-group myResourceGroup\nLinks: 202304270704\nhttps://azure.microsoft.com/en-us/updates/generally-available-operation-abort-in-aks/\nhttps://learn.microsoft.com/en-us/azure/aks/manage-abort-operations?tabs=azure-cli\n","permalink":"https://mischavandenburg.com/zet/aks-abort-operation/","summary":"It\u0026rsquo;s now possible to abort long running operations on AKS clusters. It was released as Generally Available.\nFor example:\naz aks operation-abort --name myAKSCluster --resource-group myResourceGroup\nLinks: 202304270704\nhttps://azure.microsoft.com/en-us/updates/generally-available-operation-abort-in-aks/\nhttps://learn.microsoft.com/en-us/azure/aks/manage-abort-operations?tabs=azure-cli","title":"You Can Abort Operations on AKS Clusters Now"},{"content":"I started running on the 13th of February 2023. I ran 1.2 kilometres in 9 minutes. Slowly I built it up to my first 5k which I ran on the 23th of March 2023.\nAfter I discovered a new potential within me now that I lost so much weight, I felt I needed some more structure towards my running training. Reddit, as always, comes to the rescue. On the r/running subreddit I discovered base training.\nI focused completely on the distance ran while slowly working my way up to 5 kilometres. Base training, however, made me focus on the duration of the runs. This was quite an eye opener and changed my perspective.\nThe idea is that the duration is much more important for beginners because they experience more stress on the body while running. An experienced runner might finish 10 kilometres in 30 minutes, but a beginner will experience a lot more stress on the body doing 30 minutes of running on an easy pace because there are more foot strikes occurring and because the body is unadapted. The beginner first needs to build up strength in the legs and resistance in the joints and tissues.\nSo far it has been a good experience. I like the idea of running more often, but not pushing myself every single run. The schedule also allows for variation. Some days are easier than others, so it feels good to have the opportunity to go for only a short 30 minute run on the days where I\u0026rsquo;m not feeling up to it.\nHere are the results of my first week:\nWeek 16 - 1 Easy Run 1 Mon 30min Easy Run 2 Wed 43min Easy Run 3 Thu 36,5min Easy Run 4 Sun 43min Long Run Fri 50min Total distance: 20.59km Goal I currently don\u0026rsquo;t have a particular goal in mind. I have a knee injury which started to flare up again when I started running. So far the body has adapted, and the knee stopped hurting. I\u0026rsquo;m going to follow this program for 6 weeks, adding 5 minutes (or more if I feel good) per week to my long run, and see where this takes me.\nLinks: 202304241704\nhttps://www.reddit.com/r/running/comments/3bckeh/base_training_a_guide_to_your_foundation_to/\n","permalink":"https://mischavandenburg.com/zet/base-training-running/","summary":"I started running on the 13th of February 2023. I ran 1.2 kilometres in 9 minutes. Slowly I built it up to my first 5k which I ran on the 23th of March 2023.\nAfter I discovered a new potential within me now that I lost so much weight, I felt I needed some more structure towards my running training. Reddit, as always, comes to the rescue. On the r/running subreddit I discovered base training.","title":"Base Training For Running: Time Instead Of Distance"},{"content":"Over the past two months I\u0026rsquo;ve increased the amount of exercise quite a lot. Over the past year or so I\u0026rsquo;ve been doing Brazilian Jiu Jitsu 1-2x a week and going for a 30-90 minute walk every day.\nAfter I started running in February I have quit BJJ and changed to running 5-6 times a week, 30-60 minutes of Ashtangha Yoga almost every day and two calisthenics workouts a week. For my calisthenics I use rings and I do squats in the gym .\nIn addition, I reduced my calories to 1700 calories a day spread over two meals, doing 20 hours of fasting a day. I have also eliminated all sugar from my diet.\nThe reason I needed to do this is because my weight loss has plateaued for several months and I have at least 3kg more fat to lose until I reach my goal of 10% body fat.\nMost people know me as someone who is very productive and frugal with his time, and that\u0026rsquo;s true. I\u0026rsquo;m always studying, writing, creating or learning in my free time. There is little to no time for girls and video games, I\u0026rsquo;m on my purpose.\nYet I am also aware of the need of rest and relaxation. I haven\u0026rsquo;t written much about it on my blog, and this will probably change in the time to come, but I am an established meditator and have a very solid mindfulness practice. I\u0026rsquo;ll notice very quickly when I get out of balance and fortunately my practice has provided me with the wisdom to know what to do to bring things back into balance again.\nHaving introduced an increased amount of exercise and mental stress due to caloric restriction, I saw I needed to take a few steps back and allow my body and mind to adjust to these changes. I was already on caloric restriction and fasting 18 hours a day, but still I noticed I needed time to adjust.\nTo adjust I allowed myself to take a break from evening tech study and homelabbing and read some fiction instead, and I increased my meditation practice. Stilling the mind with breath meditation is helping me to deal with very intense food cravings. Quitting sugar is definitely no walk in the park.\nI have made these kinds of changes many times before, and I know that after a while my body and mind are used to it and I can go back to my old routine again. Having a daily meditation practice gives me the tools to check in with myself. I am very grateful to myself that I put in the hard work over the past 6 years to get an established daily practice. I am also extremely grateful to my teacher and the Buddhist community who supported me while I spent time in a monastery in Norway.\nLinks: 202304242004\n[[buddhist-practice]]\n[[meditation]]\n","permalink":"https://mischavandenburg.com/zet/importance-rest-changes/","summary":"Over the past two months I\u0026rsquo;ve increased the amount of exercise quite a lot. Over the past year or so I\u0026rsquo;ve been doing Brazilian Jiu Jitsu 1-2x a week and going for a 30-90 minute walk every day.\nAfter I started running in February I have quit BJJ and changed to running 5-6 times a week, 30-60 minutes of Ashtangha Yoga almost every day and two calisthenics workouts a week. For my calisthenics I use rings and I do squats in the gym .","title":"Importance Of Rest And Meditation When Making Changes To Routine"},{"content":"This week I started a project which I\u0026rsquo;ve been putting off for too long. I finally started my homelab. Over the past year I\u0026rsquo;ve been collecting hardware here and there, and I\u0026rsquo;ve had the intention to start up a proper Kubernetes cluster at home. I got inspired by Rob Muhlenstein\u0026rsquo;s Homelab Init playlist on YouTube which I\u0026rsquo;m working on.\nThere are a few reasons why I haven\u0026rsquo;t started up until now:\nFocused on switching jobs and certifications Not knowing what to run on the cluster High electricity costs Now that I found a new job with a great employer, I\u0026rsquo;ve changed my focus towards doing more hands-on learning in my free time by learning Go and diving deeper into Cloud Native technology. Energy prices have come down in the meantime as well.\nI\u0026rsquo;ve reached a stage in my Go learning journey where I\u0026rsquo;m actually able to start making small deployable applications, and I want an environment where I can do that without high costs or without fearing to break something. I want to learn more about databases on Kubernetes, and I want to start writing small microservices and API\u0026rsquo;s that are able to query these databases.\nMy lab is going to be my playground, where I can deploy whatever I want and learn the technologies that interest me at that particular moment.\nHardware: Parts For some reason the Raspberry Pi has become synonymous with homelabs. I get that it\u0026rsquo;s fun to run a cluster on something that is not much larger than a 1kg pack of sugar. But I never really caught on to that whole scene yet. Maybe it\u0026rsquo;s because I\u0026rsquo;m a bit late to the party and the Pi\u0026rsquo;s have been scarce and very expensive lately?\nIn any case, I\u0026rsquo;ve been thankfully accepting old computers that friends were going to get rid of, and I\u0026rsquo;ve been keeping some of my own old hardware as well. I have enough motherboards and other parts to assemble around 3 nodes, which will probably have around 8GB RAM each, but possibilities to attach storage.\nThis is also what has been keeping me back for a while I think. There is quite a bit of work that I need to do to get these machines going, and probably I\u0026rsquo;ll have to purchase a couple of other parts. However, I also have some functional hardware.\nGaming Desktop I have an old gaming desktop with 16GB RAM, an Intel 6700K Skylake, 1070 video card and a couple of TB of storage.\nThis has been my Arch Linux desktop for the past year, but now that I switched to my new MacBook, I\u0026rsquo;m not using it as much. I want to keep it as it is right now, but I could run a few Virtual Machines on there, and maybe consider turning it into a ProxMox server.\nOld Laptops I have two old laptops. One Asus with 4GB of RAM and a Thinkpad T430 with 8GB RAM. The Thinkpad is actually surprisingly powerful. As a weekend project I installed Arch on it and I fitted it with a refurbished keyboard, and it is a very pleasant machine to work with. However, now that I have a very powerful laptop that I use as a desktop and portable device, it has become redundant.\nOld Laptops as Raspberri Pi\u0026rsquo;s Having these two old laptops lying around, it occurred to me that these machines were basically Raspberri Pi\u0026rsquo;s with a large form factor and a higher power usage. Why would I need to spend hundreds of euros on these smaller computers if I could just use these laptops as a starting point for my lab?\nUsing laptops has the following advantages:\nNo additional costs No building needed Easy to install Linux on them Built-in screen and keyboard for quick access when SSH does not work out Built-in batteries to handle short power disruptions (rare but possible) Can get going very quickly Choices and Goals Kubernetes The first goal is to get a Kubernetes cluster running. I will do bare metal kubeadm installs, and later I want to learn more about Talos. Fortunately I feel very comfortable installing Kubernetes with kubeadm. I did plenty of practice for my CKA, and I recently installed it on free Oracle VM\u0026rsquo;s. I\u0026rsquo;ve experimented a bit with K9S earlier, but I want to learn how to maintain on-prem Kubernetes.\nMy goals is to learn to maintain production-grade clusters properly.\nLinux Naturally I\u0026rsquo;ll be using Linux as my base OS. After some consideration I chose to use Ubuntu Server 22. Some notes on that choice:\nI already have years of Ubuntu Server experience Good to keep building on what I have Working with managed Kubernetes on my day job requires me to keep Linux admin skills fresh Still the most popular Linux distro Google uses Ubuntu Server Well documented and plenty of questions on StackOverflow Infrastructure as Code \u0026amp; GitOps Initially I\u0026rsquo;ll configure the servers by hand, but I want to have the server configuration as code as Ansible playbooks eventually. However, I\u0026rsquo;ll be using ArgoCD for all of my deployments on Kubernetes itself, so the server configuration is only a very small part of the setup. Just get Kubernetes running and do the rest with ArgoCD.\nPerhaps I will expand with larger servers that run multiple VM\u0026rsquo;s. Then it will be very relevant to start provisioning these with Ansible.\nNetworking I want to learn more about networking and use static IP addresses for my servers. I need to figure out how my home network works exactly. Surprisingly, I\u0026rsquo;ve never taken the effort to actually know how the devices on my network get their IP addresses and how they communicate, even though I\u0026rsquo;ve learned plenty about it for my day job and do networking in an enterprise environment daily.\nFor Kubernetes I\u0026rsquo;ll use Flannel to start out with, but I want to learn more about Cilium, Istio and other service mesh implementations.\nAnother goal is to host my own DNS server for internal name resolution, probably CoreDNS.\nDeployment I want to host my own container registry (Harbor) and use Tekton pipelines to for CI/CD, and I\u0026rsquo;m playing with the thought to host my own GitLab instance as well.\nLet\u0026rsquo;s Go! Another realization was that I don\u0026rsquo;t need to have everything figured out before I begin. The beauty of cluster computing is that you can add to it as you go. I can start with a small cluster of two nodes and build it out as my needs grow. I don\u0026rsquo;t expect to need more than a few GB of RAM in the foreseeable future, so these two laptops will be plenty to get going.\nLinks: 2023041213\n[[homelab]]\n[[homelab-network]]\n[[linux]]\n[[homelab-ubuntu-server]]\n[[kubernetes]]\n","permalink":"https://mischavandenburg.com/zet/starting-my-homelab/","summary":"This week I started a project which I\u0026rsquo;ve been putting off for too long. I finally started my homelab. Over the past year I\u0026rsquo;ve been collecting hardware here and there, and I\u0026rsquo;ve had the intention to start up a proper Kubernetes cluster at home. I got inspired by Rob Muhlenstein\u0026rsquo;s Homelab Init playlist on YouTube which I\u0026rsquo;m working on.\nThere are a few reasons why I haven\u0026rsquo;t started up until now:","title":"Starting My Homelab"},{"content":"The Tour of Go is very clear:\nGo does not have classes.\nOne benefit of learning multiple programming languages is that each language provides you with a set of “pegs” that you can use to refer to other languages. As I learned about structs in Go, I hung them to the “Python classes” peg and used that as a reference point. Using these reference points can help you to understand the object of study by looking at their differences and similarities.\nEven though Go does not have classes, my understanding of Python classes did help me to understand structs much more quickly.\nGo Structs A struct is a collection of fields, and they are accessed using a dot.\nEach data field in a struct has its own type, either user defined or built in.\ntype Person struct { name string address string } person1 := Person{\u0026#34;Mischa\u0026#34;, \u0026#34;Amsterdam\u0026#34;} fmt.Println(person1.name) fmt.Println(person1.address) When creating a struct, you can use the Name: syntax to set the values. Otherwise, you need to populate the fields in order.\ntype Computer struct { os string ram int } func main() { macBook := Computer{os: \u0026#34;MacOs\u0026#34;} fmt.Println(macBook) thinkPad := Computer{\u0026#34;Arch Linux\u0026#34;, 16} fmt.Println(thinkPad) } This produces the output:\n{MacOs 0} {Arch Linux 16} In the first line, the ram is 0 because I only set the os field, and unset fields get a 0 value by default.\nStruct Methods Classes in Python can contain methods. What about Go structs?\nStructs can have methods, but they are not contained in the struct definition, like you would see in Python. Methods are defined on types, and the type does not need to be a struct. Therefore, methods are defined after you create the struct.\ntype Computer struct { os string ram int } func (c Computer) doubleRam() string { return fmt.Sprintf(\u0026#34;If you would double your ram, you would have %v GB of ram.\u0026#34;, c.ram * 2) } func main() { macBook := Computer{\u0026#34;MacOs\u0026#34;, 32} fmt.Println(macBook.doubleRam()) } Output:\nIf you would double your ram, you would have 64 GB of ram.\nIn this example, doubleRam() is my method of the Computer type. Methods take a special receiver argument, written between the func keyword and the method name. The doubleRam method has a receiver of type Computer, named c.\nStruct Literal A struct literal is a struct which has its contents defined in the source code itself. The opposite would be to generate the contents of the struct through computation or reading memory during the execution of the program.\nConclusion In conclusion, here are the similarities and differences that stood out to me in this morning\u0026rsquo;s study of Go structs.\nSimilarities Both can have fields to hold values of different types Both can have methods Differences Go structs are used for data structures, classes in Python are used for OOP Go struct fields have static types Methods are defined separately from the struct definition Links: 202304100704\n[[go]]\n[[data-types]]\nhttps://go.dev/tour/moretypes/2\nhttps://go.dev/tour/methods/1\nhttps://articles.wesionary.team/map-vs-struct-in-golang-when-to-use-b0b66446627a\n","permalink":"https://mischavandenburg.com/zet/go-struct-python-class/","summary":"The Tour of Go is very clear:\nGo does not have classes.\nOne benefit of learning multiple programming languages is that each language provides you with a set of “pegs” that you can use to refer to other languages. As I learned about structs in Go, I hung them to the “Python classes” peg and used that as a reference point. Using these reference points can help you to understand the object of study by looking at their differences and similarities.","title":"Structs In Go - Similar To Classes In Python?"},{"content":"I\u0026rsquo;m working on my twitter CLI and as I was writing a function to format the tweet I remembered something I picked up last week. After a quick search in my notes I remembered to use the %q with printf.\nslice := []string{feed.Items[0].Title, feed.Items[0].Link} result := strings.Join(slice, \u0026#34;\\n\u0026#34;) fmt.Printf(\u0026#34;Testing printf %q\u0026#34;, result) This is very useful when formatting output. Now I can actually see whether it is inserting the new line characters correctly:\nTesting printf \u0026quot;I Made My First Tweet Using My Go Program\\nhttps://mischavandenburg.com/zet/go-first-tweet/\u0026quot;I Made My First Tweet Using My Go Program\nThis can be harder to see when printing the variable using fmt.Println or using the %v verb with Printf.\nLinks: 202304091304\n[[go]]\n[[coding]]\n","permalink":"https://mischavandenburg.com/zet/go-use-q-for-debugging/","summary":"I\u0026rsquo;m working on my twitter CLI and as I was writing a function to format the tweet I remembered something I picked up last week. After a quick search in my notes I remembered to use the %q with printf.\nslice := []string{feed.Items[0].Title, feed.Items[0].Link} result := strings.Join(slice, \u0026#34;\\n\u0026#34;) fmt.Printf(\u0026#34;Testing printf %q\u0026#34;, result) This is very useful when formatting output. Now I can actually see whether it is inserting the new line characters correctly:","title":"Use The %q Verb When Debugging In Go"},{"content":"I spent the evening learning about the Twitter API. It was not as straight forward as I thought. My goal was to do this project using only the standard library, and I hoped to get away with a few simple curls, but since the API requires OAuth 1 to create tweets, I had to revise my strategy.\nAfter struggling with Postman for a few hours to get the correct environment variables set up I managed to make my first tweet through Postman. Turns out that Twitter made some big changes in the free tier of their API, and it took me quite a while to figure out that the functions that are used as examples in the API documentation are not accessible to free accounts anymore.\nWhen I realized I would not get away with a simple curl I looked into libraries, but many were deprecated. Eventually I discovered gotwi and it didn\u0026rsquo;t take long to make my first tweet using Go.\nIt feels like cheating, but looking at the complexity of the library, it looks like I would be stuck in the weeds for quite a while if I wanted to figure all of this out by myself.\nThere is still enough to figure out in this project, such as curling my RSS feed and creating a tweet out of that, and wrapping it in a CLI, so in the end I\u0026rsquo;m glad I found a working library.\nHere\u0026rsquo;s the program I used to make my first tweet. It is a modified example from the gotwi GitHub readme.\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/michimani/gotwi\u0026#34; \u0026#34;github.com/michimani/gotwi/tweet/managetweet\u0026#34; \u0026#34;github.com/michimani/gotwi/tweet/managetweet/types\u0026#34; ) func main() { in := \u0026amp;gotwi.NewClientInput{ AuthenticationMethod: gotwi.AuthenMethodOAuth1UserContext, OAuthToken: os.Getenv(\u0026#34;TWITTER_ACCESS_TOKEN\u0026#34;), OAuthTokenSecret: os.Getenv(\u0026#34;TWITTER_ACCESS_TOKEN_SECRET\u0026#34;), } c, err := gotwi.NewClient(in) if err != nil { fmt.Println(err) return } p := \u0026amp;types.CreateInput{ Text: gotwi.String(\u0026#34;Hello World! This time I\u0026#39;m using os.Getenv in my Go program to load the credentials.\\n#go #coding #study #learning\u0026#34;), } res, err := managetweet.Create(context.Background(), c, p) if err != nil { fmt.Println(err.Error()) return } fmt.Printf(\u0026#34;[%s] %s\\n\u0026#34;, gotwi.StringValue(res.Data.ID), gotwi.StringValue(res.Data.Text)) } Links: 202304082104\nhttps://github.com/michimani/gotwi\nhttps://mischavandenburg.com/zet/go-twitter-cli-project/\n[[go]]\n[[go-twitter-cli-project]]\n","permalink":"https://mischavandenburg.com/zet/go-first-tweet/","summary":"I spent the evening learning about the Twitter API. It was not as straight forward as I thought. My goal was to do this project using only the standard library, and I hoped to get away with a few simple curls, but since the API requires OAuth 1 to create tweets, I had to revise my strategy.\nAfter struggling with Postman for a few hours to get the correct environment variables set up I managed to make my first tweet through Postman.","title":"I Made My First Tweet Using My Go Program"},{"content":"When learning a programming language it is important to start building things quickly and to begin applying the theory. I have a tendency to dive into the books and lose myself in the theory, where I should be getting hands on experience.\nOver the past few months I\u0026rsquo;ve generated a bunch of ideas for projects that I want to write, and I selected my first project today.\nhttps://github.com/mischavandenburg/twitter-cli\nhttps://twitter.com/mischa_vdburg\nTwitter CLI Programs should solve a problem. My problem has to do with Twitter. I recently created a Twitter account, and I want to make a tweet whenever I publish something new on my website. I\u0026rsquo;m currently doing this by hand, and that needs to stop, obviously.\nThere are bots out there for this, but I want to build it myself. I\u0026rsquo;ve created the following user stories for my project.\nUser Story 1 As a user, I need a command that I can run from a bash shell that will post the standard input to my Twitter account\nUser Story 2 As a user, I need a command that I can run from a bash shell that will take the latest post from the RSS feed generated by my blog and post it to Twitter\nConcepts By writing this program I\u0026rsquo;ll need to figure out the following problems in Go:\nTaking input from the command line Authenticating to the Twitter API Making a POST request to the Twitter API Curling an RSS feed Looping over / reading XML / HTML data Transforming that data to a suitable format to post to Twitter Expansion This will be a good start for my project and will keep me busy for a while. When I solved the previous problems I can use the result and expand further. Some thoughts about further expansion:\nRSS Feeds I can use the skills I learn to start crawling Reddit feeds and filter them for keywords. I can automatically generate a curated selection from Reddit which will be easier to consume and will save me time by only serving me content that I might think is interesting to me, based on keywords.\nDatabase I want to learn more about using databases on Kubernetes and how to interact with databases using Go. For this I\u0026rsquo;d like to store my RSS feed into a database and keep track of information in the database. I could track whether an article has been posted to Twitter and when.\nBot Rather than posting my latest blog post to Twitter by manually running a command, I should have a bot scanning my blog and posting to Twitter when it detects a new article. Or I could trigger the bot whenever I make a push to my blog repo.\nIn any case, I want to have an application running on a server. I\u0026rsquo;m making plans to start up a proper home lab and this will be a perfect use case to start running on my home Kubernetes cluster.\nLinks: 202304081304\nhttps://github.com/mischavandenburg/twitter-cli\nhttps://twitter.com/mischa_vdburg\n[[go]]\n[[go-twitter-cli-project]]\n","permalink":"https://mischavandenburg.com/zet/go-twitter-cli-project/","summary":"When learning a programming language it is important to start building things quickly and to begin applying the theory. I have a tendency to dive into the books and lose myself in the theory, where I should be getting hands on experience.\nOver the past few months I\u0026rsquo;ve generated a bunch of ideas for projects that I want to write, and I selected my first project today.\nhttps://github.com/mischavandenburg/twitter-cli\nhttps://twitter.com/mischa_vdburg\nTwitter CLI Programs should solve a problem.","title":"Outlining My First Go Project"},{"content":"Dopamine Listened to an interesting podcast on Dopamine by Andrew Huberman. I always enjoy his content because he is completely driven by science, not by personal opinion. He is truly objective as far as I can tell.\nDopamine is often misunderstood. It is not necessarily associated with good feelings after you pursue an activity. It is more related to motivation to engage in certain behaviours.\nRewards Scientists did an experiment where they observed children of kindergarten age, and later reproduced this in adults. The children were monitored during school days, where they had blocks of structured time and free time. During structured time their activities were managed. They had to sing or write, for example. Then they had blocks of free time where they could do whatever activity they liked.\nThey observed what activity the children liked to do in their free time, and then started to reward these children for their work. For example, if the children liked to draw in their free time, the researches started giving them gold stars and other praise for their work.\nThen the researches removed the reward for the activity, and interestingly, the children and adults started showing less interest and enjoyment in the activity because they were lacking the reward.Note that this is the activity that they liked to do in their free time prior to the experiment.\nThis all has to do with the nature of dopamine, dopamine baselines and peaks.\nHuberman explains this with a metaphor of a pool. In the pool you have waves, and the waves have peaks and troughs. At the peaks, your dopamine is high, but they are inevitably followed by troughs: dips in dopamine, which lead to low energy and low motivation.\nThen there is the baseline of dopamine: the amount of water in the pool. The baseline is the relative point to which the peaks and throughs are determined.\nSo it is important that you don\u0026rsquo;t reward yourself for activities that you are doing. Don\u0026rsquo;t reward yourself too much when you achieve a fitness or study goal. You will feel good after the event, but you will end up in a through. Being in the trough means feeling demotivated, leading to procrastination.\nGetting Out Of The Trough The good news is that the system will reset itself after experiencing highs or lows due to rewards.Getting out of the trough happens automatically, but you can influence the rate at which you climb out of it.\nLet\u0026rsquo;s say you are not motivated to study. You\u0026rsquo;ll need to do something which is more painful. Something that\u0026rsquo;s even harder to do. Whatever feels harder to do in the moment than the activity that you should be doing. Do something that makes you feel uncomfortable.\nTactics exercise for 1 minute do something that really sucks cold water anything that makes you cringe leverage something that\u0026rsquo;s painful The Holy Grail Of Motivation The holy grail of motivation: not needing any external reward, but enjoying the activity itself that is leading you towards your goal. For example, enjoying running training in pursuit of a marathon goal. Enjoying coding and doing coding exercises in pursuit of becoming a software engineer.\nI feel very fortunate that I succeeded at turning my passion into my career. The journey itself is fun. I enjoy coding, and that activity is taking me closer towards the goal of becoming a good software engineer and the ability to contribute to open source.\nLinks: 202303311903\nhttps://hubermanlab.com/leverage-dopamine-to-overcome-procrastination-and-optimize-effort/\n[[my ikigai and flow]]\n[[coding]]\n[[devops]]\n[[career]]\n","permalink":"https://mischavandenburg.com/zet/dopamine-and-motivation/","summary":"Dopamine Listened to an interesting podcast on Dopamine by Andrew Huberman. I always enjoy his content because he is completely driven by science, not by personal opinion. He is truly objective as far as I can tell.\nDopamine is often misunderstood. It is not necessarily associated with good feelings after you pursue an activity. It is more related to motivation to engage in certain behaviours.\nRewards Scientists did an experiment where they observed children of kindergarten age, and later reproduced this in adults.","title":"Podcast Notes: Dopamine and Motivation - Huberman"},{"content":"I noticed multiple times now that during my workouts my mind is generating lots of new ideas for coding projects or blog posts. It is a well known fact that walking stimulates areas in the brain that which will in turn stimulate creativity. But I\u0026rsquo;m noticing that it starts to happen with strength workouts as well.\nAlthough I don\u0026rsquo;t struggle with the motivation to get myself to the gym, I sometimes feel \u0026ldquo;guilty\u0026rdquo; for not spending that time on coding or studying. I\u0026rsquo;m realizing now that this is a very irrational train of thought.\nExercise actually stimulates my creativity and will help generating new ideas or help me understand concepts better in the unconscious. It is also massively beneficial for health and general well being. When general well-being is enhanced I\u0026rsquo;ll also be able to focus better and absorb information more quickly.\nI should re-frame my thinking and actually put exercise as priority number 1. Exercise time is never wasted time. It indirectly contributes to my productivity and coding endeavours as well.\nLinks: 202304011104\n[[exercise]]\n[[health]]\n[[focus]]\n[[productivity]]\n","permalink":"https://mischavandenburg.com/zet/exercise-stimulates-creativity-and-motivation/","summary":"I noticed multiple times now that during my workouts my mind is generating lots of new ideas for coding projects or blog posts. It is a well known fact that walking stimulates areas in the brain that which will in turn stimulate creativity. But I\u0026rsquo;m noticing that it starts to happen with strength workouts as well.\nAlthough I don\u0026rsquo;t struggle with the motivation to get myself to the gym, I sometimes feel \u0026ldquo;guilty\u0026rdquo; for not spending that time on coding or studying.","title":"Exercise Stimulates Creativity And Motivation"},{"content":"A couple of weeks ago I created a simple bash script to generate a date in format YYY-MM-DD to use with the magic !! wands in vim.\nJust now I wanted to expand this with being able to create a markdown header with this date.\n#!/bin/bash # Gendate generates the date in YYY-MM-DD format # Can be called with arguments h and number to generate a markdown heading # For example: \u0026#39;gendate h 3\u0026#39; will generate \u0026#39;### 2023-03-29\u0026#39; header=\u0026#34;\u0026#34; date=$(date +\u0026#34;%Y-%m-%d\u0026#34;) if [[ $# -gt 0 ]]; then # handling wrong arguments if [[ $# -eq 1 || \u0026#34;$1\u0026#34; != \u0026#34;h\u0026#34; ]]; then echo \u0026#34;Usage: gendate h 2 to generate with markdown heading ##\u0026#34; exit 1 fi # format markdown heading if arguments h, n are given if [[ $# -eq 2 ]]; then for i in $(seq 1 $2); do header+=\u0026#34;#\u0026#34; done header+=\u0026#34; \u0026#34;$date echo \u0026#34;$header\u0026#34; exit 1 fi fi # if no arguments given, generate the date echo \u0026#34;$date\u0026#34; Links: 202304011104\nhttps://github.com/mischavandenburg/dotfiles/tree/main/scripts\n","permalink":"https://mischavandenburg.com/zet/generate-markdown-headings-date/","summary":"A couple of weeks ago I created a simple bash script to generate a date in format YYY-MM-DD to use with the magic !! wands in vim.\nJust now I wanted to expand this with being able to create a markdown header with this date.\n#!/bin/bash # Gendate generates the date in YYY-MM-DD format # Can be called with arguments h and number to generate a markdown heading # For example: \u0026#39;gendate h 3\u0026#39; will generate \u0026#39;### 2023-03-29\u0026#39; header=\u0026#34;\u0026#34; date=$(date +\u0026#34;%Y-%m-%d\u0026#34;) if [[ $# -gt 0 ]]; then # handling wrong arguments if [[ $# -eq 1 || \u0026#34;$1\u0026#34; !","title":"Generating Markdown Headings with YYYY-MM-DD Date Format Using Bash"},{"content":"I\u0026rsquo;m still at the beginning of my Go learning journey, but I worked through a few tutorials and guides by now. I\u0026rsquo;ve gathered lots of ideas for programs that I want to write, big and small, but I have to start somewhere.\nThe best thing to do is to write little programs that solve a problem that you have.\nOne problem I needed to solve was converting sentences to title case in vim. There are plugins for this, or elaborate macros, but I thought this was a nice opportunity to write my first program from scratch. You can view the program here: my go repo.\nTitle Converting a string to title case is fairly easy:\n// Package title converts a string to title case. package title import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func Make(s string) { t := strings.Title(s) fmt.Printf(\u0026#34;%v\\n\u0026#34;, t) } This function takes a string as an argument and uses the Title function from the strings package to convert it. I use printf to format the output and to add a new line character.\nChallenge The challenge lies in taking input from Stdin. I solved this by reusing the things I learned from the greet challenge. I described how to read from standard input in go in this article.\nHere is the code for the title command:\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/mischavandenburg/go/projects/title\u0026#34; \u0026#34;github.com/mischavandenburg/go/projects/title/internal\u0026#34; ) func main() { var x string var err error if len(os.Args) \u0026gt; 1 { x = strings.Join(os.Args[1:], \u0026#34; \u0026#34;) } if x == \u0026#34;\u0026#34; { x, err = internal.ReadLine(os.Stdin) } if err != nil { log.Print(err) return } title.Make(x) } This main function checks if arguments are given to the program from the command line, and uses these arguments if they are given. If there are no arguments, it will expect input to be piped to it. It takes either the input from the arguments or from standard input and calls the Make() function that I described above.\nThis main function uses a Readline function to extract the string from standard input:\npackage internal import ( \u0026#34;bufio\u0026#34; \u0026#34;io\u0026#34; \u0026#34;strings\u0026#34; ) // ReadLine takes anything of type io.Reader and returns a trimmed string (initial // and trailing white space) or an empty string and error if any error // is encountered. func ReadLine(in io.Reader) (string, error) { out, err := bufio.NewReader(in).ReadString(\u0026#39;\\n\u0026#39;) out = strings.TrimSpace(out) return out, err } For a more detailed explanation of this function read this article I wrote.\nUsage I wrote the program so I can call it with a sentence as an argument:\nmischa@mac-beast:~ (ins)$ title hello world, this is my sentence in title case Hello World, This Is My Sentence In Title Case But the main use case is to use it as a UNIX filter inside of vim. A UNIX filter is a program that takes standard input, performs some operation on the input, and prints it to standard output.\nNow, when I\u0026rsquo;m working inside of vim, I can convert the current line to title case by typing the following command:\n!!title\nThe !! command sends the specified amount of lines to the command you specify. Exclamation marks truly are magic wands! I highly recommend reading this article by rwxrob to learn more about them.\nLinks: 202303280803\nhttps://github.com/mischavandenburg/go/tree/main/projects/title\nhttps://rwx.gg/tools/editors/vi/how/magic/\nReading from standard input in Go\n","permalink":"https://mischavandenburg.com/zet/my-first-go-program/","summary":"I\u0026rsquo;m still at the beginning of my Go learning journey, but I worked through a few tutorials and guides by now. I\u0026rsquo;ve gathered lots of ideas for programs that I want to write, big and small, but I have to start somewhere.\nThe best thing to do is to write little programs that solve a problem that you have.\nOne problem I needed to solve was converting sentences to title case in vim.","title":"I Wrote My First Go Program Today"},{"content":"Pods have containers, and limits can be set on those containers.\nRequests used by the kube-scheduler to determine where the Pod will be placed containers can use more than requested resources if it is available on node If a limit is specified, but no request, Kubernetes will use the limit value as the request value.\nLimits containers may never use more than the set limit\nenforced by kubelet and container\nhost kernel will kill processes that attempt to allocate more than limit (OOM error)\nreactively: killed when exceeded\nenforcement: system prevents container to ever exceed limit\nIf the node runs out of memory and the container exceeds its memory request, the pod will be evicted\ncontainer runtimes don\u0026rsquo;t terminate Pods or containers for excessive CPU usage\nPods The pod resource request and limit is the sum of the resource requests of the containers in the pod.\nCPU Units Defined as an absolute amount of resource. 1000m = 1 CPU.\nThis is always the same unit, regardless whether the host has 4 or 48 CPU\u0026rsquo;s.\n500m CPU = 0.5 CPU\nMemory Units Can use P, T, G, M etc.\nNote that \u0026ldquo;m\u0026rdquo; is not megabyte. 0.8m = 0.8 bytes.\nUse mebibytes Mi or megabytes M.\nDefiniton Example spec: containers: - name: nginx image: nginx resources: requests: memory: 100Mi cpu: 250m limits: memory: 200Mi cpu: 500m Scheduling The scheduler ensures that the sum of requests of the pods on the node does not exceed the available resources.\nEven if a node has low resource usage, it will not accept pods that have requests which exceed the available resources.\nNodes use k describe node to see the resource status of the node.\nLinks: 202303281903\nhttps://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n","permalink":"https://mischavandenburg.com/zet/kubernetes-resource-management-pods-containers/","summary":"Pods have containers, and limits can be set on those containers.\nRequests used by the kube-scheduler to determine where the Pod will be placed containers can use more than requested resources if it is available on node If a limit is specified, but no request, Kubernetes will use the limit value as the request value.\nLimits containers may never use more than the set limit\nenforced by kubelet and container","title":"Kubernetes Resource Management for Pods and Containers - CPU and Memory"},{"content":"I used to make all my notes on paper, but I decided to switch to a digital note-taking system about two years ago.\nDigital note-taking provides the following advantages:\nSearchability Collected in one place Can be converted to different output formats Easier to share with others Does not take up physical space No risk of losing your notes in case of fire or other disaster I\u0026rsquo;ve gone through several iterations of my note-taking systems. I started on Google Docs, moved on to Notion and eventually landed on Obsidian. However, as I became more proficient with UNIX systems and vim, I realized I did not need all of that distracting functionality, and I switched over to using Neovim and a few bash scripts. I occasionally open up Obsidian to look at my graph view or to make use of the Anki plugin, but I enjoy the trimmed-down version that I built myself. I don\u0026rsquo;t need to leave the command line to read my notes or to create a new one.\nIn this article I\u0026rsquo;ll show you the system I\u0026rsquo;m currently using for note-taking. My note-taking system is part of a larger system which I call my \u0026ldquo;Second Brain\u0026rdquo;, a term coined by Tiago Forte. This is an overarching system I\u0026rsquo;ve build to manage my time, projects, tasks and bookmarks. Explaining this entire system is beyond the scope of this article, but I plan to write about my Second Brain in the future as well.\nMy system is based on the Zettelkasten method, but I\u0026rsquo;ve adjusted it to my own needs. After a few years of experimentation I feel that my system has reached a \u0026ldquo;mature\u0026rdquo; state, but it will always remain continuosly under development, also because my needs may change.\nWhat is a Zettelkasten? Zettelkasten is a system of note taking and personal knowledge management. Zettelkasten means \u0026ldquo;slip box\u0026rdquo; in German. Traditionally it is a physical box of slips of paper or index cards containing smaller notes. Each of these cards have a unique identifier, and these identifiers are used to create links between the cards.\nNiklas Luhmann, who was one of the most prolific scholars in history, used it extensively. He wrote 70 books and nearly 400 academic articles, and he credited the Zettelkasten with making his productivity possible. It contained around 90,000 index cards.\nI first came across this concept by reading the book How to take Smart Notes by Sönke Ahrens.\nWhy Take Notes? \u0026ldquo;Your professional success and quality of life depend directly on your ability to manage information effectively.\u0026rdquo;\nTiago Forte, Building A Second Brain\nIn the modern age we consume very large amounts of information, much more than we can remember. It is therefore very important to manage your intake of information, but also the retention of that information. I find that taking notes on the topics that may be of interest to me at any given time helps me understand the subject much better, because it forces me to clearly formulate my thoughts and convert them to written form.\nOver time a large collection is built up which can be used to generate new ideas.\nWhat Do I Take Notes On? Firstly, I keep a daily journal where I write down my thoughts, my feelings and the activities that I undertake. Some days may be several pages worth, and other days will be only \u0026ldquo;Had a nice day today\u0026rdquo;. But I make a point to write something down every day.\nSecondly, I write about the topics I study. I\u0026rsquo;m always learning something new. I\u0026rsquo;m a DevOps Cloud Engineer, and new developments are made constantly in the Cloud Native landscape. There is always more to learn.\nMy notes are not only work related. I also keep notes of the research I do for all of my interests, such as health, longevity, exercise, diet, literature, yoga and meditation. I made a habit out of always writing a note when I read a book, watch a documentary or listen to a podcast. These notes can be a short summary, a few thoughts that come to mind, or a few bullet points that capture the main takeaways.\nThese activities are usually accompanied by taking notes:\nReading books Watching video courses Watching educational YouTube videos Researching hobbies and interests Coding Reflection Interesting conversations Listening to podcasts An Overview of My System My system is a modified Zettelkasten system that incorporates daily notes for journaling. The Zettelkasten method emphasizes small atomic notes containing only your own thoughts and links to other notes. However, I choose to also make longer notes. For example, when I did the Fundamentals of Bicep course, I made one large note that contains all of the information I wished to remember or refer to later. In this particular use case, I think it\u0026rsquo;s much better to keep everything collected in one note, rather than breaking this note up in smaller notes on parameters and variables, for example.\nAnother area where I diverge from the traditional Zettelkasten is categorization of notes. Traditionally the Zettelkasten is one big repository of notes, but I like to keep them loosely collected. When I create a new note, my system places that note in an inbox directory. Once a week I go through my inbox and revisit all of my notes. Sometimes I will throw some notes away because I don\u0026rsquo;t think they\u0026rsquo;re necessary after all. When I decide to keep it, I put it in a directory that I find suitable. I have a directory structure based on the PARA method, but I also have a large Zettelkasten directory where I put anything that does not necessary belong to a category. I mostly keep some notes collected in a directory because I expect to use them as a collection at some point, or because I want to run scripts on the files.\nEvery day a daily note is created that contains a few checkboxes for habit tracking and sometimes I\u0026rsquo;ll include an inspirational quote in my template for a while.\nThis is what a daily note looks like in my editor:\nLocal Text Files I think it is important to use locally stored markdown text files. This is mainly why I moved away from Notion. My notes are stored on my local machine rather than with a third party. This gives me complete control over my data.\nBecause my notes are stored as markdown files, I can use various tools to write or edit my notes. Moreover, storing my notes as local files allows me to run scripts on my notes and customize my workflow to my heart\u0026rsquo;s content. This can be especially useful for automating tasks, streamlining my work, or making bulk updates.\nI have my collection backed up in several places and on GitHub.\nI recommend this article about the benefits and merits of using markdown for note-taking.\nVim, My Preferred Text Editor I use Vim, or technically, Neovim for all of my text editing. It took a while to get used to, but my productivity related to text editing has increased significantly. I also find it very enjoyable to work on the command line, not having to leave my tmux window to manage my entire Zettelkasten or keep my journal.\nMy vim configuration is always subject to constant change, but I only use three plugins that are related to my note-taking and Zettelkasten.\n1. Telescope I cannot live without this plugin any longer. It is a fuzzy searcher integrated into my editor. I can search for files but also search within the files using ripgrep, and preview the files as I\u0026rsquo;m searching.\nHeres what a search for Neovim looks like:\nI can navigate through all the search results blazingly fast using only the keyboard, and I can preview the files by scrolling up and down in the window on the right hand side.\n2. Marksman LSP Marksman is a markdown language server which helps me format my documents and to create links between notes.\nWhen I start to make a link it will search through my entire Zettelkasten and look for matches based on the filename or markdown headers. Here it shows me suggestions related to markdown.\n3. Pandoc According to Wikipedia, \u0026ldquo;Pandoc is a free-software document converter, widely used as a writing tool (especially by scholars) and as a basis for publishing workflows.\u0026rdquo;\nI use the Pandoc plugin for vim to export my notes to different formats when I need to.\nHowever, the thing I like most about it is that it renders my notes very nicely as I\u0026rsquo;m writing them. I really like how headings look, and that it will make text bold while editing, which did not work when I used nvim-markdown.\nBash To facilitate my workflow I wrote a few bash scripts.\nWhen I want to take a note, I run the zet command from the command line. This command is a bash script I wrote which creates a file in my inbox, adds a template to it, and opens the file in Neovim. I can either provide a filename to it as an argument or it will ask me to provide one.\nI have another script named blog which I use to create notes that I intend on publishing on my website. These files are stored in a different location and use a different template. The blog script also has a pub function that will publish the script directly to my website in a few seconds after I\u0026rsquo;m done writing.\nThese scripts can be found in my dotfiles repo.\nIdentifiers and Filenames The Zettelkasten method assigns unique identifiers to notes. I generate a unique identifier from the current date and time, but I never really use these identifiers. However, since I\u0026rsquo;ve been doing this consistently from the beginning, I\u0026rsquo;ll keep generating them to make my system future proof. Who knows, maybe they will become useful someday when I suddenly find a use case for it.\nI\u0026rsquo;ve seen other people use unique identifiers in filenames as well, but this is a big no for me. I want to be able to discern what the contents might be from the filename whenever I\u0026rsquo;m navigating around my directory structure. Using the filename as the note identifier is a much better solution in my opinion. There is a small chance that you will choose a filename that already exists, but you can easily add a number to it or change a word and you have solved that problem.\nMoreover, I use the marksman LSP server to create links between my notes in Neovim. The LSP server is based on headings and filenames, so I\u0026rsquo;m really glad that I chose to use filenames such as \u0026ldquo;fundamentals-of-bicep.md\u0026rdquo; right from the beginning.\nTags and Links If you are as deep into note-taking systems as I am, you might have come across the problem of using tags versus using links for your note-taking system.\nI primarily use [[markdown links]] to create links in my notes. This is also why you will sometimes see these things in my public zettelkasten. The links between notes are rendered beatifully by Obsidian in the graph view. This is also why I\u0026rsquo;ll always try to keep my system compatible with Obsidian, even though I\u0026rsquo;ve moved away from the application almost entirely.\nHere is a graph view of my Zettelkasten:\nFor the notes in my Zettelkasten which are intended to be published on my website, I use tags in the YAML frontmatter. These are used by my static website generator, Hugo, to create tag pages on my website which I think will be useful to my readers.\nHere is an example of the YAML front matter of one of these notes:\n--- title: \u0026#34;I\u0026#39;m In Love with my Work: Lessons from a Japanese Sushi Master\u0026#34; date: 2022-10-08 tags: - Career - Personal - Article --- Conclusion That\u0026rsquo;s about it. My system is a minimalistic set of tools utilized for maximum productivity. It\u0026rsquo;s Neovim with a few plugins and a couple of helper scripts I wrote in bash that store markdown files in a directory structure that I find meaningful. After using many different applications and solutions, I\u0026rsquo;m extremely satisfied with the system I built for myself which is very basic, free from distractions and tailored to my own needs.\nWhen I want to reflect on a certain topic or to write an article, I go through my collection of notes and link them together. Very often I find that the creation of these links will stimulate even more new connections and associations, and I end up with new ideas and more topics of study I want to explore and write about. I use my Zettelkasten as a vehicle for reflection, learning and creativity.\nI love the simplicity of my system. It enables me to capture notes very quickly while I\u0026rsquo;m working or studying with very little effort. By storing my note collection on my iCloud drive and in GitHub, they can be accessed from all of my devices across all different operating systems.\nI hope that this article may give you some inspiration to start building your own note collection. You don\u0026rsquo;t need to build your own system like I have done, any app that satisfies your needs can be used. Keeping notes on the things I encounter in life is one of the most enriching habits I\u0026rsquo;ve acquired. It will be interesting to see how large my collection grows over the years!\nLinks: 202303270703\nhttps://fortelabs.com/blog/basboverview/\nhttps://fortelabs.com/blog/para/\nhttps://rwx.gg/lang/md/\nhttps://github.com/mischavandenburg/dotfiles/tree/main/scripts\n","permalink":"https://mischavandenburg.com/zet/neovim-zettelkasten/","summary":"I used to make all my notes on paper, but I decided to switch to a digital note-taking system about two years ago.\nDigital note-taking provides the following advantages:\nSearchability Collected in one place Can be converted to different output formats Easier to share with others Does not take up physical space No risk of losing your notes in case of fire or other disaster I\u0026rsquo;ve gone through several iterations of my note-taking systems.","title":"My Neovim Zettelkasten: How I Take Notes in Markdown Using Vim and Bash"},{"content":"I\u0026rsquo;m working through the \u0026ldquo;greet\u0026rdquo; challenge by rwxrob. It is amazing how such a relatively simple and small challenge can lead down to so many rabbit holes.\nThe program should take input from the user and print it out. I worked through the challenge together with Rob in his video but I\u0026rsquo;m going to talk (write) myself through these functions to fully understand what\u0026rsquo;s going on.\nWe have the following function in main.go:\nfunc main() { var name string var err error if len(os.Args) \u0026gt; 1 { name = strings.Join(os.Args[1:], \u0026#34; \u0026#34;) } if name == \u0026#34;\u0026#34; { fmt.Println(\u0026#34;Hello there, what\u0026#39;s your name?\u0026#34;) name, err = internal.ReadLine(os.Stdin) if err != nil { log.Print(err) return } } greet.Hi(name) } If the number of arguments passed to the program is greater than 1, we set name to a joined string created from the provided arguments. Args[0] would be the path to the program, so we don\u0026rsquo;t want that to be included. As a result, greet mischa will pass mischa to the greet.Hi() function, as defined in greet.go, and print out Hello, mischa.\nHowever, if no arguments are passed to the greet program, discovered in case name is empty, we ask the user for input. We capture the input by os.Stdin and pass it to the ReadLine() function, which is located at internal/readline.go.\n// ReadLine takes any io.Reader and returns a trimmed string (initial // and trailing white space) or an empty string and error if any error // is encountered. func ReadLine(in io.Reader) (string, error) { out, err := bufio.NewReader(in).ReadString(\u0026#39;\\n\u0026#39;) out = strings.TrimSpace(out) return out, err } } ReadLine has a parameter in of type io.Reader, which is an interface. Next, we determine that ReadLine should return two values of type string and error. I\u0026rsquo;m saving to learn about interfaces for another day, I\u0026rsquo;m just going to work through this function now.\nWe assign the output of bufio.NewReader(in).ReadString('\\n') to two new variables named out and err using the \u0026ldquo;walrus operator\u0026rdquo; := which detects the types automatically. We can do it like this because ReadString returns (string, error).\nWe take the in argument of type io.Reader which was passed to the ReadLine function, which in this case is the io.Stdin that came from our main function, and pass it on to bufio.NewReader(in). Then we are able to read the string until the newline character \\n in the string, and trim off the whitespace from the beginning and the end of the string by calling TrimSpace on the out variable.\nThen we return the trimmed string back to our original main function, which will pass it on to the Hi() function.\nHowever, if the bufio.NewReader(in).ReadString('\\n') should return an error, it is caught by this code in the main function:\nif err != nil { log.Print(err) return } This is a standard way of handling errors in Go. If the error is anything else than nil, we will print the error and end the function with the return keyword.\nThoughts I\u0026rsquo;m really glad I took the time to talk / write myself through this program. I think I\u0026rsquo;m going to make a habit of this as I\u0026rsquo;m learning Go. It made everything much clearer when I sat down and traced the arguments from function to function and describing every step in my own words.\nI\u0026rsquo;ll post this note in the YouTube comments, maybe somebody will find it useful as well.\nLinks: This page goes a lot deeper in what stdin and stdout actually do in this context. Very interesting reading:\nhttps://stackoverflow.com/questions/12363030/read-from-initial-stdin-in-go\nThe code in my repo:\nhttps://github.com/mischavandenburg/go/tree/main/rwxrob/boost2022/challenges/greet\n[[go]]\n[[go-rwxrob]]\n[[coding]]\n[[functions]]\n","permalink":"https://mischavandenburg.com/zet/go-reading-stdinput-cmdline/","summary":"I\u0026rsquo;m working through the \u0026ldquo;greet\u0026rdquo; challenge by rwxrob. It is amazing how such a relatively simple and small challenge can lead down to so many rabbit holes.\nThe program should take input from the user and print it out. I worked through the challenge together with Rob in his video but I\u0026rsquo;m going to talk (write) myself through these functions to fully understand what\u0026rsquo;s going on.\nWe have the following function in main.","title":"Go - Reading from Standard Input Provided by User"},{"content":"Beginner Boost Week 17 and 18 Notes Link to video\nDon\u0026rsquo;t forget to set GOBIN=~/.local/bin, GOPRIVATE, CGO_ENABLED=0 Go Testing - Example Tests func ExampleFoo() { foo() // Output: // Foo } The ExampleFoo indicates the test here. It needs to match the name exactly after Example. But it is capitalized.\nIt runs that function and will compare the output to what is specified.\nIt says \u0026ldquo;see if the program generates this output in std out\u0026rdquo;.\nThese are called example tests.\nTo export a function the first letter should be a capital. Everything that has a capital as first letter is exported.\nWhen you are writing example tests you are providing readable automatic documentation to your end users.\nYou can use // Unordered Output if you don\u0026rsquo;t care about the order.\nPrintf use printf %q to see all of the characters. %q escapes all of the invisible characters. So you can see \\r or \\n for example. This is the only way to check for empty values in Example tests.\nHow to Learn Go Don\u0026rsquo;t go to the books. Stay with the spec, write your own projects, and find one or two or 10 Go projects and study the crap out of them.\nStudy the code bases. Kind is a good codebase.\nRead the Go codebase!\nhttps://youtu.be/9hEnzD-bNy4?t=8467\nRead other people\u0026rsquo;s code and see if your code looks like that.\n\u0026ldquo;Good artists copy, great artists steal.\u0026rdquo; - quote accredited to Steve Jobs but it has its origin in T.S. Eliot and even further back.\nStart with the tests! Read the tests first.\nSearching Go Documentation Always search for golang when searching on the net. Preferably text based searching.\nThen you use go doc os.Stderr - for example.\nVariable Names Long variable names are frowned upon in the Go community. They should be as short as they need to be.\nIf using in a tight scope, a single letter is fine. In a block two or three characters is more than enough. It distracts from reading the code if they have very long names.\nThe more remote the variable is, the more descriptive it should be.\nThe Art of Coding breaking everything down into small 1 task functions don\u0026rsquo;t repeat yourself See stuttering\nTop Level Libraries It\u0026rsquo;s not common to make a single utility at a top-level GitHub repo.\nIt\u0026rsquo;s very likely that you are going to want to reuse code somewhere.\nYou should start thinking of things as composition. \u0026ldquo;How is this code going to be used by other people\u0026rdquo;.\nGo is different than bash: you will use this code elsewhere.\nWhat is the function of what I\u0026rsquo;m creating? Create these as small composable blocks So you can use them later Example Based Testing https://pkg.go.dev/testing\nThe package also runs and verifies example code. Example functions may include a concluding line comment that begins with \u0026ldquo;Output:\u0026rdquo; and is compared with the standard output of the function when the tests are run. (The comparison ignores leading and trailing space.) These are examples of an example:\nfunc ExampleHello() { fmt.Println(\u0026#34;hello\u0026#34;) // Output: hello } func ExampleSalutations() { fmt.Println(\u0026#34;hello, and\u0026#34;) fmt.Println(\u0026#34;goodbye\u0026#34;) // Output: // hello, and // goodbye } Searching Information Being able to look up information quickly and taking notes about them is just as important as the coding itself.\nPackages or Libraries You can either have a command, which will be a main package, or you can have an importable library named .go. Should have any other name besides main.\nYou rarely want your top level of your module to be a package.\nConvention: cmd directory.\nThis is specifically for separate commands.\nStuttering greet.Greet() is called stuttering in go. Don\u0026rsquo;t do this.\nModules A module can be defined as \u0026ldquo;a GitHub repo with a go.mod\u0026rdquo; in it.\n\u0026ldquo;A collection of Go packages stored in a file tree with a go.mod file at its root\u0026rdquo;\nThe go.mod contains the import path of the module.\nWhat Module Does Greet Belong To? In the case of our greet command, it belongs to the greet module located at:\ngithub.com/mischavandenburg/go/rwxrob/boost2022/challenges/greet\nGreet has a main package which is part of the greet module.\nNow we will add another command with another main package to this module.\nCLI Stuff that has to do with interacting with the user on the command line should never be in the package library. The package library should be written to be solid no matter what.\nThe \u0026ldquo;name\u0026rdquo; for our greet program should be able to come to anywhere.\nAvoid Interactive Input You generally want to avoid interactive input. Prefer arguments, env variables or file inputs.\nIf you call your program from another script it will stall if it waits for interactive input.\nA good example is forgetting \u0026ldquo;-y\u0026rdquo; when running apt-get.\nAn interactive story game is a different use case than a CLI tool.\nUNIX filters are specifically designed to read input and generate an output based on the input. Here it is expected behaviour to stall if no input is given.\nRunes A rune is a single Unicode point.\nThe same people who created Go, created the Unicode standard.\nGo has the best Unicode support.\nWriting Documentation Convention is to always start with the name of the thing you are documenting. When documenting a function, always start with the function name. For example // ReadLine reads from standard input\nUse go doc --all to see a print of all the documentation in your package.\nThe same goes for packages. Always start with \u0026ldquo;Package internal does bla bla\u0026rdquo;\nLinks 202303261403\nhttps://www.youtube.com/watch?v=WMH5ENF_Xvo\n[[go]]\n[[coding]]\n[[rwxrob]]\n","permalink":"https://mischavandenburg.com/zet/go-rwxrob-boost-week-17-18/","summary":"Beginner Boost Week 17 and 18 Notes Link to video\nDon\u0026rsquo;t forget to set GOBIN=~/.local/bin, GOPRIVATE, CGO_ENABLED=0 Go Testing - Example Tests func ExampleFoo() { foo() // Output: // Foo } The ExampleFoo indicates the test here. It needs to match the name exactly after Example. But it is capitalized.\nIt runs that function and will compare the output to what is specified.\nIt says \u0026ldquo;see if the program generates this output in std out\u0026rdquo;.","title":"Go - Skillstak Beginner Boost Week 17 and 18 Notes"},{"content":"To read the news free from distractions and ads I use Newsboat as a reader for RSS feeds.\nHowever, one thing that annoyed me was that it would span across my entire screen in the terminal. When you read blogs or news pages in the browser, you\u0026rsquo;ll notice that the text is always located in a middle column of the window, so you don\u0026rsquo;t have to move your neck while reading. At least, this is the case with well designed websites that serve text content.\nVim has a plugin that achieves this and I use it extensively. It is called Zenmode. In Neovim I use a similar plugin called No Neckpain.\nTo achieve a similar configuration for Newsboat I used tmux. I wrote the following bash script:\n#!/bin/bash # nb opens a new pane and runs newsboat in it. I want to read from a centered column in my screen. tmux split-pane -h \\; resize-pane -x 130\\; send -t 2 \u0026#34;newsboat\u0026#34; Enter\\; send -t 1 \u0026#34;clear\u0026#34; Enter Note that this needs to be run from within an existing tmux window with no split panes.\nIt splits the current window in to two panes, resizes the new pane to a width of 130 pixels and sends the \u0026ldquo;newsboat\u0026rdquo; command to the new pane, and the \u0026ldquo;clear\u0026rdquo; command to the old (left) pane to keep it nice and clean.\nIn my ~/.newsboat/config file I added the following setting:\ntext-width 72\nThis will limit the text on the right hand side of the screen.\nThe end result looks like this:\nLinks: 202303260903\nhttps://github.com/folke/zen-mode.nvim\nhttps://github.com/shortcuts/no-neck-pain.nvim\n","permalink":"https://mischavandenburg.com/zet/newsboat-in-zenmode/","summary":"To read the news free from distractions and ads I use Newsboat as a reader for RSS feeds.\nHowever, one thing that annoyed me was that it would span across my entire screen in the terminal. When you read blogs or news pages in the browser, you\u0026rsquo;ll notice that the text is always located in a middle column of the window, so you don\u0026rsquo;t have to move your neck while reading.","title":"How to Run Newsboat in Zenmode"},{"content":"I found an excellent video by Rob Muhlenstein explaining the differences between Cloud, Cloud Native and DevOps. Here are the notes I wrote.\nCloud These are primarily cloud services. The external cloud.\n\u0026ldquo;Something as a Service\u0026rdquo;.\nAmazon Azure GCP Cloud Native This is Cloud Native: The CNCF Landscape\nCloud Native is the technology that makes the cloud possible, and all the technology dependent on those services.\nComputing Edge Computing\nHigh Performance Computing\nEncapsulates all of the technologies that are involved with containerization of work, jobs and nodes\nDeployment of compute resources as nodes\nThis is why Google\u0026rsquo;s Borg was called Borg\nComputers are drones of a larger collective\nEvery node puts all the resources into the collective.\nThe collective is all the nodes combined, and Kubernetes is the Borg that orchestrates everything. It sees available resources and allocates the work that needs to be done.\nBorg is the internal system developed at Google to run their infrastructure. You can read about it in the Site Reliability Engineering books and I highly recommend them.\nKubernetes is /proc for the cloud\nRob Muhlenstein\nMost Important Technologies Docker, Dockerfiles\nKubernetes\nHelm\nHarbor\nDifferent registries, harbor, quay\nIt is a lot of Python and POSIX shell\nGo for infrastructure application development\nKubernetes and Helm have won the game\nContainers: Size Matters Size matters (again) in the cloud The smaller your container the better, because it takes less resources and less costs DevOps DevOps is not the same as Cloud Native. It is one piece of it, a specific set of practices and actions that can be done within Cloud Native.\nHow you write software and release it CI/CD Focused on getting the software out GitLab has become the one stop shop Purpose is to write software and get it published fast GitOps Summary In summary, \u0026ldquo;cloud\u0026rdquo; stands for the services offered by cloud providers such as AWS, Azure and GCP. Cloud Native stands for all of the technology that makes these cloud services possible. DevOps is part of Cloud Native, but definitely not the same thing. DevOps is concerned with how software is written and released.\nLinks: 202303262003\nhttps://youtu.be/gyjRriOyw-k\nhttps://landscape.cncf.io/\nhttps://sre.google/books/\n[[rwxrob]]\n[[devops]]\n[[kubernetes]]\n[[cloud-native]]\n[[cncf]]\n","permalink":"https://mischavandenburg.com/zet/cloud-cloudnative-devops/","summary":"I found an excellent video by Rob Muhlenstein explaining the differences between Cloud, Cloud Native and DevOps. Here are the notes I wrote.\nCloud These are primarily cloud services. The external cloud.\n\u0026ldquo;Something as a Service\u0026rdquo;.\nAmazon Azure GCP Cloud Native This is Cloud Native: The CNCF Landscape\nCloud Native is the technology that makes the cloud possible, and all the technology dependent on those services.\nComputing Edge Computing\nHigh Performance Computing","title":"The Difference Between DevOps, Cloud and Cloud Native"},{"content":"It happens that I want to share my notes with friends that just simply want a pdf instead of a markdown file.\nThis morning I figured out a quick way to convert markdown to pdf on a M2 MacBook running MacOS Ventura.\nYou need the pandoc and wkhtmltopdf packages.\nbrew install pandoc wkhtmltopdf To convert:\npandoc 00-zettelkasten/Fundamentals\\ of\\ Bicep.md --pdf-engine=wkhtmltopdf -o /tmp/test.pdf This will output a pdf to my /tmp/ directory and it looks pretty good.\nTo convert all markdown files in a directory you can use a wildcard:\npandoc 00-zettelkasten/*.md --pdf-engine=wkhtmltopdf -o /tmp/test.pdf Fun fact: converting my entire zettelkasten took a few seconds and generated a document of 80 pages with a font size of 10. Pretty fun to see it in a more regular format instead of the terminal.\n","permalink":"https://mischavandenburg.com/zet/pandoc-markdown-pdf-macos/","summary":"It happens that I want to share my notes with friends that just simply want a pdf instead of a markdown file.\nThis morning I figured out a quick way to convert markdown to pdf on a M2 MacBook running MacOS Ventura.\nYou need the pandoc and wkhtmltopdf packages.\nbrew install pandoc wkhtmltopdf To convert:\npandoc 00-zettelkasten/Fundamentals\\ of\\ Bicep.md --pdf-engine=wkhtmltopdf -o /tmp/test.pdf This will output a pdf to my /tmp/ directory and it looks pretty good.","title":"Converting markdown to PDF on MacOS"},{"content":"Yesterday I reached a significant milestone. I ran my first 5K!\nI\u0026rsquo;ve always been on the heavy side. I did a lot of weightlifting from age 18 to around 27 and I was always rather bulky, but very strong. This meant I was very good at working in the woods or helping people move house, but I\u0026rsquo;ve never been able to do any running or endurance because my knees would start protesting very quickly. However, I always admired endurance athletes and I had the desire to be able to run more than a few minutes without feeling the urge to die on the spot.\nOver the past 1,5 years I lost 20kg (~44 pounds) so I decided to give it yet another try.\nI\u0026rsquo;ve never been this lightweight so I decided to give running another try. I started small with only 10 minutes but over the course of two months I built it up gradually.\nLast week I ran 4km and it felt pretty good, so I just decided to push a little bit more and try for my goal of 5k, and it went well! It feels like quite an accomplishment to me.\nNow that I lost all this weight running actually feels good, and it is liberating to discover a whole new area of exercise that I haven\u0026rsquo;t explored yet: endurance. Looking back to my progress over a couple of months, I\u0026rsquo;m curious how far I\u0026rsquo;ll come and what my limits are.\n","permalink":"https://mischavandenburg.com/zet/ran-5km/","summary":"Yesterday I reached a significant milestone. I ran my first 5K!\nI\u0026rsquo;ve always been on the heavy side. I did a lot of weightlifting from age 18 to around 27 and I was always rather bulky, but very strong. This meant I was very good at working in the woods or helping people move house, but I\u0026rsquo;ve never been able to do any running or endurance because my knees would start protesting very quickly.","title":"I ran 5K for the first time in my life!"},{"content":"Did some website housekeeping today. Spent the entire morning on a few tasks that I intended to do for a while. I added a search page and reorganized the menu, and I added a \u0026ldquo;Start Here\u0026rdquo; page.\nI hope that the new \u0026ldquo;Start Here\u0026rdquo; page will do a better job of explaining the how and why of my website, and that the search function will help you nagivate my website better.\n","permalink":"https://mischavandenburg.com/zet/website-housekeeping/","summary":"Did some website housekeeping today. Spent the entire morning on a few tasks that I intended to do for a while. I added a search page and reorganized the menu, and I added a \u0026ldquo;Start Here\u0026rdquo; page.\nI hope that the new \u0026ldquo;Start Here\u0026rdquo; page will do a better job of explaining the how and why of my website, and that the search function will help you nagivate my website better.","title":"Made Some Website Improvements"},{"content":"For weeks I\u0026rsquo;ve been debating with myself whether I should open up more on my blog. I spend my energy on two main pillars of my life: work and health, and up until now I\u0026rsquo;ve only been writing about work on my blog.\nwork I spend most of my waking hours sitting at my keyboard working on the command line: working, studying, coding, note taking. My life is focused around my career and I spend at at least 20 hours a week studying or learning new skills related to my career. When I made my career change I started to write this blog to document the process and share my learning with anyone who might find it useful\nhealth The other main pillar of my life is health. In 2017 my father suffered two very serious hard attacks in close succession, and nearly losing him really woke me up and made me focus on my health.\nI started eating a plant based diet and slowly reducing all the habits that were detrimental to my health, and increasing the activities that would promote my health. I quit drinking alcohol and I\u0026rsquo;ve been sober for nearly 5 years now.\nmental health I\u0026rsquo;m also very interested in mental health. I\u0026rsquo;ve done extensive studies of meditation and did several retreats. I\u0026rsquo;ve had a daily meditation practice going for 6 years now. I have a teacher and enjoy conversing about this topic with friends that have similar interests. I also practice yoga several times a week.\ndiet I spend a lot of time reading and researching what the optimal diet is for me. I\u0026rsquo;ve done a lot of experimentation. Not only what I eat, but also when I eat has been a subject of scrutiny for years now. I\u0026rsquo;ve been on some form of intermittent fasting protocol since 2015, and I\u0026rsquo;m currently eating only one meal a day.\nCaloric restriction has been shown to extend lifespan in many different organisms and I find it very intriguing. I\u0026rsquo;ve been on a weight loss journey since late 2021 and I find that restricting my calories gives me all sorts of benefits.\nsleep My life changed when I read Matt Walker\u0026rsquo;s book \u0026ldquo;Why We Sleep\u0026rdquo; and I\u0026rsquo;ve focused on sleep hygiene ever since. My average sleep over the last year is 7 hours a night (logged by my iWatch).\nexercise I recently ran my first 5k and I\u0026rsquo;m about to embark on a whole new exercise journey where I\u0026rsquo;ll be exploring my endurance limits.\nblog All of the topics above are interests of mine and I spent a lot of time researching them. I listen to podcasts, read books, discuss them with friends. And most importantly: I keep notes about them.\nSo if I\u0026rsquo;m happy to publish all of my work related notes with the world, why should I not share my other interests as well? I spend so much time gathering all this information and writing notes about them, and I feel that it might be useful to others who don\u0026rsquo;t wish to plough through all of the material and would like to read summaries of the information.\nThere are a few reasons why I\u0026rsquo;ve been hesitant to do so. seo I used to have websites that marketed products, and from those years of optimizing for sales I\u0026rsquo;ve gained some ingrained habits. These include keeping websites centered around one topic and repeating keywords throughout articles.\nThis blog was never intended for any sales or marketing, so I haven\u0026rsquo;t been writing with any SEO in mind which has been liberating, frankly. But I find that these ingrained habits have stopped me from broadening my scope for the blog.\ncentralization But keeping the website centered focused on one area has been a sticking point. I\u0026rsquo;ve always had the reader in mind, but also for selfish reasons. Colleagues and managers have pointed out that my blog is an excellent supplement to my CV. When I switched jobs recently, one hiring manager even offered me a job with a good salary solely based on my CV, my blog and one phone conversation.\nReaders of my blog might not necessarily be interested reading about my opinions and notes on health and exercise.\nIt\u0026rsquo;s my blog! In the end I decided to start writing more about my personal life and health interests. The whole point of starting my own website was to have the freedom of writing about what I want without limitations. I could have just written all my stuff on LinkedIn on other social media, but then you don\u0026rsquo;t own any of the content. What happens if you get banned for some reason? Or hacked? All your work is gone, which is why I chose my own website written in markdown files stored locally on my disk and hosted on GitHub.\nFrom the beginning I made sure to use a system where readers can filter on tags if they are looking for specific content. And honestly, who reads my stuff anyway? I know of one person who regularly reads my stuff (Hi, F!), but my blog is mostly a relaxing creative activity. I like scrolling through it and seeing the thoughts I captured, and to see it grow over time. And it helps me tremendously with learning information, because writing about topics is a great way to test whether I really understand the matter.\nIncluding my notes on other topics such as health and exercise will make my blog less focused and centralized around DevOps and tech, but it will reveal more about me as a person, and it will be fun to look back in the future and see my progress in these other areas as well. And I think that summaries of the research I do on these topics can actually be of use to others.\nSo I\u0026rsquo;ve decided to remove all limitations on topics for my blog and to just write about everything that I feel like publishing and sharing with the world.\n","permalink":"https://mischavandenburg.com/zet/articles/write-about-health-personal/","summary":"For weeks I\u0026rsquo;ve been debating with myself whether I should open up more on my blog. I spend my energy on two main pillars of my life: work and health, and up until now I\u0026rsquo;ve only been writing about work on my blog.\nwork I spend most of my waking hours sitting at my keyboard working on the command line: working, studying, coding, note taking. My life is focused around my career and I spend at at least 20 hours a week studying or learning new skills related to my career.","title":"Writing about Health and Personal Life"},{"content":"I do all of my writing in markdown. I keep my diaries in my Second Brain, I constantly write notes on the topics I\u0026rsquo;m studying, and my entire blog is written in markdown.\nSome of the writing is done in Obsidian but I\u0026rsquo;m moving away from Obsidian step by step. I\u0026rsquo;ll still keep my second brain compatible with it, but I want to be able to do all of my writing in (neo)vim.\nI\u0026rsquo;ve been using nvim-markdown for a while now and I was quite happy with it, but it was bothering me that bold text was not rendered in my editor.\nPandoc had been on my radar for a while because it uses the Commonmark markdown spec and it can be used to convert to many different documentation types. It\u0026rsquo;s an interesting thought to keep my entire collection of notes and writings compatible with something that can be converted into anything.\nI noticed rwxrob uses pandoc as one of his few vim plugins.\nIt took me an hour to make it compatible with neovim and to disable the spelling and folding. I couldn\u0026rsquo;t just set the provided variables because they are still in vimscript and I haven\u0026rsquo;t figured out how to set them yet because they use a hashtag in their name #\nSo far I like it, but there are a few things that I miss from my nvim-markdown\nautomatic bulleted list nested bulleted lists with nvim-markdown these lists would continue Here I have to indent each line myself and add a bullet navigation between headers I didn\u0026rsquo;t use this much to be honest, but I haven\u0026rsquo;t figured it out in pandoc yet. Maybe it is possible? I find myself using bullete lists and nested lists a lot in my notes, but I wonder if it is better to step away from those and make more use of markdown headings.\n","permalink":"https://mischavandenburg.com/zet/trying-out-pandoc/","summary":"I do all of my writing in markdown. I keep my diaries in my Second Brain, I constantly write notes on the topics I\u0026rsquo;m studying, and my entire blog is written in markdown.\nSome of the writing is done in Obsidian but I\u0026rsquo;m moving away from Obsidian step by step. I\u0026rsquo;ll still keep my second brain compatible with it, but I want to be able to do all of my writing in (neo)vim.","title":"Trying out pandoc for vim"},{"content":"[[neovim]]\nI find myself quoting words very often in vim when I\u0026rsquo;m writing bash code. I used to do this by simply navigating around the word and typing them, but I knew there had to be a better way.\nI found this vim command:\nciw\u0026quot;\u0026quot;\u0026lt;Esc\u0026gt;P\n\u0026ldquo;c\u0026rdquo; deletes into register and enters insert mode. \u0026ldquo;iw\u0026rdquo; stands for \u0026ldquo;inner word\u0026rdquo; and selects the word.\nSo we delete the entire word and enter insert mode. Then we type two quotes, and we press \u0026ldquo;P\u0026rdquo; to paste the register (containing the word) before the cursor.\nVoila, the word is surrounded by quotes.\nTo make it even easier, I added this to my keymaps, and I\u0026rsquo;ll add a few more for parentheses and brackets.\nvim.keymap.set(\u0026quot;n\u0026quot;, \u0026quot;\u0026lt;leader\u0026gt;wsq\u0026quot;, 'ciw\u0026quot;\u0026quot;\u0026lt;Esc\u0026gt;P', { desc = \u0026quot;Word Surround Quotes\u0026quot; })\nhttps://vi.stackexchange.com/questions/21113/vimscript-surround-word-under-cursor-with-quotes\n","permalink":"https://mischavandenburg.com/zet/surround-word-quotes-neovim/","summary":"[[neovim]]\nI find myself quoting words very often in vim when I\u0026rsquo;m writing bash code. I used to do this by simply navigating around the word and typing them, but I knew there had to be a better way.\nI found this vim command:\nciw\u0026quot;\u0026quot;\u0026lt;Esc\u0026gt;P\n\u0026ldquo;c\u0026rdquo; deletes into register and enters insert mode. \u0026ldquo;iw\u0026rdquo; stands for \u0026ldquo;inner word\u0026rdquo; and selects the word.\nSo we delete the entire word and enter insert mode.","title":"How to Surround a Word with Quotes in Vim"},{"content":"A module is generally associated with a single git repo.\nYou can have a module with multiple packages, and each package would get its own subdirectory.\nYou should always name your main file main.go\ncreating a module Use the go mod init {{your path here}} command to initiate a module.\nmultiple modules I was running into some trouble with this because I want to have one big repo where I will store all my go projects.\nMy gopls LSP in Neovim would start throwing errors when I added multiple projects in my repo.\nThe fix is to create a separate directory for each project. For example:\n/go/hello/main.go\n/go/hi/main.go\nHello and Hi are each separate projects.\nNow I enter each of these directories and run go mod init hello\nI\u0026rsquo;m sure this isn\u0026rsquo;t good practice for production code, but it serves its purpose to collect all my learning code in one place.\nhttps://www.youtube.com/watch?v=9hEnzD-bNy4\n","permalink":"https://mischavandenburg.com/zet/package-module-go/","summary":"A module is generally associated with a single git repo.\nYou can have a module with multiple packages, and each package would get its own subdirectory.\nYou should always name your main file main.go\ncreating a module Use the go mod init {{your path here}} command to initiate a module.\nmultiple modules I was running into some trouble with this because I want to have one big repo where I will store all my go projects.","title":"What is the difference between a Go module and a package?"},{"content":"Today was meal-prepping day and I cut up some vegetables for the coming week. I’m on a strict caloric restriction regimen and need to meticulously track and plan all the food that I consume.\nI cut up three kinds of vegetables and wrote down how many grams of each I cut up so I could divide them by three and add them to my calorie tracking application.\nAs I took out my phone to pick up my calculator to divide each number, my inner engineer started complaining about the fact that I had to do three calculations and that it would be much better to loop over an array of these values.\nI had my laptop nearby with a terminal open and wrote this instead:\nfor i in 287 252 321; do echo \u0026#34;$i / 3\u0026#34; | bc; done 95 84 107 After turning my passion into my career, I love the fact that I’m starting to think like an engineer in all my other areas of life. I’m also happy to see my progress in command line work. I chose to go the hard way, using bash instead of zsh and doing all my editing in vim and using Linux as much as possible, and it is paying off because I don’t have to think much about these little operations anymore.\nThen again, I would be much better off training my brain to become better at doing math without the aid of paper or calculators 🤓\nIf you\u0026rsquo;re curious about what a shokunin is, check out this article I wrote: https://mischavandenburg.com/zet/articles/jiro-sushi/\n","permalink":"https://mischavandenburg.com/zet/cli-shokunin-moment/","summary":"Today was meal-prepping day and I cut up some vegetables for the coming week. I’m on a strict caloric restriction regimen and need to meticulously track and plan all the food that I consume.\nI cut up three kinds of vegetables and wrote down how many grams of each I cut up so I could divide them by three and add them to my calorie tracking application.\nAs I took out my phone to pick up my calculator to divide each number, my inner engineer started complaining about the fact that I had to do three calculations and that it would be much better to loop over an array of these values.","title":"Had a CLI Shokunin Moment Today"},{"content":"I do all my coding and note taking in the terminal using tmux and neovim. I picked up a nice trick from Rob Muhlenstein today.\nYou can use this command in a split window to keep running a Go file. It will update when you save the file.\nentr -c bash -c \u0026quot;go run main.go\u0026quot; \u0026lt;\u0026lt;\u0026lt; main.go\nEntr runs commands when files change. Here we are feeding it only one file, but you can also feed it a directory like so:\nfind src/ | entr -s 'make'\nSuper handy to see the outcome of your code changes in real time.\nTo run all the files in the directory, use the following:\nentr -c bash -c \u0026quot;go run . \u0026quot; \u0026lt; \u0026lt;(find .)\nI picked this up while going through Rob\u0026rsquo;s Beginner Boost of 2022:\nhttps://youtu.be/kwrN3jbv4sE\n","permalink":"https://mischavandenburg.com/zet/running-go-on-change/","summary":"I do all my coding and note taking in the terminal using tmux and neovim. I picked up a nice trick from Rob Muhlenstein today.\nYou can use this command in a split window to keep running a Go file. It will update when you save the file.\nentr -c bash -c \u0026quot;go run main.go\u0026quot; \u0026lt;\u0026lt;\u0026lt; main.go\nEntr runs commands when files change. Here we are feeding it only one file, but you can also feed it a directory like so:","title":"How to continuously run a Go file while coding in the terminal"},{"content":"Deploying to subscriptions and management groups To tell Bicep which scope to deploy to, use the targetScope keyword, for example, managementGroup.\nYou\u0026rsquo;re not specifying which management group exactly, this is done during deployment of the template file.\ntargetScope can be set to resourceGroup, subscription, managementGroup or tenant.\nIf it is not set, Bicep assumes resourceGroup.\ncreate a resource group targetScope = \u0026#39;subscription\u0026#39; resource resourceGroup \u0026#39;Microsoft.Resources/resourceGroups@2021-01-01\u0026#39; = { name: \u0026#39;example-resource-group\u0026#39; location: \u0026#39;westus\u0026#39; } To deploy you use az deployment group create for resource groups, but you use az deployment sub create for subscriptions, mg for management group and tenant for tenant.\ndeployment scripts deploymentScripts resources are either PowerShell or Bash scripts that run in a Docker container as part of your template deployment. The default container images have either the Azure CLI or Azure PowerShell available. These scripts run during the processing of the ARM template, so you can add custom behavior to the deployment process.\nHere is an example of a deployment script with some comments:\nresource myFirstDeploymentScript \u0026#39;Microsoft.Resources/deploymentScripts@2020-10-01\u0026#39; = { name: \u0026#39;myFirstDeploymentScript\u0026#39; location: resourceGroup().location // can be AzurePowershell or Azure CLI kind: \u0026#39;AzurePowerShell\u0026#39; // the script will be run in a container. We need to provide a Managed Identity to give the script the required permissions identity: { type: \u0026#39;UserAssigned\u0026#39; userAssignedIdentities: { \u0026#39;/subscriptions/01234567-89AB-CDEF-0123-456789ABCDEF/resourcegroups/deploymenttest/providers/Microsoft.ManagedIdentity/userAssignedIdentities/myscriptingid\u0026#39;: {} } } properties: { azPowerShellVersion: \u0026#39;3.0\u0026#39; // in Bicep we use \u0026#39;\u0026#39;\u0026#39; to indicate a multi line string scriptContent: \u0026#39;\u0026#39;\u0026#39; $output = \u0026#39;Hello Learner!\u0026#39; Write-Output $output // the $DeploymentScriptOutputs variable is created to return output back to the Bicep template // It needs to be a hash table $DeploymentScriptOutputs = @{} $DeploymentScriptOutputs[\u0026#39;text\u0026#39;] = $output \u0026#39;\u0026#39;\u0026#39; retentionInterval: \u0026#39;P1D\u0026#39; } } output scriptResult string = myFirstDeploymentScript.properties.outputs.text You can also write deployment scripts in Bash. To create outputs from a Bash script, you need to create a JSON file in a location specified by the AZ_SCRIPTS_OUTPUT_PATH environment variable.\nTo include a script file, use the following:\nproperties: { azPowerShellVersion: \u0026#39;3.0\u0026#39; scriptContent: loadTextContent(\u0026#39;myscript.ps1\u0026#39;) retentionInterval: \u0026#39;P1D\u0026#39; } deploying a managed identity and assigning a role var userAssignedIdentityName = \u0026#39;configDeployer\u0026#39; var roleAssignmentName = guid(resourceGroup().id, \u0026#39;contributor\u0026#39;) var contributorRoleDefinitionId = resourceId(\u0026#39;Microsoft.Authorization/roleDefinitions\u0026#39;, \u0026#39;b24988ac-6180-42a0-ab88-20f7382dd24c\u0026#39;) resource userAssignedIdentity \u0026#39;Microsoft.ManagedIdentity/userAssignedIdentities@2018-11-30\u0026#39; = { name: userAssignedIdentityName location: resourceGroup().location } resource roleAssignment \u0026#39;Microsoft.Authorization/roleAssignments@2020-04-01-preview\u0026#39; = { name: roleAssignmentName properties: { roleDefinitionId: contributorRoleDefinitionId principalId: userAssignedIdentity.properties.principalId principalType: \u0026#39;ServicePrincipal\u0026#39; } } template specs When you have a lot of reusable templates, you can use Template Specs to enable your entire organization to deploy them.\nYou can convert a Bicep file to a template spec. The template spec is then deployed to Azure as a resource, and anybody with the right access and do deployments with the template spec from the portal or Azure CLI. Azure will handle the version control.\nYou will lose any comments and whitespace.\nBicep modules are intended to be combined into larger deployments. Template specs are for sets of resources with a certain configuration.\nTemplate specs can be used as a Bicep module. You use the following code to import it:\nmodule storageAccountTemplateSpec \u0026#39;ts:f0750bbe-ea75-4ae5-b24d-a92ca601da2c/sharedTemplates/StorageWithoutSAS:1.0\u0026#39; = { name: \u0026#39;storageAccountTemplateSpec\u0026#39; } ","permalink":"https://mischavandenburg.com/zet/advanced-bicep/","summary":"Deploying to subscriptions and management groups To tell Bicep which scope to deploy to, use the targetScope keyword, for example, managementGroup.\nYou\u0026rsquo;re not specifying which management group exactly, this is done during deployment of the template file.\ntargetScope can be set to resourceGroup, subscription, managementGroup or tenant.\nIf it is not set, Bicep assumes resourceGroup.\ncreate a resource group targetScope = \u0026#39;subscription\u0026#39; resource resourceGroup \u0026#39;Microsoft.Resources/resourceGroups@2021-01-01\u0026#39; = { name: \u0026#39;example-resource-group\u0026#39; location: \u0026#39;westus\u0026#39; } To deploy you use az deployment group create for resource groups, but you use az deployment sub create for subscriptions, mg for management group and tenant for tenant.","title":"Notes: Advanced Bicep"},{"content":"The past few days I\u0026rsquo;ve been trying out a few options to run Docker containers and a Kubernetes clusters on my new MacBook Pro M2.\nUnfortunately you can\u0026rsquo;t just run brew install docker and expect it to work. Additionally, Docker desktop requires that you purchase a license if you use it for work purposes.\nMinikube works fine as well, but the networking driver for qemu is not fully supported yet, and I haven\u0026rsquo;t tried any of the other alternatives because I found something better.\nRancher Desktop provides everything that you need. It sets up a local VM where it will run a Kubernetes cluster using k3s. It will configure the containerd container engine for you which you can interact with using nerdctl.\nTo install:\nbrew install rancher #after installing rancher, start it up and wait for it to boot the VM. alias docker=nerdctl docker run hello-world And you\u0026rsquo;re good to go. Rancher will add the rancher-desktop to your kube context.\nTo test your Kubernetes cluster:\nk get pods k get nodes # test running a pod k run nginx --image=nginx k expose pod nginx --port=80 --type=NodePort # inspect your services and look for 80:31066/TCP under PORT(S) k get svc curl localhost:31066 Or visit localhost:31066 in your browser. Replace 31066 with the port you found listed under your services.\n","permalink":"https://mischavandenburg.com/zet/docker-kubernetes-on-mac-m2/","summary":"The past few days I\u0026rsquo;ve been trying out a few options to run Docker containers and a Kubernetes clusters on my new MacBook Pro M2.\nUnfortunately you can\u0026rsquo;t just run brew install docker and expect it to work. Additionally, Docker desktop requires that you purchase a license if you use it for work purposes.\nMinikube works fine as well, but the networking driver for qemu is not fully supported yet, and I haven\u0026rsquo;t tried any of the other alternatives because I found something better.","title":"Running Docker and Kubernetes on Mac M2"},{"content":"Today I finished the Intermediate Bicep module. Here are my notes.\nChild and Extension You can also use Bicep to refer to resources that were created outside the Bicep file itself. For example, you can refer to resources that your colleagues have created manually by using the Azure portal, or from within another Bicep template or module, even if they\u0026rsquo;re in a different resource group or subscription. By using these features of Bicep, you can unlock the ability to create powerful templates that deploy all aspects of your Azure infrastructure.\nSome resources are only deployed in context of their parent. For example:\nVirtual network subnets Microsoft.Network/virtualNetworks/subnets App Service configuration Microsoft.Web/sites/config SQL databases Microsoft.Sql/servers/databases Virtual machine extensions Microsoft.Compute/virtualMachines/extensions Storage blob containers Microsoft.Storage/storageAccounts/blobServices/containers Azure Cosmos DB containers\nIt does not make sense for a container to exist without a storage account.\nDifference between child and extension In summary, you define extensions with the scope keyword, and child resources are defined by nesting them or by using the parent keyword.\nAn extension resource is a resource that modifies another resource. For example, assigning a role to a resource.\nA child resource is a resource that exists only within the context of another resource, such as a subnet existing only within a vnet.\nNested resource resource vm \u0026#39;Microsoft.Compute/virtualMachines@2020-06-01\u0026#39; = { name: vmName location: location properties: { // ... } resource installCustomScriptExtension \u0026#39;extensions\u0026#39; = { name: \u0026#39;InstallCustomScript\u0026#39; location: location properties: { // ... } } } Here the extension resource is within the vm resource. The fully qualified domain name is Microsoft.Compute/virtualMachines/extensions, but it is not necessary because it inherits it from the parent. Therefore we only need to specify \u0026rsquo;extensions\u0026rsquo; here.\nNo API version is specified either, this is also inherited.\nYou can refer to a nested resource by using the :: operator. For example, you could create an output that will return the full resource ID of the extension:\noutput childResourceId string = vm::installCustomScriptExtension.id Parent property This is the second way to declare a child resource.\nresource vm \u0026#39;Microsoft.Compute/virtualMachines@2020-06-01\u0026#39; = { name: vmName location: location properties: { // ... } } resource installCustomScriptExtension \u0026#39;Microsoft.Compute/virtualMachines/extensions@2020-06-01\u0026#39; = { parent: vm name: \u0026#39;InstallCustomScript\u0026#39; location: location properties: { // ... } } dependsOn use dependsOn to indicate a dependency.\ndependsOn: [ vm ] Extension resources Extension resources are always attached to other Azure resources. They extend them with extra functionality. Some examples are role assignments, locks, and policy assignments.\nIt doesn\u0026rsquo;t make sense to deploy a lock by itself. It always has to be deployed to another resource, because it prevents deletion or modification of a resource.\nResources are defined almost the same way as normal resources, but you add the scope property to tell Bicep that it is attached to another resource in the template.\nresource cosmosDBAccount \u0026#39;Microsoft.DocumentDB/databaseAccounts@2020-04-01\u0026#39; = { name: cosmosDBAccountName location: location properties: { // ... } } resource lockResource \u0026#39;Microsoft.Authorization/locks@2016-09-01\u0026#39; = { scope: cosmosDBAccount name: \u0026#39;DontDelete\u0026#39; properties: { level: \u0026#39;CanNotDelete\u0026#39; notes: \u0026#39;Prevents deletion of the toy data Cosmos DB account.\u0026#39; } } Extensions have slightly different resource ID\u0026rsquo;s. They consist of the parent resource ID, the separator /providers/, and the extension resource ID.\nIf you see a resource ID that starts with a normal resource ID and then adds /providers/ and another resource type and name, it means that you\u0026rsquo;re looking at an extension resource ID.\nExisting resources Bicep files often need to refer to resources that have been already created elswewhere. They might have been created in the portal or by another Bicep file.\nHere you use the existing keyword in Bicep. You are defining a resource that already exists, and therefore you are telling Bicep that it shouldn\u0026rsquo;t try to deploy it. Think of it as a placeholder resource.\nYou can do the same for nested or child resources.\nresource storageAccount \u0026#39;Microsoft.Storage/storageAccounts@2019-06-01\u0026#39; existing = { name: \u0026#39;toydesigndocs\u0026#39; } Existing resources outside of the resource group and subscription resource vnet \u0026#39;Microsoft.Network/virtualNetworks@2020-11-01\u0026#39; existing = { scope: resourceGroup(\u0026#39;f0750bbe-ea75-4ae5-b24d-a92ca601da2c\u0026#39;, \u0026#39;networking-rg\u0026#39;) name: \u0026#39;toy-design-vnet\u0026#39; } You can refer to these as long as they are within your Azure AD tenant.\nAdd child and extension resources to an existing resource resource server \u0026#39;Microsoft.Sql/servers@2020-11-01-preview\u0026#39; existing = { name: serverName } resource database \u0026#39;Microsoft.Sql/servers/databases@2020-11-01-preview\u0026#39; = { parent: server name: databaseName location: location sku: { name: \u0026#39;Standard\u0026#39; tier: \u0026#39;Standard\u0026#39; } } Use the existing keyword to refer to the resource, and then you add the child by specifying the parent property.\nFinally, to deploy an extension resource to an existing resource, use the scope keyword:\nresource storageAccount \u0026#39;Microsoft.Storage/storageAccounts@2019-06-01\u0026#39; existing = { name: \u0026#39;toydesigndocs\u0026#39; } resource lockResource \u0026#39;Microsoft.Authorization/locks@2016-09-01\u0026#39; = { scope: storageAccount name: \u0026#39;DontDelete\u0026#39; properties: { level: \u0026#39;CanNotDelete\u0026#39; notes: \u0026#39;Prevents deletion of the toy design documents storage account.\u0026#39; } } Referring to an existing resource\u0026rsquo;s properties Define the resource and you can refer to its properties if the prperty isn\u0026rsquo;t secure.\nresource applicationInsights \u0026#39;Microsoft.Insights/components@2018-05-01-preview\u0026#39; existing = { name: applicationInsightsName } resource functionApp \u0026#39;Microsoft.Web/sites@2020-06-01\u0026#39; = { name: functionAppName location: location kind: \u0026#39;functionapp\u0026#39; properties: { siteConfig: { appSettings: [ // ... { name: \u0026#39;APPINSIGHTS_INSTRUMENTATIONKEY\u0026#39; value: applicationInsights.properties.InstrumentationKey } ] } } } When you need to access secure data, use the listKeys() function.\nresource storageAccount \u0026#39;Microsoft.Storage/storageAccounts@2019-06-01\u0026#39; existing = { name: storageAccountName } resource functionApp \u0026#39;Microsoft.Web/sites@2020-06-01\u0026#39; = { name: functionAppName location: location kind: \u0026#39;functionapp\u0026#39; properties: { siteConfig: { appSettings: [ // ... { name: \u0026#39;StorageAccountKey\u0026#39; value: storageAccount.listKeys().keys[0].value } ] } } } The VScode extension will show hints to help you understand the data this function returns.\nYou need to have sufficient permissions to use the listKeys function.\nChild and extension In this example we are attaching an extension to a child resource.\nresource storageAccount \u0026#39;Microsoft.Storage/storageAccounts@2019-06-01\u0026#39; existing = { name: storageAccountName resource blobService \u0026#39;blobServices\u0026#39; existing = { name: \u0026#39;default\u0026#39; } } /* Note: Here we are attaching to blobServices which itself is a child resource. So we are attaching an extension to a child resource. */ resource storageAccountBlobDiagnostics \u0026#39;Microsoft.Insights/diagnosticSettings@2017-05-01-preview\u0026#39; = { scope: storageAccount::blobService name: storageAccountBlobDiagnosticSettingsName properties: { workspaceId: logAnalyticsWorkspace.id logs: [ { category: \u0026#39;StorageRead\u0026#39; enabled: true } { category: \u0026#39;StorageWrite\u0026#39; enabled: true } { category: \u0026#39;StorageDelete\u0026#39; enabled: true } ] } } Structuring Bicep for Collaboration configuration maps Using many different parameters can be confusing to the user of the template you\u0026rsquo;re writing. One way of solving this is by creating a config map:\n@allowed([ \u0026#39;Production\u0026#39; \u0026#39;Test\u0026#39; ]) param environmentType string = \u0026#39;Test\u0026#39; var environmentConfigurationMap = { Production: { appServicePlan: { sku: { name: \u0026#39;P2V3\u0026#39; capacity: 3 } } storageAccount: { sku: { name: \u0026#39;ZRS\u0026#39; } } } Test: { appServicePlan: { sku: { name: \u0026#39;S2\u0026#39; capacity: 1 } } storageAccount: { sku: { name: \u0026#39;LRS\u0026#39; } } } } resource appServicePlan \u0026#39;Microsoft.Web/serverfarms@2020-06-01\u0026#39; = { name: appServicePlanName location: location sku: environmentConfigurationMap[environmentType].appServicePlan.sku } Here we are taking a parameter for the environment, but create an object that contains the settings for that particular environment. Note that we are accessing it like we\u0026rsquo;d access a dictionary in python: sku: environmentConfigurationMap[environmentType].appServicePlan.sku\nNaming In Bicep, you ordinarily use camelCase capitalization style for the names of parameters, variables, and resource symbolic names.\nResource names cannot be renamed after they\u0026rsquo;re deployed in Azure.\nComments use // for single line comments, and /* */ for multi-line comments.\nWhen adding comments to JSON files, you might have to save the file as jsonc to let the code editor know that comments are allowed.\n","permalink":"https://mischavandenburg.com/zet/intermediate-bicep/","summary":"Today I finished the Intermediate Bicep module. Here are my notes.\nChild and Extension You can also use Bicep to refer to resources that were created outside the Bicep file itself. For example, you can refer to resources that your colleagues have created manually by using the Azure portal, or from within another Bicep template or module, even if they\u0026rsquo;re in a different resource group or subscription. By using these features of Bicep, you can unlock the ability to create powerful templates that deploy all aspects of your Azure infrastructure.","title":"Notes: Intermediate Bicep"},{"content":"I\u0026rsquo;ll be working with Bicep during my next contract, so I\u0026rsquo;m working through the Bicep modules on Microsoft Learn to prepare. I must say that these modules are particularly helpful. They are well structured and they provide you with free sandbox environments to practice deploying the templates you create.\nWhy Bicep? Resources in Azure are deployed by the Azure Resource Manager (ARM). These resources are JSON objects under the covers, and ARM templates are a way to generate these JSON objects. However, JSON is not really meant to be edited by humans, and the ARM templates are not very suitable for editing either. Thus, Bicep was developed to allow for a better editing experience and better readability and reusability.\nBicep templates are transpiled into JSON objects, which are sent to the Azure API to create resources with the Azure Resource Manager.\nFundamentals of Bicep Notes A parameter lets you bring in values from outside the template file. For example, if someone is manually deploying the template by using the Azure CLI or Azure PowerShell, they\u0026rsquo;ll be asked to provide values for each parameter. They can also create a parameter file, which lists all of the parameters and values they want to use for the deployment. If the template is deployed from an automated process like a deployment pipeline, the pipeline can provide the parameter values.\nA variable is defined and set within the template. Variables let you store important information in one place and refer to it throughout the template without having to copy and paste it.\ngenerating unique names Bicep has another function called uniqueString() that comes in handy when you\u0026rsquo;re creating resource names. When you use this function, you need to provide a seed value, which should be different across different deployments but consistent across all deployments of the same resources.\nparam storageAccountName string = uniqueString(resourceGroup().id) Every time you deploy the same resources, they\u0026rsquo;ll go into the same resource group. The uniqueString() function will return the same value every time. If you deploy into two different resource groups in the Azure subscription, the resourceGroup().id value will be different, because the resource group names will be different. The uniqueString() function will give different values for each set of resources. If you deploy into two different Azure subscriptions, even if you use the same resource group name, the resourceGroup().id value will be different because the Azure subscription ID will be different. The uniqueString() function will again give different values for each set of resources. combining strings Can use string interpolation to generate a unique string with a recognizable hardcoded part:\nparam storageAccountName string = 'toylaunch${uniqueString(resourceGroup().id)}'\nThis can also be handy for generating correct names. For example, storage accounts may not begin with a number.\nparameter decorators allowed parameters @allowed([ \u0026#39;nonprod\u0026#39; \u0026#39;prod\u0026#39; ]) param environmentType string The template cannot be deployed unless the nonprod or prod values are provided.\n@allowed is a parameter decorator: it gives Bicep information on what the parameter\u0026rsquo;s value needs to be.\nYou can also specify the allowed length of the parameter by using the following decorators:\n@minLength(5) @maxLength(24) param storageAccountName string You can apply multiple decorators to a parameter by putting each on a separate line.\nThese min and maxLength decorators can also be used to limit the length of an array.\nTo limit int values:\n@minValue(1) @maxValue(10) param appServicePlanInstanceCount int Finally, you can add descriptions to your parameters with the @description decorator:\n@description(\u0026#39;The locations into which this Cosmos DB account should be configured. This parameter needs to be a list of objects, each of which has a locationName property.\u0026#39;) param cosmosDBAccountLocations array if statements var storageAccountSkuName = (environmentType == \u0026#39;prod\u0026#39;) ? \u0026#39;Standard_GRS\u0026#39; : \u0026#39;Standard_LRS\u0026#39; var appServicePlanSkuName = (environmentType == \u0026#39;prod\u0026#39;) ? \u0026#39;P2V3\u0026#39; : \u0026#39;F1\u0026#39; Let\u0026rsquo;s unpack this:\n? is a ternary operator and evaluates an if/then statement. The value after ? is used if the expression is true. If it\u0026rsquo;s false, the value after : is used.\nSo here, if the environmentType is prod, the SKU is set to Standard_GRS\nObjects in Bicep You can use objects within resource definitions, within variables, or within expressions in your Bicep file.\nObjects are the same as dictionaries in python:\nparam appServicePlanSku object = { name: \u0026#39;F1\u0026#39; tier: \u0026#39;Free\u0026#39; capacity: 1 } These are called \u0026ldquo;properties\u0026rdquo; of type string and int. Note that they are line separated, not comma separated like in python.\nWhen referencing the parameter in the template, you can use dot notation to access the object properties:\nresource appServicePlan \u0026#39;Microsoft.Web/serverfarms@2022-03-01\u0026#39; = { name: appServicePlanName location: location sku: { name: appServicePlanSku.name tier: appServicePlanSku.tier capacity: appServicePlanSku.capacity } } [!important] Keep in mind that you don\u0026rsquo;t specify the type of each property within an object. However, when you use a property\u0026rsquo;s value, its type must match what\u0026rsquo;s expected. In the previous example, both the name and the tier of the App Service plan SKU must be strings.\nExample: tags param resourceTags object = { EnvironmentName: \u0026#39;Test\u0026#39; CostCenter: \u0026#39;1000100\u0026#39; Team: \u0026#39;Human Resources\u0026#39; } resource appServicePlan \u0026#39;Microsoft.Web/serverfarms@2022-03-01\u0026#39; = { name: appServicePlanName location: location tags: resourceTags sku: { name: \u0026#39;S1\u0026#39; } } resource appServiceApp \u0026#39;Microsoft.Web/sites@\u0026#39; = { name: appServiceAppName location: location tags: resourceTags kind: \u0026#39;app\u0026#39; properties: { serverFarmId: appServicePlan.id } } Here we take the tags for all the resources of the template as parameters. But we easily reuse all the tags for each resource by referencing the entire object.\nArrays Arrays are not typed in Bicep. You cannot specify that it must contain strings.\nExample:\nparam cosmosDBAccountLocations array = [ { locationName: \u0026#39;australiaeast\u0026#39; } { locationName: \u0026#39;southcentralus\u0026#39; } { locationName: \u0026#39;westeurope\u0026#39; } ] This is an array of objects, which have an locationName property each.\nAnd you would access it by:\nresource account \u0026#39;Microsoft.DocumentDB/databaseAccounts@2022-08-15\u0026#39; = { name: accountName location: location properties: { locations: cosmosDBAccountLocations } } Specifying parameter values When deploying a template file there are three options:\ndefault values command line parameter file Parameter file This is a json file. To deploy a template with a paramter file, use:\naz deployment group create \\ --template-file main.bicep \\ --parameters main.parameters.json priority The order of priority is this, from high to low priority:\nParameters specified on the command line Parameter file Default values in template Securing parameters It is best to use Managed Identities for Azure, but if you need to supply secret values to a deployment, use the @secure() decorator. These values aren\u0026rsquo;t available in the deployment logs, and they won\u0026rsquo;t be displayed on the screen when entered in the terminal.\nLoops Defined with the for keyword. Usually you iterate over an array to create multiple instances of a resource.\nCopy loops param storageAccountNames array = [ \u0026#39;saauditus\u0026#39; \u0026#39;saauditeurope\u0026#39; \u0026#39;saauditapac\u0026#39; ] resource storageAccountResources \u0026#39;Microsoft.Storage/storageAccounts@2021-09-01\u0026#39; = [for storageAccountName in storageAccountNames: { name: storageAccountName location: resourceGroup().location kind: \u0026#39;StorageV2\u0026#39; sku: { name: \u0026#39;Standard_LRS\u0026#39; } }] Notice that bicep requires \u0026ldquo;[\u0026rdquo; before the for, and a closing bracket.\ncount loops resource storageAccountResources \u0026#39;Microsoft.Storage/storageAccounts@2021-09-01\u0026#39; = [for i in range(1,4): { name: \u0026#39;sa${i}\u0026#39; location: resourceGroup().location kind: \u0026#39;StorageV2\u0026#39; sku: { name: \u0026#39;Standard_LRS\u0026#39; } }] The range function takes two arguments. The first one specifies the starting value, and the second tells Bicep the number of values you want.\nIf you use range(3,4), you will get 3, 4, 5 and 6.\naccessing the index param locations array = [ \u0026#39;westeurope\u0026#39; \u0026#39;eastus2\u0026#39; \u0026#39;eastasia\u0026#39; ] resource sqlServers \u0026#39;Microsoft.Sql/servers@2021-11-01-preview\u0026#39; = [for (location, i) in locations: { name: \u0026#39;sqlserver-${i+1}\u0026#39; location: location properties: { administratorLogin: administratorLogin administratorLoginPassword: administratorLoginPassword } }] The first value is zero, so you can add 1 to i if you want your names to be sqlserver-1, sqlserver-2 etc.\ni is used here, but you can use any value you want.\nFiltering with loops param sqlServerDetails array = [ { name: \u0026#39;sqlserver-we\u0026#39; location: \u0026#39;westeurope\u0026#39; environmentName: \u0026#39;Production\u0026#39; } { name: \u0026#39;sqlserver-eus2\u0026#39; location: \u0026#39;eastus2\u0026#39; environmentName: \u0026#39;Development\u0026#39; } { name: \u0026#39;sqlserver-eas\u0026#39; location: \u0026#39;eastasia\u0026#39; environmentName: \u0026#39;Production\u0026#39; } ] resource sqlServers \u0026#39;Microsoft.Sql/servers@2021-11-01-preview\u0026#39; = [for sqlServer in sqlServerDetails: if (sqlServer.environmentName == \u0026#39;Production\u0026#39;) { name: sqlServer.name location: sqlServer.location properties: { administratorLogin: administratorLogin administratorLoginPassword: administratorLoginPassword } tags: { environment: sqlServer.environmentName } }] This will deploy -we and -eas, but not -eus2, because the environmentName does not match Production.\nControlling loop execution By default all the iterations of a loop are executed simultaneously. However, you don\u0026rsquo;t always want this to be happening.\nTo control the amount you can use the @batchSize decorator.\n@batchSize(2) resource appServiceApp \u0026#39;Microsoft.Web/sites@2021-03-01\u0026#39; = [for i in range(1,3): { name: \u0026#39;app${i}\u0026#39; // ... }] Here bicep will wait for the first two to be fully completed before it moves to the next.\nTo loop sequentially, meaning one at a time in order, use @batchSize(1)\nVariable loops You can use loops to create arrays that you can use in the Bicep template.\nvar items = [for i in range(1, 5): \u0026#39;item${i}\u0026#39;] This produces an array containing the values item1, item2 up to 5 stored in the items variable.\nReminds me of list comprehensions in python.\nHere is an example:\nparam addressPrefix string = \u0026#39;10.10.0.0/16\u0026#39; param subnets array = [ { name: \u0026#39;frontend\u0026#39; ipAddressRange: \u0026#39;10.10.0.0/24\u0026#39; } { name: \u0026#39;backend\u0026#39; ipAddressRange: \u0026#39;10.10.1.0/24\u0026#39; } ] var subnetsProperty = [for subnet in subnets: { name: subnet.name properties: { addressPrefix: subnet.ipAddressRange } }] resource virtualNetwork \u0026#39;Microsoft.Network/virtualNetworks@2021-08-01\u0026#39; = { name: \u0026#39;teddybear\u0026#39; location: resourceGroup().location properties:{ addressSpace:{ addressPrefixes:[ addressPrefix ] } subnets: subnetsProperty } } The content of the subnetsProperty array would look like this:\n[ { name: \u0026#39;frontend\u0026#39;, properties: { addressPrefix: \u0026#39;10.10.0.0/24\u0026#39; } }, { name: \u0026#39;backend\u0026#39;, properties: { addressPrefix: \u0026#39;10.10.1.0/24\u0026#39; } } ] Output loops To output the contents of the array:\nvar items = [ \u0026#39;item1\u0026#39; \u0026#39;item2\u0026#39; \u0026#39;item3\u0026#39; \u0026#39;item4\u0026#39; \u0026#39;item5\u0026#39; ] output outputItems array = [for i in range(0, length(items)): items[i]] Modules You can create modules in Bicep so the code becomes reusable. You can share the modules with other teams and use them for different outcomes.\nGenerally, it\u0026rsquo;s not a good practice to create a module for every resource that you deploy. A good Bicep module typically defines multiple related resources. However, if you have a particularly complex resource with a lot of configuration, it might make sense to create a single module to encapsulate the complexity. This approach keeps your main templates simple and uncluttered.\nSo for example it would make sense to write a networking module and a database module that handles these resources.\nModules can be nested, but it can quickly become very complex.\nTo call a module in a template:\nmodule appModule \u0026#39;modules/app.bicep\u0026#39; = { name: \u0026#39;myApp\u0026#39; params: { location: location appServiceAppName: appServiceAppName environmentType: environmentType } } The modules are stored in the modules folder in your root directory.\nParameters Modules will take parameters, but it is good practice to leave out default values for parameters in modules. In templates it\u0026rsquo;s good practice to add defaults wherever you can. Therefore it is best to leave them out in modules because templates usually have their own default values. This can get confusing if you have similar default values in the templates and modules.\nModule dependency Bicep will figure out automatically if there is a dependency between modules. For example:\n@description(\u0026#39;Username for the virtual machine.\u0026#39;) param adminUsername string @description(\u0026#39;Password for the virtual machine.\u0026#39;) @minLength(12) @secure() param adminPassword string module virtualNetwork \u0026#39;modules/vnet.bicep\u0026#39; = { name: \u0026#39;virtual-network\u0026#39; } module virtualMachine \u0026#39;modules/vm.bicep\u0026#39; = { name: \u0026#39;virtual-machine\u0026#39; params: { adminUsername: adminUsername adminPassword: adminPassword subnetResourceId: virtualNetwork.outputs.subnetResourceId } } Here the virtualMachine module takes the subnetResourceId from the virtualNetwork module outputs.\nBecause it is defined like this, Bicep will wait with deploying the virtualMachine modul until the virtualNetwork module is finished, and pass in the required parameter.\nIt is important to note that this means that it will wait until the virtualNetwork module is completely finished. If it takes a long time to deploy the previous module, all the subsequent modules will have to wait until it\u0026rsquo;s finished.\n","permalink":"https://mischavandenburg.com/zet/articles/fundamentals-of-bicep/","summary":"I\u0026rsquo;ll be working with Bicep during my next contract, so I\u0026rsquo;m working through the Bicep modules on Microsoft Learn to prepare. I must say that these modules are particularly helpful. They are well structured and they provide you with free sandbox environments to practice deploying the templates you create.\nWhy Bicep? Resources in Azure are deployed by the Azure Resource Manager (ARM). These resources are JSON objects under the covers, and ARM templates are a way to generate these JSON objects.","title":"Notes: Fundamentals of Bicep"},{"content":"The CTO of my new company recommended the Udemy course \u0026ldquo;Go: The Complete Developer\u0026rsquo;s Guide (Golang)\u0026rdquo;. I started today and here are some notes I made.\nHello World in Go We start by writing a Hello World and studying all the elements.\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World!\u0026#34;) } How do we run code? go run main.go runs the program go build main.go compiles it to an executable\nWhat does package main mean? package main\nA package is a collection of common source code files.\nOne app is a package. If you have multiple files in a folder, such as helper.go or support.go, they should have package main to indicate that they belong to package main.\n*Why do we call it main?\nThere are two types of packages.\nexecutable generates file that can be run reusable used as \u0026ldquo;helpers\u0026rdquo; reusable logic When you call the package main, you are telling the compiler it needs to be compiled as an executable. If it has a different name, it won\u0026rsquo;t generate an executable. Main is sacred.\nAny other name is a reusable or dependency type package (helper code).\nAnother important point is that whenever you create an executable package, it must always have a func called \u0026lsquo;main\u0026rsquo;.\nWhat does import fmt mean? The import statement is used to give our package access to code written in another package. You are saying \u0026ldquo;give access to all code in fmt\u0026rdquo;. Fmt is a standard library package included in Go. Short for format. Used to print out information to the terminal.\nOther packages included in the standard library of go are debug, math, encoding, crypto, io.\ngolang.org/pkg for documentation on standard library packages for Go.\nA lot of learning go is learning the standard packages and how they work.\nOrganizing the main.go file It is the same for every go file, just like the code example at the top of the page. Package main, import fmt, and func main.\nvariable declarations var card string = \u0026quot;Ace of Spades\u0026quot;\nvar: we are about to create a new variable\ncard: name\nstring = telling the go compiler that only strings will be assigned to this variable\nAlternatively: card := \u0026quot;Ace of Spades\u0026quot;\nHere you are relying on the compiler to figure out what type it is.\nCompiler will infer the type.\nWe only use this := assignment for new variables\nIf you want to assign a value to a variable after it is declared, you just do card = \u0026quot;Five of Diamonds\u0026quot;\nGo types Go is a statically typed language.\nJavascript, python are dynamically typed language. We don\u0026rsquo;t care what value is assigned to a variable.\nYou always a assign a type to a variable in Go.\nBasic go types:\nbool string into float64 : a number with a decimal after it. ","permalink":"https://mischavandenburg.com/zet/go-day-1/","summary":"The CTO of my new company recommended the Udemy course \u0026ldquo;Go: The Complete Developer\u0026rsquo;s Guide (Golang)\u0026rdquo;. I started today and here are some notes I made.\nHello World in Go We start by writing a Hello World and studying all the elements.\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello World!\u0026#34;) } How do we run code? go run main.go runs the program go build main.go compiles it to an executable","title":"Learning Go Day 1: Notes"},{"content":"For month\u0026rsquo;s I considered to learn Go, and today I finally started.\nI doubted for a long time, because I figured it would be better to dive deeper into Python. However, when I reflected on it, I realized I\u0026rsquo;m able to do the things I want to do in Python. I can create scripts to manipulate data, and I can string different tools and libraries together if I need to. So how deep do I actually need to go as a DevOps Engineer?\nThe breakthrough came when I discovered this website: Good First Issue. It\u0026rsquo;s a collection of issues in open source projects which are suitable for people who are starting out. Scrolling through the available projects for Python and Go, I noticed I got a lot more energy from the things I saw in the Go list: Grafana, ArgoCD, Kubernetes. I probably have a long way to go before I can make any meaningful contributions, but my goal is to be able to contribute to open source in the future.\nAdditionally, I\u0026rsquo;m going to focus my career in the direction of Kubernetes and CNCF, where Go is mostly used.\nI have a week off before I start my new job so I\u0026rsquo;m going to spend a few hours a day to get a good start, and when I\u0026rsquo;m working full time again, my plan is to spend at least one pomodoro (25 minutes) a day on Go. Small increments will add up to something big over time.\nI created a new GitHub repo where I\u0026rsquo;ll be uploading all my practice code and projects.\n","permalink":"https://mischavandenburg.com/zet/start-learning-go/","summary":"For month\u0026rsquo;s I considered to learn Go, and today I finally started.\nI doubted for a long time, because I figured it would be better to dive deeper into Python. However, when I reflected on it, I realized I\u0026rsquo;m able to do the things I want to do in Python. I can create scripts to manipulate data, and I can string different tools and libraries together if I need to. So how deep do I actually need to go as a DevOps Engineer?","title":"I started to learn Go!"},{"content":"I\u0026rsquo;m a little obsessed with controlling everything with my keyboard. That\u0026rsquo;s why I loved AwesomeWM so much on my Arch Linux setup, I hardly used my mouse anymore.\nOne thing I loved about my setup was the ability to control my music from the keyboard from anywhere. This is a feature I picked up from the awesome-copycats theme for AwesomeWM. This was one of the first things I missed when I made my switch to MacOS.\nI started using Apple Music as my music app but it does not have any global hotkeys, and it makes you use a widget with the mouse.\nskhd I solved the problem using skhd. This is a free hotkey daemon for MacOS. To install:\nbrew install koekeishiya/formulae/skhd brew services start skhd Then I added the following to my skhd config file:\n# Control apple music globally # Based on Aesome-copycats theme for AesomeWM ctrl + cmd + fn - up : osascript -e \u0026#39;tell app \u0026#34;Music\u0026#34; to playpause\u0026#39; ctrl + cmd + fn - left : osascript -e \u0026#39;tell app \u0026#34;Music\u0026#34; to back track\u0026#39; ctrl + cmd + fn - right : osascript -e \u0026#39;tell app \u0026#34;Music\u0026#34; to play next track\u0026#39; links https://github.com/koekeishiya/skhd\n","permalink":"https://mischavandenburg.com/zet/apple-music-hotkeys/","summary":"I\u0026rsquo;m a little obsessed with controlling everything with my keyboard. That\u0026rsquo;s why I loved AwesomeWM so much on my Arch Linux setup, I hardly used my mouse anymore.\nOne thing I loved about my setup was the ability to control my music from the keyboard from anywhere. This is a feature I picked up from the awesome-copycats theme for AwesomeWM. This was one of the first things I missed when I made my switch to MacOS.","title":"Controlling Apple Music with hotkeys from anywhere on MacOS"},{"content":"My new employer kindly sponsored me with a new 16-inch MacBook Pro M2. I chose 32GB Ram and the base model with 12 CPU and 19 GPU cores and 1TB of hard disk. These specifications will suit my needs well.\nI\u0026rsquo;ve been daily driving Linux for a year now, and it has been such an incredible journey. Building my own Arch Linux system taught me much about Linux and what it means to maintain a system yourself. I will undoubtedly miss my custom AwesomeWM configuration and the freedom that Arch provides.\nTechnically I could have chosen a Windows laptop and installed Linux on it. But I went for a Mac for the following reasons:\nCompatibility. I\u0026rsquo;ll be doing contracts for various customers, so I\u0026rsquo;ll likely run into environments where I\u0026rsquo;ll need to use some software, such as a VPN that is not supported on Linux. MacOS will always be compatible everywhere. Portability. I\u0026rsquo;ll probably be going to the office multiple times a week, and using a MacBook as a daily driver will allow me to take my full setup with me everywhere. I also plan to spend some time abroad, and using a MacBook as a daily driver will allow me to work remotely for extended periods. Stability. Even though my Linux systems never really broke on me, there is always a possibility. I don\u0026rsquo;t have to worry about that with MacOS. Even though I\u0026rsquo;ll be switching to my MacBook as my primary workstation, I will continue using Linux for my hobby projects and home lab. So there will be plenty of opportunity to keep growing in that area in the future.\n","permalink":"https://mischavandenburg.com/zet/move-to-macos/","summary":"My new employer kindly sponsored me with a new 16-inch MacBook Pro M2. I chose 32GB Ram and the base model with 12 CPU and 19 GPU cores and 1TB of hard disk. These specifications will suit my needs well.\nI\u0026rsquo;ve been daily driving Linux for a year now, and it has been such an incredible journey. Building my own Arch Linux system taught me much about Linux and what it means to maintain a system yourself.","title":"New Laptop: Moving to MacOS"},{"content":"Last week I accepted a job offer! I\u0026rsquo;ve been hired as a DevOps Engineer by Fullstaq.\nFullstaq specialises in Kubernetes and Cloud Native, so I\u0026rsquo;m really happy I could join their team. I\u0026rsquo;ll be doing projects for a variety of clients, and I think it will be a great place to learn and gain more experience in the Kubernetes and CNCF space.\nFullstaq has been delightfully welcoming and great to work with so far. The future looks bright!\n","permalink":"https://mischavandenburg.com/zet/new-job-2023/","summary":"Last week I accepted a job offer! I\u0026rsquo;ve been hired as a DevOps Engineer by Fullstaq.\nFullstaq specialises in Kubernetes and Cloud Native, so I\u0026rsquo;m really happy I could join their team. I\u0026rsquo;ll be doing projects for a variety of clients, and I think it will be a great place to learn and gain more experience in the Kubernetes and CNCF space.\nFullstaq has been delightfully welcoming and great to work with so far.","title":"New job!"},{"content":"This guide uses the official getting started guide with a few modifications. This installation is only for lab purposes. Running ArgoCD in a production environment requires more configuration.\nInstall argocd and argocd cli kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml My VM is running on arm architecture, so I need these commands to install the argocd cli on ubuntu.\ncurl -sSL -o argocd-linux-arm64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64 sudo install -m 555 argocd-linux-arm64 /usr/local/bin/argocd rm argocd-linux-arm64 Change the service type to LoadBalancer\nkubectl patch svc argocd-server -n argocd -p \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;LoadBalancer\u0026#34;}}\u0026#39; Retrieve your passsword\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 -d; echo Find out which port argocd-server is running on\nk get svc -A Look for the argocd-server and see where port 80 is mapped to. In my case, it is 80:31372.\nOpen this port in your network security group for your VM, and you should be able to log in on ArgoCD in the browser by entering the VM ip followed by the port:\nhttp://143.44.179.11:31372\nLinks https://argo-cd.readthedocs.io/en/stable/getting_started/\n","permalink":"https://mischavandenburg.com/zet/articles/lab-vm-install-argocd/","summary":"This guide uses the official getting started guide with a few modifications. This installation is only for lab purposes. Running ArgoCD in a production environment requires more configuration.\nInstall argocd and argocd cli kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml My VM is running on arm architecture, so I need these commands to install the argocd cli on ubuntu.\ncurl -sSL -o argocd-linux-arm64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64 sudo install -m 555 argocd-linux-arm64 /usr/local/bin/argocd rm argocd-linux-arm64 Change the service type to LoadBalancer","title":"Lab VM project - Install ArgoCD to your Kubernetes cluster"},{"content":"You can get a free 24GB ram VM from Oracle. What better place for your own Kubernetes lab that is always available? See this article to create your VM.\nHere are the steps I took to install a single node kubernetes cluster on the Ubuntu VM.\nInstallation sudo apt-get update sudo apt install apt-transport-https curl Install containerd\nsudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install containerd.io Remove the default containerd configuration, because it creates errors when running kubeadm init.\nsudo rm -f /etc/containerd/config.toml sudo systemctl status containerd.service Install Kubernetes\nsudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list sudo apt install kubeadm kubelet kubectl kubernetes-cni Avoid the error \u0026ldquo;/proc/sys/net/bridge/bridge-nf-call-iptables does not exist\u0026rdquo; on kubeinit (reference https://github.com/kubernetes/kubeadm/issues/1062).\nsudo modprobe br_netfilter sudo echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward Start the cluster Initialize the Kubernetes cluster for use with Flannel\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Copy to config as kubadm command says\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Usually you wouldn\u0026rsquo;t run pods on your control-plane node. However, since we are running a lab environment on a single VM, it\u0026rsquo;s ok. To be able to schedule pods on the control-plane node, we need to remove the NoSchedule taint:\nkubectl taint node instance-20230205-0909 node-role.kubernetes.io/control-plane:NoSchedule- Add a Container Networking Interface Install Flannel to the cluster (reference https://github.com/flannel-io/flannel)\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Configure the server firewall We use Uncomplicated Firewall. Run these commands:\nsudo ufw allow 22 sudo ufw allow 6443/tcp sudo ufw allow 2379:2380/tcp sudo ufw allow 10250/tcp sudo ufw allow 10259/tcp sudo ufw allow 10257/tcp sudo ufw enable sudo ufw status Set up bashrc Next, edit your bashrc with vim ~/.bashrc and add these lines:\nsource \u0026lt;(kubectl completion bash) alias k=kubectl complete -o default -F __start_kubectl k Then run source ~/.bashrc\nThis configures autocompletion for kubectl, and sets up \u0026ldquo;k\u0026rdquo; as an alias for kubectl.\nLet\u0026rsquo;s run a pod! To see all pods running on your cluster:\nk get pods -A\nNow let\u0026rsquo;s run a simple nginx pod and expose it:\nk run nginx --image=nginx k expose pod nginx --port=80 --type=NodePort To find out which port it\u0026rsquo;s running on, run k get service. In the PORT(S) column, there will be an nginx service exposing port 80 to a random port on the node in the range of 30000-32767.\nIn my case, it says \u0026ldquo;80:31878/TCP\u0026rdquo;\nTo see if we can reach the container, run:\ncurl localhost:31878\nIf everything went well, you will get back the HTML of the default index page served by NGINX:\nubuntu@instance-20230205-0909:~$ curl localhost:31878 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; To reach the pod from the browser, open your port in the security group configured for the subnet of your VM.\nGood luck with your new lab environment!\nLinks https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\nhttps://kubernetes.io/docs/concepts/services-networking/service/\nhttps://github.com/flannel-io/flannel\n","permalink":"https://mischavandenburg.com/zet/articles/simple-cluster-on-ubuntu-vm/","summary":"You can get a free 24GB ram VM from Oracle. What better place for your own Kubernetes lab that is always available? See this article to create your VM.\nHere are the steps I took to install a single node kubernetes cluster on the Ubuntu VM.\nInstallation sudo apt-get update sudo apt install apt-transport-https curl Install containerd\nsudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.","title":"Setting up a Kubernetes cluster on an Ubuntu 20.04 VM with containerd and flannel"},{"content":"A few weeks ago someone gave me a tip. Oracle actually has a really good free tier offering.\nYou can host a 4CPU 24GB VM for free!\nThis is perfect for a lab environment.\nI spent my evening creating the VM and setting up a kubernetes cluster from scratch.\nUse this video to claim your free vm:\nhttps://www.youtube.com/watch?v=NKc3k7xceT8\n","permalink":"https://mischavandenburg.com/zet/free-oracle-vm/","summary":"A few weeks ago someone gave me a tip. Oracle actually has a really good free tier offering.\nYou can host a 4CPU 24GB VM for free!\nThis is perfect for a lab environment.\nI spent my evening creating the VM and setting up a kubernetes cluster from scratch.\nUse this video to claim your free vm:\nhttps://www.youtube.com/watch?v=NKc3k7xceT8","title":"Get a free 4 CPU 24GB Ram VM on from Oracle"},{"content":"Today I added a harddisk I had lying around because I needed some more space. On my Arch Linux system I have all my drives encrypted like a good boy. It can be a bit tricky when you are adding them because you need to configure a few different files and add different UUID\u0026rsquo;s in each of them.\nHere are the steps I follow to add a new disk. Note that this how to assumes that you already have set up your system with dm-crypt.\nList out the disks with lsblk:\n(ins)[mischa@arch-beast ~]$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 223.6G 0 disk └─sda1 8:1 0 223.6G 0 part └─games 254:0 0 223.6G 0 crypt /games sdb 8:16 0 931.5G 0 disk └─sdb1 8:17 0 931.5G 0 part └─data-hdd 254:2 0 931.5G 0 crypt /data-hdd sdc 8:32 0 931.5G 0 disk └─sdc1 8:33 0 931.5G 0 part └─data-hdd2 254:3 0 931.5G 0 crypt /data-hdd2 sdd 8:48 0 465.8G 0 disk ├─sdd1 8:49 0 300M 0 part /boot └─sdd2 8:50 0 465.5G 0 part └─root 254:1 0 465.5G 0 crypt / sde 8:64 0 931.5G 0 disk └─sde1 8:65 0 931.5G 0 part I will be adding /dev/sde to my system. As you see, I already created a partition on it, named sde1. The mountpoint for the disk will be /data-hdd3.\nIf you still need to add your partition, use sudo gdisk /dev/sde to write a new table and partition.\nencryption First I create the mount point I\u0026rsquo;ll use and set the appropriate permisssions:\nsudo mkdir /data-hdd3 sudo chown mischa:mischa /data-hdd3 Now we create a LUKS header and an encrypted filesystem on the disk. Note that I\u0026rsquo;m using the notation convention from the Arch Wiki where the \u0026ldquo;#\u0026rdquo; indicates that the command should be run as root.\n# cryptsetup -y -v luksFormat /dev/sde1 # cryptsetup open /dev/sde1 data-hdd3 # mkfs.ext4 /dev/mapper/data-hdd3 # mount /dev/mapper/data-hdd3 /data-hdd3 Verify that it worked and the new encrypted partition is mounted:\narch-beast# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 223.6G 0 disk └─sda1 8:1 0 223.6G 0 part └─games 254:0 0 223.6G 0 crypt /games sdb 8:16 0 931.5G 0 disk └─sdb1 8:17 0 931.5G 0 part └─data-hdd 254:2 0 931.5G 0 crypt /data-hdd sdc 8:32 0 931.5G 0 disk └─sdc1 8:33 0 931.5G 0 part └─data-hdd2 254:3 0 931.5G 0 crypt /data-hdd2 sdd 8:48 0 465.8G 0 disk ├─sdd1 8:49 0 300M 0 part /boot └─sdd2 8:50 0 465.5G 0 part └─root 254:1 0 465.5G 0 crypt / sde 8:64 0 931.5G 0 disk └─sde1 8:65 0 931.5G 0 part └─data-hdd3 254:4 0 931.5G 0 crypt /data-hdd3 Auto mounting at boot We\u0026rsquo;ll need to add this disk to the kerenel parameters, /etc/crypttab and /etc/fstab. I haven\u0026rsquo;t gotten round to switching to systemd boot yet, but I will do so very soon.\nOpen tmux and split the pane. In the bottom pane, run lsblk -f to have all the UUIDs listed. Then open the grub configuration file with sudoedit /etc/default/grub\nYou can discern which uuid to add from the listed examples. For my new disk, I needed to add the following:\nrd.luks.name=3169af6c-a129-448e-b451-d7767866f607 data-hdd3=/dev/mapper/data-hdd3\nThen run sudo grub-mkconfig -o /boot/grub/grub.cfg to update grub with the new settings. Adjust the path if you use a different path for your boot partition!\nNext, we add it to /etc/crypttab\nTo mount the new encrypted partition at boot, we add it to /etc/fstab.\nNote that this time we need to use the UUID of the partition located at /dev/mapper/data-hdd3\nUse sudo findmnt --verify to check if there is antyhing wrong with the file.\nNow you should be able to reboot and your new encrypted disk should be mounted automatically.\n(ins)[mischa@arch-beast ~]$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 223.6G 0 disk └─sda1 8:1 0 223.6G 0 part └─games 254:1 0 223.6G 0 crypt /games sdb 8:16 0 931.5G 0 disk └─sdb1 8:17 0 931.5G 0 part └─data-hdd 254:0 0 931.5G 0 crypt /data-hdd sdc 8:32 0 931.5G 0 disk └─sdc1 8:33 0 931.5G 0 part └─data-hdd2 254:4 0 931.5G 0 crypt /data-hdd2 sdd 8:48 0 465.8G 0 disk ├─sdd1 8:49 0 300M 0 part /boot └─sdd2 8:50 0 465.5G 0 part └─root 254:2 0 465.5G 0 crypt / sde 8:64 0 931.5G 0 disk └─sde1 8:65 0 931.5G 0 part └─data-hdd3 254:3 0 931.5G 0 crypt /data-hdd3 links https://wiki.archlinux.org/title/Dm-crypt/Encrypting_an_entire_system#LUKS_on_a_partition\nhttps://wiki.archlinux.org/title/GRUB\n","permalink":"https://mischavandenburg.com/zet/articles/new-luks-encrypted-disk/","summary":"Today I added a harddisk I had lying around because I needed some more space. On my Arch Linux system I have all my drives encrypted like a good boy. It can be a bit tricky when you are adding them because you need to configure a few different files and add different UUID\u0026rsquo;s in each of them.\nHere are the steps I follow to add a new disk. Note that this how to assumes that you already have set up your system with dm-crypt.","title":"Setting up a new LUKS encrypted disk with dm-crypt in Arch Linux"},{"content":"For the past few months I\u0026rsquo;ve been stuyding every hour of free time that I had. Now that I reached my certification goals for now, I finally had some time to do a chore I had been meaning to do for a long time.\nMy Arch Linux system is fully encrypted, and I make backups. But I was still doing it a bit haphazardly, usually every Friday.\nI wanted to automate this for a long time now, but I never got round to it. Today I made the first steps, but it is still in progress.\nNaturally, I could use a tool like Timeshift or something similar to schedule my backups. However, I want to do it myself using rsync because I want to fully understand what I am backing up, when, and where. Rsync is also used in our environment at work, so I assume it is more common in enterprise and production environments.\nfull system backup Before I was making a full system backup every Friday using this command:\nsudo rsync -aAXH --info=stats1,progress2 --exclude={\u0026#34;/dev/*\u0026#34;,\u0026#34;/proc/*\u0026#34;,\u0026#34;/sys/*\u0026#34;,\u0026#34;/tmp/*\u0026#34;,\u0026#34;/run/*\u0026#34;,\u0026#34;/mnt/*\u0026#34;,\u0026#34;/media/*\u0026#34;,\u0026#34;/lost+found\u0026#34;,\u0026#34;/home/*/.cache/*\u0026#34;,\u0026#34;/data-hdd/\u0026#34;,\u0026#34;/games/\u0026#34;,\u0026#34;/var/lib/docker/*\u0026#34;,\u0026#34;/home/mischa/music/*\u0026#34;,\u0026#34;/swapfile\u0026#34;, \u0026#34;/data-hdd2/\u0026#34;, \u0026#34;/data-hdd3/\u0026#34;} / /data-hdd/backups/arch-beast/01-01-23 This command creates a full backup of my entire root filesystem, and it should be possible to restore my entire system by just reversing the target and destination in the end.\nHowever, as I was coming up with my new strategy, I thought this was overkill.\nslimming down All I really need to back up is my home directory and it would be nice to have my /etc directory backed up as well.\nSo I wrote a simple shell script to do this:\n#!/bin/bash BACKUPS_DESTINATION=\u0026#34;/data-hdd/backups/arch-beast\u0026#34; # format: # rsync -a --delete --quiet /path/to/backup /location/of/backup # stop the script if an error occurs set -e rsync -a --delete --quiet --exclude=\u0026#34;{\u0026#34;/home/*/.cache/*\u0026#34;}\u0026#34; /home/mischa $BACKUPS_DESTINATION/home rsync -a --delete --quiet /etc $BACKUPS_DESTINATION echo \u0026#34;Made backups on: $(date)\u0026#34; \u0026gt;\u0026gt; /var/log/backup.log -a flag from man page:\n\u0026ldquo;This is equivalent to -rlptgoD. It is a quick way of saying you want recursion and want to preserve almost everything.\u0026rdquo;\n\u0026ndash;delete: means files deleted on the source are to be deleted on the backup as well\nautomation I have a few scripts running in cronjobs on my system. I have a goal of putting them all in systemd timers, but I haven\u0026rsquo;t gotten round to it yet. For now, I will just add my backup scripts to my existing cronjobs setup.\nTo make my backups every day, I added this to my crontab:\n0 12 * * * /bin/bash /home/mischa/git/lab/bash/backup\nEvery day it will make a backup to the same directory and update the changed files, or delete the files I deleted from my system.\nI also wanted to have a weekly backup happening on Monday.\nI will make a more elaborate script to make a weekly directory, and rotate it with a new directory every week. But for now, I just chose a quick solution by creating a weekly version of my script and running it every Monday.\nThe only difference is the path:\nBACKUPS_DESTINATION=\u0026quot;/data-hdd/backups/arch-beast/weekly\u0026quot;\nIn the crontab:\n0 10 * * 1 /bin/bash /home/mischa/git/lab/bash/backup-weekly\nto do set up weekly backup in the same script create error handling and improve logging set up in systemd timers instead of crontab ","permalink":"https://mischavandenburg.com/zet/arch-backup-setup-1/","summary":"For the past few months I\u0026rsquo;ve been stuyding every hour of free time that I had. Now that I reached my certification goals for now, I finally had some time to do a chore I had been meaning to do for a long time.\nMy Arch Linux system is fully encrypted, and I make backups. But I was still doing it a bit haphazardly, usually every Friday.\nI wanted to automate this for a long time now, but I never got round to it.","title":"Setting up automated backups on my Arch Linux system with rsync and bash"},{"content":"I\u0026rsquo;m typing this 30 minutes after I passed my AZ-400 exam. I\u0026rsquo;m sitting in a lovely cafe on Leidseplein in Amsterdam and feel relieved. Another significant certification bites the dust. This one took about 70 hours of study.\nI started preparing immediately after passing my AZ-104 exam, which was a good move. The AZ-400 requires you to know many details about Azure services and how to access them. For example, Shared Access Signatures are only used for accessing storage accounts, but they came up quite often as alternative answers to the questions.\nThe exam itself was difficult, but the AZ-104 was harder. The AZ-104 exam was more challenging because the questions were complicated and required you to simultaneously balance many different factors in the mind. The AZ-400 was difficult because the answer alternatives that are provided are incredibly similar to each other, and they make you very insecure about what the right choice might be. As a result, I changed my answers many times.\nI will do another study guide for this certification soon and publish my notes and Anki deck too. Now it\u0026rsquo;s time to celebrate and relax a little.\n","permalink":"https://mischavandenburg.com/zet/passed-az-400/","summary":"I\u0026rsquo;m typing this 30 minutes after I passed my AZ-400 exam. I\u0026rsquo;m sitting in a lovely cafe on Leidseplein in Amsterdam and feel relieved. Another significant certification bites the dust. This one took about 70 hours of study.\nI started preparing immediately after passing my AZ-104 exam, which was a good move. The AZ-400 requires you to know many details about Azure services and how to access them. For example, Shared Access Signatures are only used for accessing storage accounts, but they came up quite often as alternative answers to the questions.","title":"I passed the AZ-400 DevOps Expert today"},{"content":"The PAT (Personal Access Token) often comes up during practice tests for the AZ-400.\nOne way to remember when to use a PAT is that these are only for authenticating into Azure DevOps, never to external services.\nFor example, you might get a question on connecting your Azure DevOps project with a GitHub account from Azure DevOps, and PAT will show up as one of the alternative answers. By remembering that PATs are only for authenticating into ADO, you can elminate this alternative, and make your choice easier.\nPersonal Access Tokens are an alternative to passwords but should be treated in exactly the same way.\nhttps://learn.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops\u0026amp;tabs=Windows\n","permalink":"https://mischavandenburg.com/zet/azure-personal-access-tokens/","summary":"The PAT (Personal Access Token) often comes up during practice tests for the AZ-400.\nOne way to remember when to use a PAT is that these are only for authenticating into Azure DevOps, never to external services.\nFor example, you might get a question on connecting your Azure DevOps project with a GitHub account from Azure DevOps, and PAT will show up as one of the alternative answers. By remembering that PATs are only for authenticating into ADO, you can elminate this alternative, and make your choice easier.","title":"Azure DevOps Personal Access Tokens are always for authenticating into ADO"},{"content":"I did a lot of studying last year, and I achieved a few tough certifications. I\u0026rsquo;ve always been good at studying and never struggled with getting decent grades in university. As a result, I never felt the need to use particular techniques to pass my tests. However, now that I need to do my studies combined with a full-time job, I did some optimization and looked into study techniques.\nOne technique I\u0026rsquo;ve become very fond of is the Pomodoro Technique. I don\u0026rsquo;t have any problems focusing for long periods, but I still decided to try it. I use the standard 25-minute study with a 5-minute break routine, and after four cycles, I take a 30-minute break.\nThe Pomodoro technique has been a way to force myself to take breaks, which I wasn\u0026rsquo;t used to. I used to chip away at a specific task for hours. However, I discovered that when I take a break, walk around for five minutes, and apply myself to the task again, my mind is in a fresh state and much more receptive to the information. Perhaps the time I spend studying after a break is actually more productive because the mind had a little rest.\nThe technique also pushed my limits a bit more. I study more hours a day, considering that I also work full time. There is this moment where I want to quit studying, but I ask myself, \u0026ldquo;do I have another Pomodoro in me?\u0026rdquo;\nNow that I\u0026rsquo;ve gotten used to breaking things up into 25-minute chunks of time, I started using the Pomodoro technique for other areas in life as well, such as blog writing or coding projects.\nYou can use any tool you like to start using the Pomodoro technique and pick any break schedule that suits you. I\u0026rsquo;ll link some resources below. All you need is some sort of timer. You can use a timer on your computer or a physical timer. I use the Forest app on my iPhone because it integrates with the iOs \u0026ldquo;do not disturb\u0026rdquo; and \u0026ldquo;focus\u0026rdquo; modes, so I don\u0026rsquo;t get any distracting notifications when I\u0026rsquo;m on a Pomodoro.\nhttps://science.nichd.nih.gov/confluence/display/newsletter/2020/05/07/The+Pomodoro+Technique%3A+An+Effective+Time+Management+Tool\nhttps://www.youtube.com/watch?v=5WRO79zuJ4U\n","permalink":"https://mischavandenburg.com/zet/pomodoro/","summary":"I did a lot of studying last year, and I achieved a few tough certifications. I\u0026rsquo;ve always been good at studying and never struggled with getting decent grades in university. As a result, I never felt the need to use particular techniques to pass my tests. However, now that I need to do my studies combined with a full-time job, I did some optimization and looked into study techniques.\nOne technique I\u0026rsquo;ve become very fond of is the Pomodoro Technique.","title":"The Pomodoro technique has won me over"},{"content":"Last modified: 2023-01-10\nIn this evening\u0026rsquo;s studies I came across this bash script in a tutorial by Rob Muhlenstein:\n!#/bin/bash echo -e ${PATH//:/\\\\n} I could not make heads or tails of all these slashes and curly braces, since the output clearly indicated that search and replacement was being performed. I\u0026rsquo;m used to the sed / vim syntax: s/foo/bar\nAfter some research I learned that \u0026lsquo;//\u0026rsquo; is a global search and replace syntax of several text processing programs. It is known as parameter expansion in bash.\nExample:\nfoo=\u0026#34;1234567890\u0026#34; echo \u0026#34;${foo//[0-9]/x}\u0026#34; This replaces all the digits in the $foo variable with \u0026lsquo;x\u0026rsquo;, so the output would be xxxxxxxxxx\nTo do this with sed, you would do:\necho \u0026#34;$foo\u0026#34; | sed \u0026#39;s/[0-9]/x/g\u0026#39; For more info:\nman bash\n/parameter expansion\n","permalink":"https://mischavandenburg.com/zet/slash-syntax-replace/","summary":"Last modified: 2023-01-10\nIn this evening\u0026rsquo;s studies I came across this bash script in a tutorial by Rob Muhlenstein:\n!#/bin/bash echo -e ${PATH//:/\\\\n} I could not make heads or tails of all these slashes and curly braces, since the output clearly indicated that search and replacement was being performed. I\u0026rsquo;m used to the sed / vim syntax: s/foo/bar\nAfter some research I learned that \u0026lsquo;//\u0026rsquo; is a global search and replace syntax of several text processing programs.","title":"Using parameter expansion as search and replace"},{"content":"My friend gave me a nice tip for customizing the readme on my personal GitHub page. I discovered there is a whole world of plugins and customizations out there.\nI set up this one for my GitHub homepage. It uses a workflow to update the readme in my personal GitHub repo with the most recent posts from this blog, based on the RSS feed. Neat!\nIt was very easy to set up. If you don\u0026rsquo;t have your own blog, you could configure it with a different RSS feed. Hacker News for example.\nhttps://github.com/gautamkrishnar/blog-post-workflow\nhttps://github.com/abhisheknaiidu/awesome-github-profile-readme\n","permalink":"https://mischavandenburg.com/zet/adding-posts-github-readme/","summary":"My friend gave me a nice tip for customizing the readme on my personal GitHub page. I discovered there is a whole world of plugins and customizations out there.\nI set up this one for my GitHub homepage. It uses a workflow to update the readme in my personal GitHub repo with the most recent posts from this blog, based on the RSS feed. Neat!\nIt was very easy to set up.","title":"Automatically adding my recent blog posts to my GitHub Readme"},{"content":"I\u0026rsquo;ve used zsh for nearly two years now. I have a custom setup with autocompletion and a good looking prompt.\nRecently I\u0026rsquo;ve been diving deeper into bash scripting, following tutorials by rwxrob. He emphasizes all the time that it is much better to stick to bash instead of zsh.\nAdvantages of using bash:\nthe default Linux shell available on any Linux system full documentation available anywhere at all times with man bash free software less dependent on external plugins and configurations more portable practice by working on the command line The fact that working on the commandline is already coding convinced me to leave my beloved customized prompt behind (for now) and go back to the basics.\nI want to improve my bash scripting, and working in the bash shell will improve that just by virtue of doing my daily tasks on the command line.\nAlso I noticed I\u0026rsquo;ve gotten used to zsh\u0026rsquo;s excellent autocompletion and menu navigation. When I log in to servers at work, there is always this little moment of \u0026ldquo;oh, I don\u0026rsquo;t have that here\u0026rdquo;. I want to get better at bash so I\u0026rsquo;m not dependent on these external crutches anymore.\nAlso, I\u0026rsquo;m going to port my zsh configuration to bash. My current zsh configuration loads a bunch of plugins, and it is more of a hassle to get set up on a new system.\nI want to be able to pull my dotfiles repo and do very few steps to configure my environment.\nBut I\u0026rsquo;m going to miss that good-looking prompt with all the lovely icons!\n","permalink":"https://mischavandenburg.com/zet/back-to-bashics/","summary":"I\u0026rsquo;ve used zsh for nearly two years now. I have a custom setup with autocompletion and a good looking prompt.\nRecently I\u0026rsquo;ve been diving deeper into bash scripting, following tutorials by rwxrob. He emphasizes all the time that it is much better to stick to bash instead of zsh.\nAdvantages of using bash:\nthe default Linux shell available on any Linux system full documentation available anywhere at all times with man bash free software less dependent on external plugins and configurations more portable practice by working on the command line The fact that working on the commandline is already coding convinced me to leave my beloved customized prompt behind (for now) and go back to the basics.","title":"Back to Bas(h)ics: leaving zsh for now"},{"content":"I wanted to build an application from a Dockerfile and deploy it to a VM. I used a default Svelte setup as an example app.\nNaturally, Azure prefers that you deploy containers to services such as Azure Container Instances or App Services, so they don\u0026rsquo;t provide modules for the pipelines to deploy to docker servers as far as I could tell.\nI searched for a long time but I could not find a solution. In the end I just ran shell commands from the pipeline to run the container on on the server.\nsteps: - script: | sudo docker stop svelte-test sudo docker rm svelte-test sudo docker run --name svelte-test -p 8080:80 -d mischavandenburg/svelte-test:$(Build.BuildId) You can find the full pipeline code, the app and Dockerfile in my lab repo:\nhttps://github.com/mischavandenburg/lab/tree/main/azure-pipelines/docker-to-azure-vm\n","permalink":"https://mischavandenburg.com/zet/docker-to-azure-vm/","summary":"I wanted to build an application from a Dockerfile and deploy it to a VM. I used a default Svelte setup as an example app.\nNaturally, Azure prefers that you deploy containers to services such as Azure Container Instances or App Services, so they don\u0026rsquo;t provide modules for the pipelines to deploy to docker servers as far as I could tell.\nI searched for a long time but I could not find a solution.","title":"How to build and deploy a Docker container to an Azure VM using Azure Pipelines"},{"content":"To reach a VM from Azure Pipelines, you need to set up an environment.\nCreate your Linux VM in Azure.\nIn Azure DevOps, click envirnoments, new, and select the Virtual Machine option.\nA command is generated for you. SSH into your VM and run the command.\nNow the VM should show up under environments in Azure DevOps.\nSet up a repo with an azure-pipelines.yml with these contents to test. under environment, set the same name as you did in Azure DevOps for your environment.\ntrigger: - main pool: vmImage: ubuntu-latest jobs: - deployment: VMDeploy displayName: Deploy to VM environment: name: dev resourceType: VirtualMachine strategy: runOnce: deploy: steps: - script: echo \u0026#34;Hello world\u0026#34; You can see it when the deploy runs on the VM:\n","permalink":"https://mischavandenburg.com/zet/azure-pipelines-deploy-vm/","summary":"To reach a VM from Azure Pipelines, you need to set up an environment.\nCreate your Linux VM in Azure.\nIn Azure DevOps, click envirnoments, new, and select the Virtual Machine option.\nA command is generated for you. SSH into your VM and run the command.\nNow the VM should show up under environments in Azure DevOps.\nSet up a repo with an azure-pipelines.yml with these contents to test. under environment, set the same name as you did in Azure DevOps for your environment.","title":"How to deploy to a Linux VM in Azure with Azure Pipelines"},{"content":"For a project I\u0026rsquo;m setting up my environment with Terraform.\nI used this tutorial, but modified the code to make it simpler and easier to understand for beginners. The original uses a random module to generate random names, and generates a new SSH key. Also, this tutorial uses expensive VM tiers and Premium storage, which are not necessary when you are learning.\nI also thought the SSH configuration was overcomplicated. My version just takes an SSH keypair stored at ~/.ssh/id_rsa.pub\nTo run:\nterraform init terraform plan terraform apply The scripts prints the public IP of the newly created VM. You should be able to SSH to it:\nssh azureuser@the_printed_ip_address\nYou can find the code in my \u0026ldquo;lab\u0026rdquo; repo on GitHub.\nhttps://github.com/mischavandenburg/lab/tree/main/terraform/azure-simple-linux-vm\nhttps://learn.microsoft.com/en-us/azure/virtual-machines/linux/quick-create-terraform\nhttps://learn.microsoft.com/en-us/azure/developer/terraform/authenticate-to-azure?source=recommendations\u0026amp;tabs=bash#authenticate-to-azure-via-a-microsoft-account\n","permalink":"https://mischavandenburg.com/zet/terraform-linux-vm/","summary":"For a project I\u0026rsquo;m setting up my environment with Terraform.\nI used this tutorial, but modified the code to make it simpler and easier to understand for beginners. The original uses a random module to generate random names, and generates a new SSH key. Also, this tutorial uses expensive VM tiers and Premium storage, which are not necessary when you are learning.\nI also thought the SSH configuration was overcomplicated. My version just takes an SSH keypair stored at ~/.","title":"Deploying a Linux VM to Azure with Terraform"},{"content":"I use the Obsidian app, but I mostly write and search my notes with neovim. I added my zet directory from this blog repo into the Obsidian vault as a symbolic link, but I soon discovered that these files were not being searched.\nTelescope.nvim uses ripgrep (rg) to do the live grepping in its search, and ripgrep does not follow symbolic links by default. You need to pass the -L flag to it.\nTo pass the -L flag, and some other flags, I added the following to my telescope config file:\n-- Custom ripgrep configuration: local telescope = require(\u0026#34;telescope\u0026#34;) local telescopeConfig = require(\u0026#34;telescope.config\u0026#34;) -- Clone the default Telescope configuration local vimgrep_arguments = { unpack(telescopeConfig.values.vimgrep_arguments) } -- I want to search in hidden/dot files. table.insert(vimgrep_arguments, \u0026#34;--hidden\u0026#34;) -- I don\u0026#39;t want to search in the `.git` directory. table.insert(vimgrep_arguments, \u0026#34;--glob\u0026#34;) table.insert(vimgrep_arguments, \u0026#34;!**/.git/*\u0026#34;) -- I want to follow symbolic links table.insert(vimgrep_arguments, \u0026#34;-L\u0026#34;) telescope.setup({ defaults = { -- `hidden = true` is not supported in text grep commands. vimgrep_arguments = vimgrep_arguments, }, pickers = { find_files = { -- `hidden = true` will still show the inside of `.git/` as it\u0026#39;s not `.gitignore`d. find_command = { \u0026#34;rg\u0026#34;, \u0026#34;--files\u0026#34;, \u0026#34;--hidden\u0026#34;, \u0026#34;--glob\u0026#34;, \u0026#34;!**/.git/*\u0026#34;, \u0026#34;-L\u0026#34; }, }, }, }) Based on the configuration examples found on the project\u0026rsquo;s GitHub page.\nhttps://github.com/nvim-telescope/telescope.nvim\n","permalink":"https://mischavandenburg.com/zet/neovim-telescope-follow-symlinks/","summary":"I use the Obsidian app, but I mostly write and search my notes with neovim. I added my zet directory from this blog repo into the Obsidian vault as a symbolic link, but I soon discovered that these files were not being searched.\nTelescope.nvim uses ripgrep (rg) to do the live grepping in its search, and ripgrep does not follow symbolic links by default. You need to pass the -L flag to it.","title":"How to follow symbolic links while searching with Telescope in neovim"},{"content":"When you have an Ansible language server installed, you might find that your yaml LSP will attach to your current buffer, but the ansible language server won\u0026rsquo;t attach.\nYou can fix this by setting the correct file type for the current buffer:\n:set ft=yaml.ansible\nYou could also adjust the Ansible LSP so it attaches to all yaml files. However, this does not work out for me, because I edit different yaml files for different purposes every day. Not all yaml files are to be used with Ansible.\nThere is logic for the Ansible language server to figure out if you are working on Ansible yaml files based on the directory structure you\u0026rsquo;re working in.\nSo setting the filetype when I needed works well for me.\nhttps://www.reddit.com/r/neovim/comments/tbd7g0/lsp_ansiblels_wont_attach_anymore/\n","permalink":"https://mischavandenburg.com/zet/ansible-lsp-fix/","summary":"When you have an Ansible language server installed, you might find that your yaml LSP will attach to your current buffer, but the ansible language server won\u0026rsquo;t attach.\nYou can fix this by setting the correct file type for the current buffer:\n:set ft=yaml.ansible\nYou could also adjust the Ansible LSP so it attaches to all yaml files. However, this does not work out for me, because I edit different yaml files for different purposes every day.","title":"Attaching the Ansible Language Server to yaml files in neovim (LSP)"},{"content":"Make sure to have pip installed.\nRun pip install python-openstackclient\nPip will install a binary called \u0026ldquo;openstack\u0026rdquo; in ~/.local/bin\nIf the openstack command is not available in your session, you might need to add it to your PATH:\nexport PATH=\u0026quot;$HOME/.local/bin:$PATH\u0026quot;\nAdd this to your ~/.zshrc or ~/.bashrc to make sure this happens for each shell session.\nDon\u0026rsquo;t forget to source your updated ~/.zshrc if you chose to add it:\nsource ~/.zshrc\nhttps://docs.openstack.org/newton/user-guide/common/cli-install-openstack-command-line-clients.html\n","permalink":"https://mischavandenburg.com/zet/install-openstack-cli/","summary":"Make sure to have pip installed.\nRun pip install python-openstackclient\nPip will install a binary called \u0026ldquo;openstack\u0026rdquo; in ~/.local/bin\nIf the openstack command is not available in your session, you might need to add it to your PATH:\nexport PATH=\u0026quot;$HOME/.local/bin:$PATH\u0026quot;\nAdd this to your ~/.zshrc or ~/.bashrc to make sure this happens for each shell session.\nDon\u0026rsquo;t forget to source your updated ~/.zshrc if you chose to add it:\nsource ~/.","title":"How to install the Openstack CLI on Linux"},{"content":" Download the Openstack RC file from the Openstack portal. Click your username in the top right corner to find it. Source the RC file to make the environment variables avaialable to your current session: source ~/my_openstack.sh Find the instance ID of your VM from the portal. Run openstack server set --root-password be3xxxx5-8348-418b-xxxb-c4xxxx575cd You will be prompted for the new password which will be set on the virtual machine. ","permalink":"https://mischavandenburg.com/zet/openstack-root-password/","summary":" Download the Openstack RC file from the Openstack portal. Click your username in the top right corner to find it. Source the RC file to make the environment variables avaialable to your current session: source ~/my_openstack.sh Find the instance ID of your VM from the portal. Run openstack server set --root-password be3xxxx5-8348-418b-xxxb-c4xxxx575cd You will be prompted for the new password which will be set on the virtual machine. ","title":"How to Reset a VM Root Password using the Openstack CLI"},{"content":"When you install a pip package which is meant to be run from the command line as a command, you might find that it is not available to you after installation.\nIf this happens, it might be that the path is missing from your PATH variable. Therefore, the shell does not source these binaries when initiated, and does not know that these executables exist.\nYou can find the location of your binaries by running pip show package_name\nUsually the binaries will be located in ~/.local/bin on a UNIX based system.\nTo add this to your path, run:\nexport PATH=\u0026quot;$HOME/.local/bin:$PATH\u0026quot;\nAdd this to your ~/.zshrc or ~/.bashrc to make sure this happens for each shell session.\nDon\u0026rsquo;t forget to source your updated ~/.zshrc if you chose to add it:\nsource ~/.zshrc\nhttps://stackoverflow.com/questions/29980798/where-does-pip-install-its-packages\n","permalink":"https://mischavandenburg.com/zet/run-installed-pip-packages/","summary":"When you install a pip package which is meant to be run from the command line as a command, you might find that it is not available to you after installation.\nIf this happens, it might be that the path is missing from your PATH variable. Therefore, the shell does not source these binaries when initiated, and does not know that these executables exist.\nYou can find the location of your binaries by running pip show package_name","title":"How to run installed pip packages as binaries"},{"content":"Rob Muhlenstein makes an interesting point that using bash on the command line is already coding. When you are running commands in the terminal, you are coding one line at a time.\nWhen you put these commands in a file you have a bash script. Therefore, he argues that bash should be your first language.\nI think this is such an interesting point. I\u0026rsquo;ve been using Linux and working on the command line for years but it never dawned on me that I, in fact, was coding while working on the command line. However, when I was writing bash scripts, I did consider myself to be coding. There is literally no difference. A bash script is just a string of commands that you would enter manually anyway.\nhttps://rwx.gg/\n","permalink":"https://mischavandenburg.com/zet/bash-cmdline-is-coding/","summary":"Rob Muhlenstein makes an interesting point that using bash on the command line is already coding. When you are running commands in the terminal, you are coding one line at a time.\nWhen you put these commands in a file you have a bash script. Therefore, he argues that bash should be your first language.\nI think this is such an interesting point. I\u0026rsquo;ve been using Linux and working on the command line for years but it never dawned on me that I, in fact, was coding while working on the command line.","title":"Working on the command line is already coding"},{"content":"Sed, it\u0026rsquo;s so powerful. I remember I struggled with finding practical uses for it when I did my LPIC-1 certification. But now I find myself using it several times a week. It is so powerful to edit multiple files at a time. I use it for work, but also for making changes to my entire second brain in Obsidian with one command.\nToday I needed to update my /articles/ links to /zet/articles/ links because I\u0026rsquo;m restructuring my website. Here is the sed expression that is executed for every markdown file that is found by fd:\nsed -i \u0026#39;s/\\/articles\\//\\/zet\\/articles\\//g\u0026#39; $(fd .md) The result:\ndiff --git a/content/zet/move-to-zet.md b/content/zet/move-to-zet.md index 1e37283..3b817e3 100644 --- a/content/zet/move-to-zet.md +++ b/content/zet/move-to-zet.md @@ -6,7 +6,7 @@ tags: --- -I\u0026#39;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my [Obsidian](/articles/obsidian-introduction/) vault. +I\u0026#39;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my [Obsidian](/zet/articles/obsidian-introduction/) vault. These sites are super useful to help you formulate your expressions:\nhttps://sed.js.org/\nhttps://regex101.com/\n","permalink":"https://mischavandenburg.com/zet/fall-in-love-with-sed/","summary":"Sed, it\u0026rsquo;s so powerful. I remember I struggled with finding practical uses for it when I did my LPIC-1 certification. But now I find myself using it several times a week. It is so powerful to edit multiple files at a time. I use it for work, but also for making changes to my entire second brain in Obsidian with one command.\nToday I needed to update my /articles/ links to /zet/articles/ links because I\u0026rsquo;m restructuring my website.","title":"Fall in love with sed."},{"content":"Telemetry is the collection of measurements or other data at remote points, and transmitting that data to a receiver for monitoring.\nSampling is used to reduce telemetry traffic and costs for storage and data in Application Insights.\nFor small and medium sized applications sampling is generally not necessary.\nAdvantages of sampling:\nThrottling data when the application suddenly sends a high volume of telemetry in a short time This saves costs! Keeping a pricing tier quota Reduce network traffic from telemetry collection Three different kinds of sampling:\nadaptive sampling automatically adjusts volume of telemetry from ASP.NET or Azure Functions only for these two fixed-rate sampling rate is set by the administrator use when you have a clear idea of the appropriate sampling percentage reduces volume from ASP.NET or ASP.NET Core server Java server Python applications User browsers ingestion sampling used when monthly quota is often met reduces amount of processed and retained traffic by Application Insights less processing = less cost doesn\u0026rsquo;t reduce telemetry traffic sent from the app happens at Applications Insight service endpoint disabled if SDK samples telemetry can set sampling rate without redeploying the app only applies when no other sampling is in effect supports all Application Insights SDK\u0026rsquo;s ","permalink":"https://mischavandenburg.com/zet/application-insights-sampling/","summary":"Telemetry is the collection of measurements or other data at remote points, and transmitting that data to a receiver for monitoring.\nSampling is used to reduce telemetry traffic and costs for storage and data in Application Insights.\nFor small and medium sized applications sampling is generally not necessary.\nAdvantages of sampling:\nThrottling data when the application suddenly sends a high volume of telemetry in a short time This saves costs! Keeping a pricing tier quota Reduce network traffic from telemetry collection Three different kinds of sampling:","title":"Application Insights: Telemetry Sampling"},{"content":"This term can be confusing. Initially I thought it meant monitoring of the pipelines themselves. However, in the context of Azure Release Pipelines, continuous monitoring refers to something else.\nContinuous monitoring leverages metrics from other services such as Application Insights. You can set up release gates based on these metrics. For example, you can set up a release gate to roll back the deployment if an alert is being fired for high CPU usage in the application.\nYou can set up several of these checks. If all these checks pass, the pipeline can proceed.\n","permalink":"https://mischavandenburg.com/zet/pipelines-continuous-monitoring/","summary":"This term can be confusing. Initially I thought it meant monitoring of the pipelines themselves. However, in the context of Azure Release Pipelines, continuous monitoring refers to something else.\nContinuous monitoring leverages metrics from other services such as Application Insights. You can set up release gates based on these metrics. For example, you can set up a release gate to roll back the deployment if an alert is being fired for high CPU usage in the application.","title":"Pipelines: Continuous Monitoring"},{"content":"Debugging is done using call stacks in monolithic applications. Nowadays it is more common to deploy an application using a microservices architecture. Microservices make it easier to update certain parts of the application, and allow for more frequent deployments.\nUsing microservices does have a disadvantage: you cannot use the local call stack for debugging, because calls are sent to different microservices.\nDistributed tracing is an implementation of the call stack in the cloud. It is usually implemented by adding an agent, SDK, or library to the service. In Azure you can enable distributed tracing via Application Insights through auto-instrumentation or SDKs.\nUnified cross-component transaction diagnostics\n","permalink":"https://mischavandenburg.com/zet/distributed-tracing/","summary":"Debugging is done using call stacks in monolithic applications. Nowadays it is more common to deploy an application using a microservices architecture. Microservices make it easier to update certain parts of the application, and allow for more frequent deployments.\nUsing microservices does have a disadvantage: you cannot use the local call stack for debugging, because calls are sent to different microservices.\nDistributed tracing is an implementation of the call stack in the cloud.","title":"Distributed Tracing"},{"content":"A software development kit (SDK) is a set of tools provided by the manufacturer of (usually) a hardware platform, operating system (OS), or programming language.\nSDKs contain all the tools you need to get started. They typically contain a compiler, a debugger and an API. But they can also contain documentation and testing tools.\n","permalink":"https://mischavandenburg.com/zet/sdk/","summary":"A software development kit (SDK) is a set of tools provided by the manufacturer of (usually) a hardware platform, operating system (OS), or programming language.\nSDKs contain all the tools you need to get started. They typically contain a compiler, a debugger and an API. But they can also contain documentation and testing tools.","title":"What is a SDK?"},{"content":"All of the content on this blog is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0).\nYou are free to: Share — copy and redistribute the material in any medium or format\nUnder the following terms: Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNonCommercial — You may not use the material for commercial purposes.\nNoDerivatives — If you remix, transform, or build upon the material, you may not distribute the modified material.\nhttps://creativecommons.org/licenses/by-nc-nd/4.0/\n","permalink":"https://mischavandenburg.com/zet/articles/copyright-license/","summary":"All of the content on this blog is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0).\nYou are free to: Share — copy and redistribute the material in any medium or format\nUnder the following terms: Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.","title":"Copyright and License"},{"content":" As I alluded to in my article about Obsidian, I am very fond of editing my text in neovim. Naturally, if you want to edit in neovim, you need to have your text as local files. I keep all of my personal notes in markdown.\nPreviously I was using WordPress, but the editing and writing experience became torture which I could not endure any longer. I looked for a different solution that would allow me to edit my files locally instead of in the browser.\nI discovered Hugo and I fell in love with it immediately.\nHugo is a static site generator based on markdown files. My entire blog is written in markdown files which are stored in a GitHub repo.. I write my blog posts in vim and when I\u0026rsquo;m done I use Hugo to generate the updated website.\nThe result is what you see in the \u0026ldquo;public\u0026rdquo; directory in the GitHub repo. This public directory is pushed to a different repo which is hooked up to my hosting provider. My hosting provider uses Plesk, and with Plesk I have the option to connect the GitHub repo to the web server with a webhook. When I push to my hosting repo, the contents are gathered by the webserver and served as public web content.\nMy complete writing and publishing workflow looks like this:\nCreate a new markdown file Write the note or article Save the file and run the \u0026ldquo;hugo\u0026rdquo; command to regenerate the website Run the \u0026ldquo;publish\u0026rdquo; script. This is a custom script I wrote that takes the contents of the \u0026ldquo;public\u0026rdquo; directory to my hosting repo Push the newly generated website to the hosting repo And we\u0026rsquo;re live! 🚀 🎉 It is such a smooth and convenient process. I can literally have a new note published to the interet within a few minutes, and it is all done from the command line using my favorite tools.\nBlog GitHub repo\n","permalink":"https://mischavandenburg.com/zet/articles/how-this-blog-is-created/","summary":"As I alluded to in my article about Obsidian, I am very fond of editing my text in neovim. Naturally, if you want to edit in neovim, you need to have your text as local files. I keep all of my personal notes in markdown.\nPreviously I was using WordPress, but the editing and writing experience became torture which I could not endure any longer. I looked for a different solution that would allow me to edit my files locally instead of in the browser.","title":"How This Blog is Created, Written and Hosted"},{"content":"When you call a function, the system sets aside space in memory for the function to do its work. Those chunks are called \u0026ldquo;stack frames\u0026rdquo; or \u0026ldquo;function frames.\u0026rdquo;\nThese frames are arranged in a stack. The frame for the most recently called function is always at the top of the stack. When a new function is called, it becomes the active frame, and it is on top of the stack.\nThe function that is actually doing something at the moment is on top of the stack and is known as the \u0026ldquo;active frame.\u0026rdquo;\nWhen the function finishes its work, the frame is popped off of the stack. The frame in second place becomes the active frame. It had been paused in the meantime, and now it is active again, because it is on top.\nFunctions that are not on top, are not running.\nThis video explains it well.\n","permalink":"https://mischavandenburg.com/zet/call-stacks/","summary":"When you call a function, the system sets aside space in memory for the function to do its work. Those chunks are called \u0026ldquo;stack frames\u0026rdquo; or \u0026ldquo;function frames.\u0026rdquo;\nThese frames are arranged in a stack. The frame for the most recently called function is always at the top of the stack. When a new function is called, it becomes the active frame, and it is on top of the stack.","title":"Call Stacks"},{"content":"I\u0026rsquo;m starting a project with a friend. Developing an application. We make a good team, he\u0026rsquo;s great at coding and knows the backend too.\nHe\u0026rsquo;ll do the development, I\u0026rsquo;m in charge of hosting. We\u0026rsquo;re setting everything up in Azure DevOps, so it is a great way to practice my Azure skills and apply the things I\u0026rsquo;ve learned in my recently obtained AZ-104 Azure Administrator certification.\nEven though it is a small scale hobby project, I still plan to approach it as if it was an enterprise production application. I\u0026rsquo;ll set up a full CI/CD pipeline with testing in a secure manner. Credentials stored in an Azure key vault and images pushed to a private registry.\nThis is going to be fun!\n","permalink":"https://mischavandenburg.com/zet/starting-a-project/","summary":"I\u0026rsquo;m starting a project with a friend. Developing an application. We make a good team, he\u0026rsquo;s great at coding and knows the backend too.\nHe\u0026rsquo;ll do the development, I\u0026rsquo;m in charge of hosting. We\u0026rsquo;re setting everything up in Azure DevOps, so it is a great way to practice my Azure skills and apply the things I\u0026rsquo;ve learned in my recently obtained AZ-104 Azure Administrator certification.\nEven though it is a small scale hobby project, I still plan to approach it as if it was an enterprise production application.","title":"Starting a Project"},{"content":"I\u0026rsquo;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my Obsidian vault.\nThe concept of \u0026ldquo;atomic notes\u0026rdquo; is also very important in Zettelkasten methods. Notes should be small and concise.\nUp until this point I\u0026rsquo;ve been publishing full articles on my blog. I came across Rob Muhlestein yesterday and I was very inspired by his setup and public zettelkasten. I think I\u0026rsquo;ll move to a similar approach. Still planning to write and publish full articles as well, but also including atomic notes and personal status updates.\n","permalink":"https://mischavandenburg.com/zet/move-to-zet/","summary":"I\u0026rsquo;ve transitioned my note taking system towards a Zettelkasten system. I still use directories for folders and make copious links, but more often than not I put them in the larger generic 00-zettelkasten directory in my Obsidian vault.\nThe concept of \u0026ldquo;atomic notes\u0026rdquo; is also very important in Zettelkasten methods. Notes should be small and concise.\nUp until this point I\u0026rsquo;ve been publishing full articles on my blog. I came across Rob Muhlestein yesterday and I was very inspired by his setup and public zettelkasten.","title":"Going to Publish Smaller, and More Often"},{"content":"As a DevOps or Cloud engineer, you work with many different technologies daily. Therefore, a good engineer needs a solid foundation in Linux, a lot of knowledge about your cloud solution, networking, CI/CD, at least one programming language, and many other topics.\nNot only are there many of these categories, but within these categories, there are several alternatives. For example, in the category of infrastructure management, there is Ansible, Puppet, or Chef, each with its particular approach and configuration methods.\nIt can be challenging to keep everything memorized at all times. However, when I started my journey to become a DevOps engineer, I kept meticulous notes of everything I learned, and this practice has been highly beneficial so far. This blog is a result of the notes I keep every day.\nNote-taking is an essential part of the DevOps engineer\u0026rsquo;s toolkit. It allows you to stay organized, track changes, document processes, and keep track of important information. Using a powerful note-taking app like Obsidian can streamline your note-taking process and work more efficiently.\nObsidian for DevOps engineers Having a reliable and efficient system in place for managing your notes and documentation is crucial. That\u0026rsquo;s where Obsidian comes in. Obsidian is a powerful note-taking app that can help you organize and manage your notes more efficiently.\nOne of the main features of Obsidian is its use of \u0026ldquo;vaults.\u0026rdquo; A vault is a folder containing your notes as markdown text files. Your notes are stored on your machine rather than in the cloud. This gives you complete control over your data. You always have access to your local text files and can interact with them or back them up as you see fit.\nBecause your notes are stored as markdown files, you can use different tools to write or edit your notes. I mostly use neovim for editing, but I use the Obsidian application for making new links and visualization. Moreover, storing your notes as files allows you to run python scripts on your notes and customize your workflow as needed. This can be especially useful for automating tasks, streamlining your work, or making bulk updates.\nLinks and graph view In addition to its local storage capabilities, Obsidian also offers several other valuable features for DevOps engineers. For example, you can use the \u0026ldquo;graph view\u0026rdquo; to visualize your notes and see how they\u0026rsquo;re related to one another. This can be particularly useful for understanding complex systems and tracking changes over time.\nThese relations between notes are created by \u0026ldquo;[[markdown links]]\u0026rdquo;. When a note receives many links, its dot size will increase on the graph view, and in this manner, it is easy to see which notes or topics are significant in your vault and play an important role in your life.\nThis is the local graph view, showing all the linked notes to my Linux note.\nConclusion Many note-taking apps, such as Evernote, Notion, or Roam research, are available. I tried a few of these, but Obsidian was the best solution for me. Mainly because your notes are stored as markdown files on your machine and because they offer a syncing service with end-to-end encryption. Their graph view provides an interesting way to navigate your notes and discover unexpected connections.\nGive it a try. It\u0026rsquo;s free.\nObsidian website\n","permalink":"https://mischavandenburg.com/zet/articles/obsidian-introduction/","summary":"As a DevOps or Cloud engineer, you work with many different technologies daily. Therefore, a good engineer needs a solid foundation in Linux, a lot of knowledge about your cloud solution, networking, CI/CD, at least one programming language, and many other topics.\nNot only are there many of these categories, but within these categories, there are several alternatives. For example, in the category of infrastructure management, there is Ansible, Puppet, or Chef, each with its particular approach and configuration methods.","title":"Obsidian: A Note Taking App For DevOps Engineers"},{"content":"When you learn about DevOps, you will come across the concept of a container early on. This is a \u0026ldquo;Mischa Explains\u0026rdquo; article where I attempt to explain a concept in my own words as simply as possible. I use the Feynman technique and pretend to explain it to a 12-year-old.\nVirtualization To understand containers, we need to understand virtualization. Virtualization is the process of creating \u0026ldquo;fake computers\u0026rdquo; or \u0026ldquo;virtual computers\u0026rdquo; on a physical computer.\nOn your desk, you have a laptop or a desktop PC. This machine has hardware such as a motherboard, a hard disk, and a video card. To run programs on your computer, it needs an Operating System. Usually, Windows, macOS, or Linux are used.\nLet\u0026rsquo;s say you have a computer running Windows, but you want to run a program that can only run on Linux. One solution is to buy another laptop and put it beside your Windows laptop on your desk. So now you have two computers with two different operating systems.\nFortunately, there are other solutions. We can use virtualization to make a Virtual Machine. A virtual machine is created by software to imitate a fully functional running computer inside your current operating system. You can create a virtual machine that runs Linux on your Windows computer. Your Windows computer running the Linux virtual machine is known as the **host.\nNow you don\u0026rsquo;t need to buy another computer to run your Linux program. Instead, you can boot up your Linux virtual machine and run your program when needed. If you have a powerful computer, you could run ten or more virtual machines, each of which has its own operating system and custom environment.\nContainers Every time you create a virtual machine, the virtual machine needs a complete operating system to work. So, first, the software creates a virtual processor, virtual video card, and a virtual network interface. Then, it runs a fully functional operating system on that virtual hardware. This takes up a lot of resources.\nContainers are lightweight packages of software. They are designed to do a very specific task, and therefore they only contain the resources they need to do that task. Nothing more.\nContainers use the operating system of the physical computer to run. They have a very minimal, lightweight operating system inside them, but it only contains the elements they need to do their specific task. Therefore, containers are very easy to distribute, and you can run them very quickly.\nContainers are like newspapers Containers are like newspapers. Newspapers have a particular task: providing you with the day\u0026rsquo;s news. You cannot use newspapers to study for your mathematics exam. You use your math book to study for your math exam. If you want to be informed of the day\u0026rsquo;s news, you use a newspaper. This is what I mean by containers having a specific task.\nNext, newspapers are printed on a specific kind of paper. When you buy an expensive book, it will have a sturdy and durable cover, and the pages are made of nice thick paper that will last a long time. The pages don\u0026rsquo;t tear very quickly, and when the book gets wet, it can withstand it. This thick cover and high-quality papers are like the operating system of a virtual machine.\nNewspapers, on the other hand, are printed on very thin paper. Because they are designed to distribute the news to you effectively, newspapers do not need to be stored forever or do any other tasks. If you used thick, expensive paper for newspapers, they would become costly, and no one would buy them anymore. The paper is optimized to bring the news to you.\nIn the same way, the container only comes with the components it needs to do its specific task. Therefore, the container is optimized for its purpose. As a result, they can be distributed more quickly and do not take up a lot of resources when running.\nThere are other benefits to containers, such as improving the ability to autoscale your application, but I will expand on those in a future blog post.\nFurther study To learn more about containers, you can use the following resources:\nContainers \u0026amp; Friends from John Savill\u0026rsquo;s DevOps Masterclass\nDocker Documentation\nDocker Tutorial for Beginners\n","permalink":"https://mischavandenburg.com/zet/articles/what-are-containers/","summary":"When you learn about DevOps, you will come across the concept of a container early on. This is a \u0026ldquo;Mischa Explains\u0026rdquo; article where I attempt to explain a concept in my own words as simply as possible. I use the Feynman technique and pretend to explain it to a 12-year-old.\nVirtualization To understand containers, we need to understand virtualization. Virtualization is the process of creating \u0026ldquo;fake computers\u0026rdquo; or \u0026ldquo;virtual computers\u0026rdquo; on a physical computer.","title":"What Are Containers?"},{"content":"I\u0026rsquo;ve been using neovim for over a year now, and I\u0026rsquo;m very happy that I went through the initial difficulty of learning vim. One of the best perks of using neovim is that you can customize your entire editing experience and workflow. However, it can be a daunting experience to start with an empty configuration and set up everything from scratch.\nI started with an empty vanilla vim config and slowly added the plugins as I went along. Videos by content creators such as ThePrimagen were also helpful in getting inspiration on which plugins I might like for my setup. But this might not be suitable for everyone. I was only editing yaml files and writing simple Python scripts at the time, whereas you might be looking for an IDE experience out of the box.\nRecently I discovered kickstart.nvim by neovim core maintainer TJdeVries.\nI decided to give it a try, and I was pleasantly surprised. It is a great starting setup for a beginner. It is simple and does not overwhelm you with thousands of features.\nI\u0026rsquo;ve completely rewritten my config based on kickstart.nvim, and I am delighted with the result. Especially the LSP setup is very well thought out, and it works much better than the setup I came up with on my own.\nTJ DeVries also made a video introducing kickstart.nvim and going through the initial setup.\nI highly recommend kickstart.nvim if you are interested in using neovim and are looking for a sane place to start.\nlinks kickstart.nvim\nKickstart video by TJdeVries\n","permalink":"https://mischavandenburg.com/zet/articles/kickstart-nvim/","summary":"I\u0026rsquo;ve been using neovim for over a year now, and I\u0026rsquo;m very happy that I went through the initial difficulty of learning vim. One of the best perks of using neovim is that you can customize your entire editing experience and workflow. However, it can be a daunting experience to start with an empty configuration and set up everything from scratch.\nI started with an empty vanilla vim config and slowly added the plugins as I went along.","title":"Getting Started with Neovim: kickstart.nvim"},{"content":"TLDR It took me 80 hours of studying to gain this certification. Here are my notes and Anki deck: GitHub repo\nIntroduction When I did my English degree at University, exams were usually handwritten essays that needed to be done within a 3-hour timeframe. Sometimes we had multiple-choice tests, and I would always consider them a guaranteed pass because multiple-choice was much easier in my experience.\nThat opinion has changed since I\u0026rsquo;ve obtained a few IT certifications. These tests are hard! I\u0026rsquo;m typing this while sitting on the bus on my way home from my AZ-104 exam. I passed with an 860 score of 1000, where 700 or higher is a pass. But it was an astonishingly tough exam. Usually, I finish quickly and spend at least half an hour reviewing my answers. I had only 5 minutes to review my questions this time because I had used up all of the available time. The questions required intense concentration and were time-consuming because I needed to compare many options which were very similar to each other. There were no easy questions.\nPreparation I studied 80 hours for this exam in a month. I work full-time as a DevOps Engineer, so I study in the evenings and on weekends. I have my Azure Fundamentals and CKA, but I only work with Azure occasionally in my current role.\nHere is what I did to prepare for my exam:\nGo through all of the Microsoft Learn modules for the AZ-104 Watch the entire AZ-104 study list by John Savill Practice exams on TutorialsDojo until I could pass them with 90%+ scores Microsoft ESI practice exams Microsoft AZ-104 Exam prep videos Microsoft Learn You really need to master all of the subject matter. Only completing the Microsoft Learn modules is not enough preparation. They are more like summaries. At the end of each module, they provide links to the documentation for the subject for further study. Unfortunately, Microsoft does not go easy on you. It expects you to know obscure details of nearly every service this exam covers. Therefore, I advise going beyond the Microsoft Learn modules and studying the linked articles after each module.\nYouTube AZ-104 Study Playlist by John Savill I\u0026rsquo;m not sure if it\u0026rsquo;s better to watch this playlist first and then do the Microsoft modules or the other way around. I did the Microsoft modules first, but for my next exam (AZ-400 DevOps Expert), I\u0026rsquo;ll start with the videos and then do the Microsoft Learn modules.\nTutorialsdojo These practice exams are excellent. I used them in preparation for my fundamentals exam.\nThe best thing about them is that they provide extensive documentation and explanation of the questions. So after you finish the exam, you can study a lot with these examples.\nESI Practice Exams You\u0026rsquo;re lucky if your organization participates in Microsoft\u0026rsquo;s Enterprise Skills Initiative. The practice exams provided in the ESI environment give you a good indication of what you can expect at the exam. I first did the Tutorialsdojo exams and then moved on to the ESI exams, and I was humiliated. The ESI questions are very complex and hard to solve, and I learned a lot from these exams.\nThere are 210 questions total, and I worked through all of them, and whenever I failed a question, I did a deeper dive into the question\u0026rsquo;s theme.\nstudying I take notes in Obsidian, and I use Anki for spaced repetition. I highly recommend keeping a deck of Anki cards and continuously testing yourself. You will need to memorize a lot of details. For example, you are expected to remember that storage accounts of the FileStorage type do not support Geo Redundant Storage. You can find my Anki deck in the GitHub repo.\nlinks AZ-104 Exam page with learning modules\nJohn Savill\u0026rsquo;s AZ-104 Study playlist\nGitHub repo containing my notes and Anki deck\nMicrosoft AZ-104 Exam prep videos\n","permalink":"https://mischavandenburg.com/zet/articles/az-104-study-guide/","summary":"TLDR It took me 80 hours of studying to gain this certification. Here are my notes and Anki deck: GitHub repo\nIntroduction When I did my English degree at University, exams were usually handwritten essays that needed to be done within a 3-hour timeframe. Sometimes we had multiple-choice tests, and I would always consider them a guaranteed pass because multiple-choice was much easier in my experience.\nThat opinion has changed since I\u0026rsquo;ve obtained a few IT certifications.","title":"Study Guide: AZ-104 Azure Administrator Associate"},{"content":"This weekend I had a lot of fun with a project. I wanted to learn more about GitOps and try out ArgoCD.\nMy goal was to be able to deploy an application from a GitHub repo to my local Kubernetes cluster running in minikube. There are many options I could have used, such as running Jenkins in my cluster. But I wanted to use Azure pipelines for practice, which complicates the deployment to my local cluster, because the cluster is not running on Azure. I also wanted to try out ArgoCD and learn more about GitOps.\nThe application is a simple web app that I wrote which displays a quote in the browser:\nGitOps and Structure GitOps is used to automate the process of provisioning infrastructure. Infrastructure as code is used to generate the same environment every time the environment is deployed.\nFor my project I have two separate GitHub repos. The first repo contains the code for a simple web app I created and the Dockerfile to generate the image. I call this my application repo. The other repo is my GitOps repo which contains the manifest files to deploy the application in Kubernetes. I decided to leverage Helm to create my manifest files. This way I can create templates and define my desired values in a values.yaml file in the repo.\nUltimately my goal was to use an Azure pipeline to build an image from my application repo and push it to Docker hub. This new image is given a new tag which needs to be stored. The first pipeline should trigger a new pipeline that makes a pull request to the GitOps repo to update the tag in my Helm chart.\nArgoCD will then scan the GitOps repo and realize that the tag has been updated, and deploy the new tag to my cluster.\nMinikube I used minikube to deploy my local Kubernetes cluster. Another option is kind (Kubernetes In Docker) but I wanted to use a VM approach this time.\nArgoCD ArgoCD is a declarative GitOps continuous delivery tool for Kubernetes. This is the solution I used to continuously scan my GitOps repo. When ArgoCD detects a change in the desired state, it will compare it with the state in my running cluster and make changes accordingly. I found a really good tutorial to run ArgoCD in minikube.\nAzure Pipelines With my cluster running on my local machine and my repos set up, I needed to use Azure Pipelines to bring it all together. Building the image and pushing it to Docker Hub wasn\u0026rsquo;t a big deal. But I had two big challenges in my desired setup: I needed to pass the new tag number to a new pipeline, and I needed to use Azure Pipelines to create a new PR to my GitOps repo.\nPassing a value from one pipeline to another Interestingly, this wasn\u0026rsquo;t as easy as it sounds, and from my internet searching it seemed that many people struggled with this. I decided to use the Variable Groups in Azure DevOps. However, after I finished writing my pipeline, I discovered I had no problems with reading the value from the Variable Groups, but it was impossible to update it using existing pipeline tasks. So I had to a bit of hacking to make it work. In the end I had to use the Azure CLI from within the pipeline to update my variable:\n- stage: update_tag jobs: - job: update_tag_variable displayName: Update Tag Variable steps: - bash: | az pipelines variable-group variable \\ update --group-id 202 \\ --org $(System.CollectionUri) \\ --project $(System.TeamProject) \\ --name tag --value $(Build.BuildId) env: AZURE_DEVOPS_EXT_PAT: $(System.AccessToken) This didn\u0026rsquo;t feel like a very elegant solution, but it was the only solution I could come up with.\nI also struggled a lot with permissions. I needed to find the correct service principal to assign the administrator rights to. This post really helped to solve my problem.\nSubmitting a PR to a GitHub repo When I started writing my pipeline I thought it would be very straightforward to just submit a PR to a repo, but I quickly discovered that this is not natively supported in Azure pipelines yet. In fact, I could not find a way to submit a PR at all. I had to settle for a solution that checks out the GitOps repo and creates a new branch. This new branch updates the tag in the values.yaml with the new tag that was passed from the previous pipeline.\nvariables: - group: mischa-quote - name: passed_tag value: $[variables.tag] - name: branch_name value: \u0026#34;pipeline-$(passed_tag)\u0026#34; pool: vmImage: ubuntu-latest steps: - checkout: self persistCredentials: true clean: true - script: | git config --global user.email \u0026#34;mischa@pipeline.com\u0026#34; git config --global user.name \u0026#34;Mischa Pipeline\u0026#34; git switch -c \u0026#34;$(branch_name)\u0026#34; sed -i \u0026#34;s/tag:.*/tag: $(passed_tag)/\u0026#34; values.yaml git add . git commit -m \u0026#34;Update tag to $(passed_tag)\u0026#34; git push --set-upstream origin \u0026#34;$(branch_name)\u0026#34; This also felt a bit hacky to do with explicit shell commands, but it was the only way I could find to achieve my goal. I used sed to update the tag.\nResult The resulting deployment pipeline is as follows.\nI make a commit to my application repo, which triggers a build pipeline in Azure DevOps: This resulted in an image pushed to my Docker Hub: The pipeline created a new branch in my GitOps repo. Unfortunately, I have to make the PR myself, but as you can see, the pipeline successfully updates the values.yaml with the new tag which we also saw in Docker Hub: When I merged the pull request, ArgoCD detected the change and deployed a new pod with the new tag. Running a kubectl describe on the pod also verifies that we have the correct image: Conclusion This was a fun challenge, but I learned a lot from solving the problems I encountered and my entire Saturday flew by in an uninterrupted flow state. I had some good practice in setting up Azure pipelines, learned about Helm, and did my first implementation of GitOps. Not bad for a day\u0026rsquo;s work!\nLinks Application GitHub repo\nGitOps repo\nminikube\nkind\nArgoCD\ntutorial to run ArgoCD in minikube\n","permalink":"https://mischavandenburg.com/zet/articles/lab-argocd-azure-pipelines/","summary":"This weekend I had a lot of fun with a project. I wanted to learn more about GitOps and try out ArgoCD.\nMy goal was to be able to deploy an application from a GitHub repo to my local Kubernetes cluster running in minikube. There are many options I could have used, such as running Jenkins in my cluster. But I wanted to use Azure pipelines for practice, which complicates the deployment to my local cluster, because the cluster is not running on Azure.","title":"Lab Project: GitOps with ArgoCD, Azure Pipelines and Minikube"},{"content":"Introduction Have you ever thought about your identity on the internet? How does LinkedIn know it is you when you log in to LinkedIn? And when you allow LinkedIn to post to your Twitter, how does LinkedIn access your account and not your kindergarten teacher\u0026rsquo;s account?\nThis is a \u0026ldquo;Mischa Explains\u0026rdquo; article where I attempt to explain a concept in my own words as simply as possible. I use the Feynman technique and pretend to explain it to a 12-year-old.\nIdentity The first step in this process is identity. You need a starting point; for many of us, this can be our Google account. You signed up for this account and probably verified this with your phone number.\nThis relates to authentication. Authentication is the process of verifying identity. You\u0026rsquo;ll need to provide the correct password when you log in to your Google account. You must give a valid password to log in to your account and access the resources. Google uses your password to authenticate that it is you.\nAuthorization Then we have authorization. Authorization means granting access to particular resources. For example, let\u0026rsquo;s say you are working in the science classroom at school. In the classroom is a bookcase that everybody can use: it is not dangerous, and every student can take the books they need without asking for permission. In the back of the science classroom is a cabinet that contains chemicals. It would be very dangerous if everybody could go into the cabinet and take out the sulphuric acid. Not everybody might know how dangerous sulphuric acid is. That\u0026rsquo;s why the cabinet is locked.\nIf you need something from the chemicals cabinet, you need to ask permission from the teacher. You need to be authorized by the teacher to take out the sulphuric acid. When you make your request, the teacher may ask you questions to ensure you know what you are doing. He might even ask you for your school ID card because he has not seen you before. The teacher authenticates you by asking for your school ID, and then he authorizes you to take out the sulphuric acid.\nTokens How do we accomplish this on the internet?\nTo verify identities on the internet, we have identity providers. Google is an identity provider. Azure AD is also an identity provider. An open-source identity provider is Keycloak.\nIdentity providers use tokens to verify identity and authorize access to resources. There are two types of tokens: ID tokens and access tokens. And for each token, there is an associated protocol.\nID tokens OpenID Connect, also known as OIDC, is an open standard for authentication. Identity providers have agreed with each other that they will use this standard. When you go through an OpenID workflow, the result is an ID token, proving that the user has been authenticated.\nYour school ID card is the ID token in our science class example. When you started at your school, you went through a registration process. Your parents probably handled this. Your name was written down, and the school verified that it was you by looking at your passport and talking to your parents. The result of this process was your school ID card, which you use to borrow books from the library. The school ID card proves that you are a student of that school and that you can use the facilities at the school.\nAccess tokens These are specifically designed to allow access to a resource. For example, this resource could be a file on a server or a database.\nAccess tokens are strictly for authorization and use the OAuth 2.0 standard.\nIn our science class example, the token would be the key to the chemicals cabinet. The teacher authorizes you to access the cabinet and gives you the key to the cabinet.\nPutting it Together Now let\u0026rsquo;s put it together with an example.\nYou just created a new Facebook account and want to add all your friends. However, you have a Google account, and Facebook can use the contacts in your Google account to automatically add all of your friends.\nYour Google account can only be accessed by you, and your contacts are locked away behind a password. But it is possible to grant Facebook access to this.\nOn Facebook, you select the \u0026ldquo;import contacts from Google\u0026rdquo; function. Facebook sends you to Google, and Google will ask you to log in. Google is the teacher in our science class example. Google needs you to authenticate to prove that it is you. When this is done, Google generates an ID token using OIDC for Facebook: Google gives Facebook a school ID that it can use.\nNext, Facebook needs access to the contacts in your Google account. In our example, Facebook asks to take the sulphuric acid from the chemicals cabinet. You will see a menu that specifies what Facebook wants to do, and you need to give your permission. When you give your permission, Google generates an OAuth 2.0 token for Facebook. In other words, Google gives the key to the chemicals cabinet to Facebook, and Facebook is now authorized to take the sulphuric acid.\nWhen both of these tokens are generated, Facebook contacts Google and asks if it can take the sulphuric acid from the chemicals cabinet.\nGoogle, the teacher, asks Facebook for the school ID, and Facebook shows the ID card it received earlier. When Google is satisfied with the ID and successfully authenticates Facebook, it gives Facebook the key to the chemicals cabinet. Facebook is now authorized to take out the sulphuric acid. Facebook is now authorized to access the contacts in your Google account.\nLinks You can use these resources to learn more about this topic:\nAn Illustrated Guide to OAuth and OpenID connect\nID Tokens vs Access Tokens - Do you know the difference?\nMicrosoft Learn: ID Tokens\nMicrosoft Learn: Security Tokens\n","permalink":"https://mischavandenburg.com/zet/articles/identity/","summary":"Introduction Have you ever thought about your identity on the internet? How does LinkedIn know it is you when you log in to LinkedIn? And when you allow LinkedIn to post to your Twitter, how does LinkedIn access your account and not your kindergarten teacher\u0026rsquo;s account?\nThis is a \u0026ldquo;Mischa Explains\u0026rdquo; article where I attempt to explain a concept in my own words as simply as possible. I use the Feynman technique and pretend to explain it to a 12-year-old.","title":"Tokens and Identity on the Internet"},{"content":"An interesting podcast episode describing the system that runs Norway\u0026rsquo;s welfare payments. It was interesting to hear that they focus on open source and that everything runs one one big kubernetes cluster.\nIt was also very inspiring to hear that they went from 4 nightly deployments a year to 1700 deployments a week.\nLink to the podcast episode:\nThe system that runs Norway\u0026rsquo;s welfare payments\n","permalink":"https://mischavandenburg.com/zet/articles/nav-podcast/","summary":"An interesting podcast episode describing the system that runs Norway\u0026rsquo;s welfare payments. It was interesting to hear that they focus on open source and that everything runs one one big kubernetes cluster.\nIt was also very inspiring to hear that they went from 4 nightly deployments a year to 1700 deployments a week.\nLink to the podcast episode:\nThe system that runs Norway\u0026rsquo;s welfare payments","title":"Podcast Tip: The system that runs Norway's welfare payments"},{"content":"I came across this little book while doing some research for my Jiro Dreams of Sushi article. While scanning the book\u0026rsquo;s description, I was intrigued by this sentence: \u0026ldquo;the happiness of always being busy.\u0026rdquo; Although I work hard every day, I also enjoy ticking off the last item on my to-do list and enjoying some rest. Is there more happiness in being in constant activity?\nIkigai \u0026ldquo;He who has a why to live for can bear with almost any how.\u0026rdquo;\nFriedrich Nietzsche According to Japanese culture, everybody has a purpose in life: the ikigai. \u0026ldquo;Ikigai is the reason we get up in the morning.\u0026rdquo; The book explores this concept through interesting stories and brings related notions from various areas to explain ikigai to the Western mind.\nThere are many different ikigai, and people can have several ikigai simultaneously. For example, some people have their vegetable garden as their ikigai, while others have drawing or calligraphy. Jiro has making sushi as his ikigai. Even though many people have their work as their ikigai, it does not necessarily have to be the case. Ikigai can also be of a social nature, such as a family or local community.\nRetirement When I watched Jiro Dreams of Sushi for the first time, I was surprised that Jiro still worked at his restaurant every day at age 85. This book explores that further.\nApparently, many people never really retire in Japan. The concept of retirement, as we know it in the West, does not exist in the Japanese language: there is \u0026ldquo;no word in Japanese that means retire in the sense of \u0026ldquo;leaving the workforce for good\u0026rdquo; as in English.\u0026rdquo; People continue doing what they like doing as long as their health allows. They keep following their ikigai.\nThis concept was very refreshing to me and had a profound influence on how I imagine my own future. After becoming more intentional about my career, I became interested in FIRE and the possibility of retiring early. However, as I contemplated this strategy, I discovered that I didn\u0026rsquo;t want to stop working because I really enjoy my work.\nWhy would I want to retire if I\u0026rsquo;m doing what I love? That was the whole point of switching my career to IT, and this is where Western culture can learn a lot from Japanese culture. In Japanese culture, there is more emphasis on aligning your career with your interests and continuing that passion well into old age.\nWhen to quit? The job you have worked so hard for? I never once hated my job. I fell in love with my work and gave my life to it. Even though I\u0026rsquo;m 85 years old, I don\u0026rsquo;t feel like retiring.\nJiro Longevity A large part of the book is about the residents of Okinawa: the island with the highest number of people 100 years old or older. The authors tell the story of their visit to the island to reveal the secret of the Okinawan\u0026rsquo;s long lives. It is not uncommon to see people working in the fields who are well into their eighties. The Okinawans freely share their secrets with us, and the authors do a great job translating the Japanese principles into actionable advice.\nMuch of the advice is centered around dietary habits. Not only what to eat, but also how to eat it: \u0026ldquo;Okinawans stop eating when they feel their stomachs reach 80 percent of their capacity, rather than overeating\u0026rdquo;, a practice which is named \u0026ldquo;hara haci bu.\u0026rdquo; They consume a daily average of 1800 to 1900 calories, a significant difference from the 2200 to 3300 calories consumed by an average person in the US every day.\nAnother theme that keeps returning is the crucial function of social groups for finding meaning in life, especially in old age: \u0026ldquo;It is customary in Okinawa to form close bonds within local communities. A moai is an informal group of people with common interests who look out for one another. For many, serving the community becomes part of their ikigai.\u0026rdquo;\nThis book may be a good resource if you are interested in longevity. Even though I only expected to read about the ikigai concept, it contains a surprisingly large amount of valuable advice and practical tips to live a longer and happier life.\nChock-full \u0026ldquo;Ikigai: The Japanese Secret to a Long and Happy Life\u0026rdquo; is a small book that covers an astonishing amount of subjects. It covers topics such as meditation, flow states, and exercise methods such as Tai Chi and Qi Gong. The disadvantage is that it does not deeply cover any of these topics. But I think this book can be a very useful springboard for further research and a great introduction to many different subjects that can improve your life.\nIt is a short read, but it contains a lot of wisdom, and I learned much from this book. It has changed the way I think of retirement and the way I approach my work. I am also very interested in health and longevity. Through the conversations with the centenarians of Okinawa, I received a lot of helpful tips, which I\u0026rsquo;m already applying to my daily life.\nHave I discovered the art of being busy? I believe I took this definition too literally when I started reading this book. I found that Okinawans lead active lives full of meaning but also take plenty of rest. Always being busy does not mean that you have to work yourself to death. However, it does mean that the secret to reaching a healthy old age is to keep doing what you love. There is no need to become sedentary and only sit in front of the TV when you turn 67. I think Western culture has a lot to learn in this area.\n","permalink":"https://mischavandenburg.com/zet/articles/ikigai-book/","summary":"I came across this little book while doing some research for my Jiro Dreams of Sushi article. While scanning the book\u0026rsquo;s description, I was intrigued by this sentence: \u0026ldquo;the happiness of always being busy.\u0026rdquo; Although I work hard every day, I also enjoy ticking off the last item on my to-do list and enjoying some rest. Is there more happiness in being in constant activity?\nIkigai \u0026ldquo;He who has a why to live for can bear with almost any how.","title":"Book Notes: Ikigai: The Japanese Secret to a Long and Happy Life"},{"content":" This book is the sequel to the Phoenix project. Both books are set at Parts Unlimited, a fictitious company that supplies car parts to DIY mechanics and repair shops. Phoenix is a new system that Parts Unlimited has worked on for multiple years. It is supposed to handle order processing and communication between manufacturing, stores, and clients. Phoenix will also play a role in sales and marketing. The company has been gathering customer data for years, but it cannot use any of this data yet. Phoenix will enable it to generate targeted marketing campaigns from the data when it\u0026rsquo;s finished.\nBut as we saw in the previous book, it is far from finished, and things go wrong all the time. The company is not doing well, the stock prices are falling, and they need an edge over the competition. Phoenix will be their edge, but they\u0026rsquo;ve been working on it for years. Eventually, management decided that Phoenix needed to be deployed in two weeks. But it is far from ready.\nThe main character in the Unicorn project is Maxine, a senior developer who temporarily transferred to a different department. She had to work on the Phoenix project against her will because of an unfortunate situation that needed a scapegoat. However, Maxine decides to make the best out of it, and she\u0026rsquo;d like to begin with one thing: to get a Phoenix build going on her laptop.\nVery quickly, she finds it impossible to run a full build of the Phoenix project due to missing files and other elements. She is appalled and makes it her mission to get the build going, but she meets another hurdle every step of the way. Missing credentials. Missing binaries and libraries. And for each of these hurdles, she must submit a ticket with a different department. Very soon, she has over 20 tickets running with long waiting times. Just to get a build going on her machine so she can work! Dozens of developers were hired to work on the Phoenix project. But when she asks them if they\u0026rsquo;ve managed to get a build going yet, Maxine is horrified to discover that they\u0026rsquo;ve tried for several months but haven\u0026rsquo;t made any progress. Maxine has made more progress in a week.\n\u0026ldquo;Everyone around here thinks features are important because they can see them in their app, on the web page, or in the API. But no one seems to realize how important the build process is. Developers cannot be productive without a great build, integration, and test process.\u0026rdquo;\nUnicorn Project After a few weeks, Maxine receives an invitation to have a drink with a group of people who are very interested in her. When she arrives at the bar, she meets the Rebellion: a group of developers, managers, and people from Operations, who are tired of the old organizational structure and want to make real changes. They think out of the box and experiment with new technologies, even though they are not authorized to do so.\nWith the Rebellion, Maxine significantly improves the build and deployment process. They recognized that Phoenix actually never was being built in its entirety. Developers were always working on parts of the application. However, after a lot of struggle, they create a build process that enables each developer to become operational on his first day.\nThis is the first step of a long series of exciting events that lead to Phoenix becoming a success. By the end of the book, they have a completely new development and testing process, and they can deploy changes to production without needing to take the entire application down. This allows them to create targeted marketing campaigns and respond to changes in the market. The first campaign was a huge success and generated the highest sales ever.\nMaxine\u0026rsquo;s struggle with the build process was an eye-opening experience for me. It gave me a very practical example of the need for DevOps principles to enable delivering value to customers. It is also something I recognize in my current organization. For example, projects can get stuck on a firewall change that needs to be approved by an external party. By implementing DevOps principles and arranging teams according to the \u0026ldquo;you build it, you run it\u0026rdquo; principle, teams can be responsible for the entire process from idea to production and therefore have a very short release cycle for their application.\nI thoroughly enjoyed the first part of the book. However, the second part was less engaging to me. It became long-winded and felt like butter spread over too much bread. The author demonstrates a high level of technical experience and knowledge through his descriptions of processes, deployments, and fictional applications. Although I understand the intention of making Parts Unlimited a believable company, I think it could have been accomplished with much less detail and words.\nThe second part has more corporate drama, such as temporarily suspended managers without any clear reason. The focus shifts from a development and operations perspective to a managerial perspective. Maybe I will reread the book in a few years and this part will make a lot more sense to me then. The same happened when I reread the Phoenix project. I could not understand some aspects of the book, which became much clearer to me when I revisited it after gaining experience in the field.\nI highly recommend this book to anyone working as a developer, DevOps Engineer, or in operations, especially if you are starting your career. The book gave me a lot of insights into \u0026ldquo;the old way of working\u0026rdquo; and a better understanding of the need for DevOps principles in the modern IT landscape. However, make sure to read the Phoenix project first.\nThe Unicorn Project: A Novel about Developers, Digital Disruption, and Thriving in the Age of Data by Gene Kim ","permalink":"https://mischavandenburg.com/zet/articles/unicorn-project/","summary":"This book is the sequel to the Phoenix project. Both books are set at Parts Unlimited, a fictitious company that supplies car parts to DIY mechanics and repair shops. Phoenix is a new system that Parts Unlimited has worked on for multiple years. It is supposed to handle order processing and communication between manufacturing, stores, and clients. Phoenix will also play a role in sales and marketing. The company has been gathering customer data for years, but it cannot use any of this data yet.","title":"Book Notes: The Unicorn Project"},{"content":"Last week I watched \u0026ldquo;Jiro Dreams of Sushi\u0026rdquo; again. It must be the eighth time I revisited this piece of art. I have very little interest in sushi, but there is much more to this documentary. It was first recommended to me by my good friend Anders more than five years ago, but I couldn\u0026rsquo;t grasp its underlying life lessons the first time around.\nEven though I couldn\u0026rsquo;t fully understand the message, I was intrigued by it and kept returning to the documentary. Over the years, I managed to grasp more of its deeper meaning. The documentary is about Jiro: one of the best sushi chefs in the world. His tiny restaurant, located in a subway station, even received a 3 Michelin star rating. So how does a man operating from a subway restaurant become the best in the world? And what can a DevOps Engineer learn from a sushi chef?\nJiro is referred to as a shokunin, a Japanese cultural phenomenon that doesn\u0026rsquo;t have a direct translation into English. A shokunin is an artisan or a craftsman who has devoted his entire life to becoming a master of his craft. For example, there are shokunin carpenters, weavers, and blacksmiths. The shokunin achieve mastery by doing the same action over and over again and trying to improve with every repetition.\n\u0026ldquo;Once you decide on your occupation, you must immerse yourself in your work. You have to fall in love with your work. Never complain about your job. You must dedicate your life to mastering your skill. That\u0026rsquo;s the secret of success and is the key to being regarded honorably.\u0026rdquo;\nJiro We get to know Jiro as a man who is devoted to his occupation. He follows the same routine every day; he even gets on the train from the same position. He says he dislikes holidays and prefers to be at work. He used to get up at 5:00 and get home after 22:00. Even at age 85, he\u0026rsquo;s still working at the restaurant every day, simply because he doesn\u0026rsquo;t want to do anything else.\nBut it\u0026rsquo;s not just about putting in long hours and working past the retirement age. It\u0026rsquo;s also about the mindset and the attitude that Jiro has adopted towards his craft:\n\u0026ldquo;I\u0026rsquo;ve seen many chefs who are self-critical, but I\u0026rsquo;ve never seen another chef who is so hard on himself. He sets the standard for self-discipline. He\u0026rsquo;s always looking ahead. He\u0026rsquo;s never satisfied with his work. He\u0026rsquo;s always trying to find ways to make the sushi better or to improve his skills. Even now, that\u0026rsquo;s what he thinks about every day.\u0026rdquo;\nMasuhiro Yamamoto, Food Critic. Finding my Craft It was hard to decide on my occupation. It took me 32 years and a lot of trial and error to find the answer. I have always envied people who knew they wanted to become a nurse since childhood.\nWhat occupation should I choose? I answered this question by answering another question: what do I like to do in my free time? The answer was clear: I tinkered with computers. I had already coded several websites and loved experimenting with game automation. I ran \u0026ldquo;bot farms\u0026rdquo; on Linux servers which I configured myself from the command line.\nI decided to make IT and tech my occupation. Fortunately for me, the job market was in my favor, and employers were much more willing to consider candidates without a formal background in IT. If you\u0026rsquo;d like to read more, I wrote about my journey into DevOps in this article.\nThe Ways of the Shokunin After making the career change, I adopted the shokunin mindset and dedicated my life to mastering my craft. In practical terms, I needed to commit to devoting my time to my profession and avoid straying from it. Making this commitment wasn\u0026rsquo;t very difficult because I chose my career based on my free-time activities. It\u0026rsquo;s more about adopting a mindset of striving to make everything relate to each other. For example, I try to select hobby projects that directly relate to what I\u0026rsquo;m working with during the day. This way, my leisure activities will strengthen my professional skills, and my professional expertise will improve my hobby projects, creating a feedback loop that will eventually lead to results.\nHowever, sticking to one thing does not necessarily come naturally to me. I have a tendency to pick up many different hobbies and get very excited about them. First, I will become extremely interested in a particular subject. Then, after approximately three months, I put it aside and become excited about something else. This isn\u0026rsquo;t necessarily a case of Shiny Object Syndrome because I tend to return to these hobbies in a cyclical pattern. As I apply myself to learning the skill with a feverish intensity, I\u0026rsquo;m able to make a lot of progress during these bouts of obsession. But to the outside world, it might seem like I\u0026rsquo;m constantly changing my mind about what I want.\nI always considered this a negative character trait, but over the past few years, I\u0026rsquo;ve learned to embrace it and guide this tendency in the right direction. Because I chose IT as my occupation and DevOps as an area of specialization, I gave myself a broad scope of interest with many sub-skills to learn. If you look at the DevOps Roadmap, you\u0026rsquo;ll see that a good DevOps Engineer must master many different skills.\nIt\u0026rsquo;s like I\u0026rsquo;ve given myself a large playground with a fence around it, full of exciting things to learn. I can go down a Python rabbit hole for a few months and improve my coding skills. Later, I find myself sucked into builing my own OS and learning more about Linux in the process. The fence around the playground isn\u0026rsquo;t locked, but I do my best to stay inside the fence. When, for example, I start getting the urge to get back into music production again, I consider that it will take up a few hours a day to get back on track. Investing these hours into something that brings me joy, but is also related to my occupation, would be a better option. Reflecting in this way keeps me focused on my goals.\nMy website is another example of this fusion between professional and free-time activities. I love to write. It\u0026rsquo;s a relaxing activity, even though it is very challenging sometimes. After I learn about a new subject, I try to write about it. This is the best way I know to verify whether I\u0026rsquo;ve really understood the topic. When I sit down to write about something, I force myself to think clearly about it and to make sure everything aligns properly in my mind. When I cannot explain the concepts in a few clear sentences, I know I don\u0026rsquo;t fully understand it yet.\n\u0026ldquo;Clear thinking becomes clear writing; one can\u0026rsquo;t exist without the other.\u0026rdquo;\nWilliam Zinsser, On Writing Well Another way my blog supports my professional development is because I prefer to write my blog posts in neovim in the markdown format. Writing and editing text often involves moving a lot of words and paragraphs around. Because I use vim to do my writing, I\u0026rsquo;m also constantly practicing the keybinds I use for writing and editing code during my day job. I often learn a new motion for my blog writing, which I use the next day at work.\nNever Finished \u0026ldquo;All I want to do is make better sushi. I do the same thing over and over, improving bit by bit. There is always a yearning to achieve more. I\u0026rsquo;ll continue to climb, trying to reach the top, but no one knows where the top is. Even at my age, after decades of work, I don\u0026rsquo;t think I have achieved perfection. But I feel ecstatic all day. I love making sushi. That\u0026rsquo;s the spirit of the shokunin.\u0026rdquo;\nJiro Jiro taught me never to be satisfied with my skills. If I desire to become a master of my craft, there will never be a point where I can lean back and think that I\u0026rsquo;ve learned enough. There\u0026rsquo;s always something to improve, which is why I chose an IT career. My thirst for learning cannot be quenched, and there\u0026rsquo;s always something to learn in this field.\nDevotion Although it might seem like a simple food documentary, do not be deceived. Jiro Dreams of Sushi is full of valuable life lessons. It\u0026rsquo;s one of the documentaries which I revisit regularly. It\u0026rsquo;s relaxing to watch, and I get hugely inspired by Jiro\u0026rsquo;s devotion to his craft and powerful teachings every time.\nJiro\u0026rsquo;s guidance has changed my life. He made me realize that if I wished to become a master of my craft, I needed to devote my life to it. I changed my lifestyle, so the things I do in my free time strengthen my professional skills. I also became more mindful of the content I consume and the things I read, trying to keep it related to my occupation. He showed me the true meaning of the phrase \u0026ldquo;my work is my hobby.\u0026rdquo;\n\u0026ldquo;Always look beyond and above yourself. Always try to improve on yourself. Always strive to elevate your craft. That\u0026rsquo;s what he taught me.\u0026rdquo;\nYoshikazu, Jiro\u0026rsquo;s oldest son. ","permalink":"https://mischavandenburg.com/zet/articles/jiro-sushi/","summary":"Last week I watched \u0026ldquo;Jiro Dreams of Sushi\u0026rdquo; again. It must be the eighth time I revisited this piece of art. I have very little interest in sushi, but there is much more to this documentary. It was first recommended to me by my good friend Anders more than five years ago, but I couldn\u0026rsquo;t grasp its underlying life lessons the first time around.\nEven though I couldn\u0026rsquo;t fully understand the message, I was intrigued by it and kept returning to the documentary.","title":"I'm In Love with my Work: Lessons from a Japanese Sushi Master"},{"content":"If you are just starting your Linux journey, you might have noticed that a few camps exist in the Linux world. Just like in any other area of life, it seems that groups of human beings enjoy dividing themselves instead of living in harmony. There are camps centered around Linux distributions (I use Arch, btw) but also around text editors.\nThe Beginning The reason why I started to use vim is rather practical. When I was studying to become a Cloud Engineer, I had access to subscriptions on AWS and Azure to experiment with virtual machines. This was a perfect place to learn to work with Ansible. Many of the labs projects I did involved setting up a few virtual machines, and I destroyed many VMs when I made some big mistakes in the configuration.\nI was using Visual Studio Code at the time on my local machine, but I had to connect to a new virtual machine multiple times a day. It became very tiresome to set everything up with VSCode every time, or pulling the files to my local machine and copying them over again. So I just ssh\u0026rsquo;ed into the machines to edit the text files with the included editor, which happened to be vim.\nObsession in its Infancy When you first use vim, it is a rather disorienting experience. But in every tutorial, I was told it would be difficult in the beginning but much faster and more effective in the end. I found this very appealing because I like to do things the hard way and challenge myself.\nI discovered that there were people out there who did all of their text editing and coding in vim. I met programmers who refuse to use anything else and people who write entire books in vim. So there had to be something to it.\nIt also fitted very well with my intention of working on the command line as much as possible and moving away from GUI applications whenever possible. I like to move in this direction because I love the idea of controlling your entire workflow with your keyboard instead of using your mouse, and vim fits perfectly into this picture.\nWhat I like after Nine Months At this point, I\u0026rsquo;ve been using vim as my primary text editor for about nine months. In my current job, I work a lot with yaml files stored in private git repositories.\nI only work with these files from the command line, and I don\u0026rsquo;t have any other code editor installed. I use ripgrep and fzf (fuzzy file finder) to search through the files, and I use neovim to edit them. When I need to search for files from within vim, I use the awesome Telescope plugin.\nIn these months, I\u0026rsquo;ve picked up a few tricks, and I am starting to see the power of vim. The best thing I like about it is that I don\u0026rsquo;t have to leave my terminal window to do the tasks I need to do. Instead, I can search through the files I need to work with, open them, make adjustments, and commit them to the repository. Then I enter the command to run the ansible playbook, and it all happens in the same window, and I don\u0026rsquo;t have to lift my fingers from the keyboard.\nKeyboard Shortcuts Now that I am gaining more experience with vim, I\u0026rsquo;m picking up more advanced usages that significantly improve my workflow. For example, \u0026ldquo;da(\u0026rdquo; meaning \u0026ldquo;delete around parentheses\u0026rdquo; to quickly delete the text between two parentheses. Or \u0026ldquo;da\u0026lt;\u0026rdquo; to very quickly delete HTML tags. Another great feature is the visual block mode, where I can add comment tags to many lines simultaneously, for example.\nSearching and Navigation Navigating large text files has become incredibly quick since I started using vim. Of course, it takes some getting used to, but it is a lovely experience to open a file, press / to search and enter the keyword and immediately arrive at the point I need to be—no scrolling with the mouse and no need to lift my hands from the keyboard.\nI also love the ability to jump from sentence to sentence using ) or paragraphs using }.\nMultiple Files It takes a little while to get used to, but when you get into it, it is effortless to open up two files at a time if you need information from both. Often I need data from 4 or more files, and opening them quickly with keyboard commands has significantly improved my workflow speed.\nCustomization One of the things I enjoy most about vim is the ability to customize it exactly to my needs. I\u0026rsquo;m completely in charge of the plugins which are loaded into vim and which colors it uses, and this appeals a lot to me. However, it can be rather overwhelming in the beginning. To be honest, it is still overwhelming after ten months. It can be tough to get an idea of where to start, which plugins you need, and which settings you need to change.\nI just started with the base install of vim and started from there. Every time I required a particular functionality, I searched around to see if a plugin was available. Very often, someone out there had the same problem as you and created a plugin for it. For example, I recently installed a plugin for using emojis in vim 😄\nHow to Get Started The short answer is to simply start using vim for all of your text editing, whether it be coding or writing for pleasure. It is a cliche to say, but it will be hard in the beginning, but I promise you it will pay off in the end.\nThe second thing I\u0026rsquo;d recommend is to run vimtutor on a Linux machine. Do this once a day for a couple of weeks, and you\u0026rsquo;ll know how to edit text files on any Linux system for the rest of your life, which is a precious skill.\nFinally, don\u0026rsquo;t spend too much time reading about all the available plugins. Your needs will become apparent to you as you start to use vim for all of your tasks, and you can search for plugins to address those needs. This way, you start with a minimal editor, which you\u0026rsquo;ll build according to your needs.\nGood Luck! ","permalink":"https://mischavandenburg.com/zet/articles/how-started-vim/","summary":"If you are just starting your Linux journey, you might have noticed that a few camps exist in the Linux world. Just like in any other area of life, it seems that groups of human beings enjoy dividing themselves instead of living in harmony. There are camps centered around Linux distributions (I use Arch, btw) but also around text editors.\nThe Beginning The reason why I started to use vim is rather practical.","title":"How and Why I Started Using Vim"},{"content":" When I started my DevOps traineeship, I borrowed this book from my boss and read it from cover to cover. I loved the story and the characters; it helped me understand \u0026ldquo;the old way\u0026rdquo; of doing things and the merits of implementing DevOps principles.\nI reread the book ten months later. In the meantime, I\u0026rsquo;ve learned many new skills and technologies and started working full-time as a DevOps engineer.\nNot surprisingly, it made a lot more sense to me this time, and I\u0026rsquo;m sure it will be even better when I reread it a few years later. In this article, I\u0026rsquo;ll share my thoughts and notes on the book.\nThe Story The main character is Bill Palmer, a mid-level IT manager in a manufacturing company called Parts Unlimited. Within a few pages, he is called into the CEO\u0026rsquo;s office, and he is promoted to the VP of Operations, putting him in charge of IT, much against his own will or desire.\nThe situation Bill enters is a humorously chaotic one. We are thrown straight into a Sev 1 incident where managers point fingers and shout at each other. We quickly get the impression that this is a dysfunctional department that only performs tasks for the manager who shouts the loudest while fighting off crippling outages.\nIt’s like the Wild West out here. We’re mostly shooting from the hip.”\nThe Phoenix Project\nThe bulk of the story revolves around how Bill, together with his team of managers, Wes, Patty, and John, manage to turn this chaos into a department that does work according to a streamlined plan in a much more predictable manner.\nTo achieve this goal, Bill is introduced to Erik, a prospective board member of the company. Erik becomes Bill\u0026rsquo;s mentor and guides Bill through the process of creating order in the chaos. Their interaction reminds me of Zen masters training their disciples by asking deep questions which don\u0026rsquo;t have an immediately apparent answer.\nMaster \u0026amp; Disciple Erik takes Bill to the manufacturing plant of Parts Unlimited and tries to impress upon Bill that manufacturing planning principles from Lean can be applied to IT work. Erik argues that an IT department could be structured like a factory production line, but Bill is not ready to accept this.\nA fundamental notion from manufacturing principles is that work should always be moving forwards along the production line, never backward. But unfortunately, this is very often the case in the \u0026ldquo;old\u0026rdquo; way of working: the development team works on an application for several months, and when they are finished with it, they throw it over the fence to the Operations people, whose job it is to deploy the application.\nOne of the developers had actually walked in a couple of minutes ago and said, “Look, it’s running on my laptop. How hard can it be?”\nThe Phoenix Project\nHowever, as we see happening time after time in the book, usually the application is incompatible with the infrastructure it is deployed to. As a result, the application needs to go back to development. According to manufacturing theory, this is a situation where work goes backward through the production line, which we must avoid at all costs.\nImplementation Erik challenges Bill to start doing ten deployments a day instead of one deployment every nine months. Understandably, this is a ridiculous notion to Bill. The last few deployments were disastrous events that required his entire department to pull all-nighters through the weekend, and still, the stores were not managing to process all orders and payments.\nHowever, Bill takes his mentor\u0026rsquo;s advice and figures out a way to do it together with his team. One of the main problems they uncovered was the inconsistent deployment and production environments.\nThe solution to this problem was to involve the operations people in the development stage right from the beginning, so the development environment matched the production environment exactly. The environments were standardized and put in code with version control, and things started progressing quickly.\nAs Wes talks, I think about Erik challenging me to think like a plant manager as opposed to a work center supervisor. I suddenly realize that he probably meant that I needed to span the departmental boundaries of Development and IT Operations. The Phoenix Project\nThis is just one of the problems addressed by melting away the fence between Development and Operations. By the end of the book, the two camps started to work together much better. They come closer to the target of 10 deployments a day, and the DevOps way of working was born.\nClosing Thoughts I think this book is a must-read for anyone considering entering the DevOps field or anyone already working with DevOps.\nAs a nerd who loves structure and organization, the theme of the story is incredibly entertaining and satisfying to me. The authors excellently capture the transition from an utterly disorganized situation to a predictable environment with happy co-workers. Actually, I\u0026rsquo;m a little embarrassed by how much joy this transition brings me.\nEspecially the second time around, it helped me better understand the underlying principles that enable the DevOps way of working in an organization. Moreover, it paints a great picture of how an organization can change for the better by embracing DevOps principles and how these changes express themselves in the improved quality and speed of software development and deployment. All of these advantages lead to delivering better value to the customer, which is the core focus of any productive and creative endeavor involving customers and end users.\nThe Phoenix Project, written by Gene Kim, Kevin Behr, George Spafford ","permalink":"https://mischavandenburg.com/zet/articles/phoenix-project/","summary":"When I started my DevOps traineeship, I borrowed this book from my boss and read it from cover to cover. I loved the story and the characters; it helped me understand \u0026ldquo;the old way\u0026rdquo; of doing things and the merits of implementing DevOps principles.\nI reread the book ten months later. In the meantime, I\u0026rsquo;ve learned many new skills and technologies and started working full-time as a DevOps engineer.","title":"Book Notes: The Phoenix Project"},{"content":"I recently obtained my CKA certification. I started this certification journey with zero knowledge of Kubernetes. However, I was already working as a DevOps Engineer, and I know a fair bit of Linux. I daily drive Arch Linux and have LPIC-1 certification. It was handy to know where files are located on Linux systems and how to interact with systemd services. I also knew yaml quite well because I work with Ansible daily. I passed on my first try, and I did one session of killer.sh.\nMy preparation KodeKloud CKA Course Killer.sh Mock Exam Killercoda I kept track of the time I spent on this certification. In total, I spent 80 hours on study and practice.\nIn Hindsight I spent too much time repeating things during the KodeKloud course. This is the one thing I would do differently if I could start over. I went over some modules multiple times and kept meticulous notes. However, I have hardly used any of those notes. But they will be nice to have for the future.\nI learned most from the killer.sh exams. So I would advise you to go through the KodeKloud course and do all the exercises, but don\u0026rsquo;t spend too much time repeating stuff. If you don\u0026rsquo;t understand the topic at all, it is, of course, necessary to repeat it. But you don\u0026rsquo;t need to know all the details.\nKiller.sh After I finished the KodeKloud course, I purchased the exam voucher and started the killer.sh on Saturday morning. I wanted to simulate the exam experience as much as possible, so I set the timer and did not allow myself to stand up for two hours. My first round was humiliating. I only managed to get 24 out of 125 points. A little shocked by the experience, I spent the whole Saturday going through all the solutions of the exercises that killer.sh provides. The explanations they give are extensive, and I found them helpful. Saturday evening, I went out for dinner with friends, and on Sunday morning, I passed killer.sh. I spent the whole Sunday studying the solutions more and more, and on my last try on Sunday evening, I scored 115 out of 125.\nTips: I know tmux quite well and used it extensively during the killer.sh, but it was not necessary during the exam. No need to learn it if you don\u0026rsquo;t know it already.\nKnowing vim well will save you a lot of time at the exam. For example, dG to delete all lines until the end of the file from your current location. Run \u0026ldquo;vimtutor\u0026rdquo; on a Linux system to learn the basics.\nYou cannot use bookmarks. Learn how to search the docs efficiently. One handy one I figured out was to control + F and enter \u0026ldquo;kind: Pod\u0026rdquo; or \u0026ldquo;kind: PersistentVolume\u0026rdquo; to immediately go to the example YAML.\nmy exam environment did not need much extra configuration. All I added to my .bashrc was alias v=vim and export do=\u0026quot;\u0026ndash;dry-run=client -o yaml\u0026quot; so you can use \u0026ldquo;k run Nginx $do \u0026gt; Nginx.YAML\u0026rdquo;\nThe exam environment is not as bad as people make it out to be on the internet. There is a little delay while scrolling through the docs in the browser, but working in the terminal didn\u0026rsquo;t give me any problems. Get used to the environment on killer.sh, and there should not be any surprises in the real exam environment.\nSkip questions you cannot solve immediately. But don\u0026rsquo;t spend time reviewing all the questions, sorting by the highest % and doing those first. You will lose a lot of time evaluating all of these questions. It is much better to solve the questions during your first pass through and skip the ones you cannot immediately solve.\nWhen the 120-minute timer ran out, I was presented with a screen that said \u0026ldquo;quit\u0026rdquo; or \u0026ldquo;request more time.\u0026rdquo; I was pretty sure I could not get more time for this exam, so I just pressed \u0026ldquo;quit.\u0026rdquo; After I pressed quit, the application closed immediately, and there was no confirmation whatsoever that they received my exam results or anything. This was extremely disorienting, and I was left doubting if I had done it correctly. Eventually, I could see in the Linux Foundation portal that my exam was in Grading status.\nSpeed is of the essence. An hour before my exam, I used killercoda to get into the mood and get things up to speed. Learn to solve things quickly and don\u0026rsquo;t spend time having to arrange terminal windows on your screen or stumbling around in vim. You cannot afford to lose time on these things.\nFinally, this video is an excellent summary of all the necessary tips and information: ","permalink":"https://mischavandenburg.com/zet/articles/cka-tips/","summary":"I recently obtained my CKA certification. I started this certification journey with zero knowledge of Kubernetes. However, I was already working as a DevOps Engineer, and I know a fair bit of Linux. I daily drive Arch Linux and have LPIC-1 certification. It was handy to know where files are located on Linux systems and how to interact with systemd services. I also knew yaml quite well because I work with Ansible daily.","title":"Certified Kubernetes Administrator (CKA) Exam Tips"},{"content":"NOTE: In this article, I use a rather broad definition of “Operating System.” I do not intend to appear as if I wrote and compiled my own Linux kernel, nor do I understand the inner workings of the kernel written in C. Instead, with “building my OS from scratch,” I intend to convey that I used a minimal Linux distribution as a starting point and started building from there.\nintroduction I started using GNU/Linux as a daily driver about six months ago, and I have not regretted the decision ever since. There has not been a single use case where I needed to use Windows for anything at all.\nAs I was getting more used to daily driving Linux, I noticed how much I enjoyed the ability to customize my operating system and workflow. Finally, after spending a weekend going down the customization rabbit hole, I had a good-looking terminal and customized neovim to perform as I needed it.\nNot much later, I came across Arch Linux and the idea of building your own operating system from the ground up. I was instantly intrigued and knew I wanted to do the same. A few months have passed since I first came across Arch Linux, and now I am writing this blog post in neovim on my custom OS that I created from scratch. The font, the spacing, the colors, everything is exactly how I like it, and I love using it.\nWhen you first install Arch Linux, all you get is a black screen with a blinking cursor. However, the experience of creating a fully functional graphical environment from “nothing” has been extremely satisfying, and I learned so much about GNU/Linux in the process. I also realized that this could be seen as a creative activity, like a painter creating his masterpiece from a blank canvas or a sculptor carefully chipping away at a block of marble.\nnot just graphics When I say customization, I am not just referring to the visual aspects of the operating system. The things going on “under the hood” must also be carefully configured when you use a minimal distro such as Arch Linux.\nArch Linux comes with very few packages preinstalled, and every time you wish to add something to your system, you need to install it and enable the service in systemd. For example, after I did the installation and created my user account, I needed to run a command with root privileges. To my great surprise, even the “sudo” command was unavailable and needed to be installed.\nThis is the aspect I learned most from. Whenever I desired a certain functionality from my operating system, I needed to install and enable it. This has given me a much better understanding of the processes and daemons running on my system. It has also given me a greater appreciation of all the elements needed to provide a working environment.\ngraphic violence When you create an Arch Linux installation USB and boot it up, you are greeted with a command line and nothing else.\nWhen you install something more beginner-friendly, such as Ubuntu or Manjaro KDE, your installation will include a graphical desktop environment. But on Arch Linux, you must install and configure this yourself. Furthermore, to be able to render a graphical environment, you will also need to install and configure a display server such as Xorg.\nWhen I started on my journey, I intended to create something that used minimal resources with a minimal look. Having used GNOME on Manjaro for a few months, I was very satisfied, but I wanted to try a tiling window manager to shave down even more resource usage. After some research, I ended up with the Awesome Window Manager. Here are some screenshots of the final result:\nThis is what my desktop looks like when I boot up.\nHere I’m editing my window manager configuration file, while I have a browser open and keep an eye on my system resources\nmy music listening setup, using mpd + ncmpcpp, cava and sptlrx. the lyrics are shown in real time as the music is played.\ncreativity The Cambridge Dictionary defines creativity as “the ability to produce original and unusual ideas, or to make something new or imaginative.”\nWhen you embark on a journey, such as creating your operating system, you will probably start with a particular intention or a goal that you will work towards. With this goal in mind, you can start searching for the tools and color schemes you need to create the system that you have in mind. The result is a unique combination of tools, colors, fonts, and programs specifically tailored to your needs and wants and chosen by you.\nIs this any different from a painter starting with a blank canvas or a musician starting with a fragment of a melody, ending up with a complete symphony? Entering commands into a computer terminal might not strike everybody as a creative activity. Still, I have found that it is a very effective and satisfying way of expressing myself and creating something I love to use daily. As an IT professional, I spend most of my time behind my computer. Doesn’t it make sense to put effort into building something customized to your needs?\nresources If you want to start building your own OS, I recommend these resources:\nArch Linux\nArch Wiki\nr/unixporn – a subreddit about customization\n","permalink":"https://mischavandenburg.com/zet/articles/linux-creativity/","summary":"NOTE: In this article, I use a rather broad definition of “Operating System.” I do not intend to appear as if I wrote and compiled my own Linux kernel, nor do I understand the inner workings of the kernel written in C. Instead, with “building my OS from scratch,” I intend to convey that I used a minimal Linux distribution as a starting point and started building from there.\nintroduction I started using GNU/Linux as a daily driver about six months ago, and I have not regretted the decision ever since.","title":"Building my Own OS: Linux as a Creative Activity"},{"content":"Last week I upgraded Jenkins to the latest version on the server infrastructure at work. Starting with the Jenkins 2.357 release, Java 11 or Java 17 will be required to run Jenkins. Also, the upcoming LTS release will require Java 11.\nThis means that I also needed to update Java on our Jenkins servers. Here are the steps that I did to perform the Jenkins and Java upgrade.\nSSH into the server and stop the service. Then get the latest upgrades for your server, which is good practice:\nservice jenkins stop apt-get update apt-get upgrade Depending on your setup, the apt-get upgrade command might upgrade Jenkins to the latest version that does not require Java 11+. In my case, that was 3.346.\nWhen you get a question about updating your current config file, take the default option. This option keeps your current configuration.\nHowever, if your Jenkins is installed from a binary or another source, you might need to upgrade Jenkins to 3.346 using the Jenkins.war file:\ncd /usr/share/jenkins mv jenkins.war jenkins.war.old wget https://updates.jenkins-ci.org/latest/jenkins.war service jenkins start When you start Jenkins, it will be updated to the latest version that does not require Java 11 or higher. You will notice that there will be a new folder called migrate in /usr/share/jenkins , and the jenkins.war is now located in /usr/share/java\nThis is where I got confused because it did not patch to the latest version, only up to 3.346 and the jenkins.war file was no longer being updated from the /usr/share/jenkins folder.\nThe reason is that this update moves the .war file to the /usr/share/java directory.\njava To get Jenkins to the latest version, we need to install or update Java and check if it has worked:\napt-get install default-jre java -version Now that you have updated the java version, you are ready to update Jenkins to the latest version.\nNotice that we use the /usr/share/java folder now, instead of /usr/share/jenkins\nservice jenkins stop cd /usr/share/java mv jenkins.war jenkins.war.old wget https://updates.jenkins-ci.org/latest/jenkins.war service jenkins start nodes When I accessed the Jenkins GUI, everything seemed fine, and my version was up to 3.358.\nHowever, I noticed that the build nodes were all offline. When inspecting the logs, I saw the following error:\njava.io.EOFException at java.base/java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2905) at java.base/java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:3400) at java.base/java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:936) at java.base/java.io.ObjectInputStream.\u0026lt;init\u0026gt;(ObjectInputStream.java:379) at hudson.remoting.ObjectInputStreamEx.\u0026lt;init\u0026gt;(ObjectInputStreamEx.java:49) at hudson.remoting.Command.readFrom(Command.java:142) at hudson.remoting.Command.readFrom(Command.java:128) at hudson.remoting.AbstractSynchronousByteArrayCommandTransport.read(AbstractSynchronousByteArrayCommandTransport.java:35) at hudson.remoting.SynchronousCommandTransport$ReaderThread.run(SynchronousCommandTransport.java:61) Caused: java.io.IOException: Unexpected termination of the channel at hudson.remoting.SynchronousCommandTransport$ReaderThread.run(SynchronousCommandTransport.java:75) Observing that the error had something to do with Java, I ssh’d into the build nodes and updated Java there as well with the same command:\napt-get install default-jre After updating Java on the build node, head back to the GUI on the master node and restart the build node.\nIt should now be online again.\n","permalink":"https://mischavandenburg.com/how-to-upgrade-java-and-jenkins-on-ubuntu-18-04/","summary":"Last week I upgraded Jenkins to the latest version on the server infrastructure at work. Starting with the Jenkins 2.357 release, Java 11 or Java 17 will be required to run Jenkins. Also, the upcoming LTS release will require Java 11.\nThis means that I also needed to update Java on our Jenkins servers. Here are the steps that I did to perform the Jenkins and Java upgrade.\nSSH into the server and stop the service.","title":"How to Upgrade Java and Jenkins on Ubuntu 18.04"},{"content":"In this post, I’d like to share the five main reasons why I changed my career to IT in my thirties. Making a career change can be daunting, especially when you are past your twenties, and employers can get more skeptical of hiring and training you. However, when I passed my twenties and became more serious and intentional about my life and career, I decided to take the plunge and hope for the best. These are listed in no particular order.\n#1 job opportunities IT has always been a field with many job opportunities, and with the current movements of digitalization and automation, there is no sign that it will slow down.\nAccording to the U.S. Bureau of Labor Statistics, “Employment in computer and information technology occupations is projected to grow 13 percent from 2020 to 2030, faster than the average for all occupations. These occupations are projected to add about 667,600 new jobs. Demand for these workers will stem from greater emphasis on cloud computing, the collection and storage of big data, and information security.”\nThe situation is no different here in the Netherlands. Currently, there is a shortage of people in IT, and employers are much more willing to provide training to motivated individuals to make a change.\n#2 remote work I think remote work is one of the best parts of living in post-pandemic 2022. I am an introvert, and having a quiet, stable space without distractions, which is the same from day to day, is a huge boost to my productivity.\nSecondly, I think it is crucial to be mindful of your posture and body while working at a desk. For example, I am dependent on having a standing desk which I adjust more than ten times a day. I also need a chair suitable for my body type to avoid getting stiff and getting a sore back. Although some offices take care of providing these facilities to their employees, I think it is beneficial to invest in your own setup, which you can tailor to your own needs.\nThirdly, working from anywhere in the world is a massive advantage. I am not very interested in living a digital nomad lifestyle, working from a MacBook in coffee shops, but I think it’s great that you can spend some time abroad while working from that location.\n#3 personal interest This is a big one. You should not change your career to IT just because it earns well or because you think you can work from the beach in Thailand. I have been tinkering with computers and programming languages since I was a kid and have always enjoyed it. I always found myself “the computer guy” in groups of friends or colleagues.\nHowever, for some reason, I never managed to make my career out of it until now, and I get a lot of satisfaction from my work every day after I made the change.\n#4 high income It is no secret that tech jobs are some of the best paying jobs in the U.S., having a mean wage of $99,860. And if you work your way up into management, there are even higher salaries. Here in the Netherlands, it is also a financially sound choice, with a mean wage of €47.200\n#5 fast-changing field IT is a broad field with many little niches you can get into, and every niche is constantly developing. Being in IT means you will need to stay on board by continuing to learn the new technologies and languages to keep on track.\nThis is also what makes it exciting to me, being a life-long learner. There is always more to learn and some cutting-edge technology to become familiar with, which can improve your workflow and your deployments.\nlinks: Computer and Information Technology Occupations – US Bureau of Labor Statistics\nMay 2021 National Occupational Employment and Wage Estimates\nSalaries in IT - Dutch\n","permalink":"https://mischavandenburg.com/5-reasons-why-i-changed-my-career-to-it-in-my-thirties/","summary":"In this post, I’d like to share the five main reasons why I changed my career to IT in my thirties. Making a career change can be daunting, especially when you are past your twenties, and employers can get more skeptical of hiring and training you. However, when I passed my twenties and became more serious and intentional about my life and career, I decided to take the plunge and hope for the best.","title":"5 Reasons Why I Changed my Career to IT in my Thirties"},{"content":"I have installed my OS on a 240GB SSD, and I prefer to keep my data on a different disk to leave enough space to work with. I wanted to move my steam game files to a separate hard drive on Linux. I’ll show you what I did to make this happen in this article. I use Manjaro GNOME.\nFirst, you need a correctly partitioned hard drive.\nTo wipe your drive clean and have a single partition on it, we’ll use GParted.\nSelect your disk in the upper right corner.\nThen go to Device and select Create Partition Table:\nFollow the wizard and use an ext4 filesystem. NTFS can cause problems because Steam cannot read it properly.\nmounting To use a disk or a partition in Linux, it needs to be mounted.\nList your devices and identify the one you wish to mount by using the “lsblk” command.\nIn my case, I wish to mount the drive sdc1\nOn Linux, all filesystems need to be mounted before they can be used. I wanted my whole disk to be available in the directory /mnt/data\nBefore mounting, I created the directory.\ncd /mnt\nsudo mkdir data\nWhen you make the directory by using sudo, the directory owner will be the root user. This means that you cannot access the directory and write to it from your own user.\nUse this command to change the ownership of the directory. Replace “mischa” with your username.\nsudo chmod mischa:mischa data\nVerify that the directory now has the correct ownership:\nNow you can mount your directory, so it is available for use.\nmount /dev/sdc1 /mnt/data\nmounting on boot For the mount to happen automatically on startup, you’ll need to add it to the /etc/fstab file. We start by finding the UUID of our disk.\nUse the following command:\nls -al /dev/disk/by-uuid/\nIn my case the UUID will be 50d608bc-a7ad-4ff6-bf44-bb6f26efa4f6\n/etc/fstab open the file in your favorite editor. I like to use vim.\nsudo vim /etc/fstab\nAdd a new entry to your /etc/fstab file and use the following parameters:\nUUID=50d608bc-a7ad-4ff6-bf44-bb6f26efa4f6 /mnt/data ext4 defaults 0 0\nBefore we go further, verify that we did this correctly by using the following command:\nfindmnt --verify\nThis will verify the /etc/fstab file. Not meaning to scare you, but an incorrectly configured fstab may lead to an unbootable system.\nNow reboot your system and check if your disk is mounted automatically.\nIt is also a good idea to cd to your mounted directory and touch a file to see if you have write permissions.\nSteam Now it’s time to set things up in Steam. Open Steam and open your settings.\ngo to Downloads –\u0026gt; Steam Library Folders\nClick the + button and navigate to your mounted drive.\nTo test, install a game and reboot your system.\n","permalink":"https://mischavandenburg.com/how-to-move-your-steam-game-files-to-a-separate-hard-drive-on-linux/","summary":"I have installed my OS on a 240GB SSD, and I prefer to keep my data on a different disk to leave enough space to work with. I wanted to move my steam game files to a separate hard drive on Linux. I’ll show you what I did to make this happen in this article. I use Manjaro GNOME.\nFirst, you need a correctly partitioned hard drive.\nTo wipe your drive clean and have a single partition on it, we’ll use GParted.","title":"How To Move Steam Game Files To a Separate Hard Drive on Linux"},{"content":"After getting my LPIC-1 certification, my interest in Linux continued to grow. When I started my new job, I performed more sysadmin tasks, such as increasing the size of filesystems or removing backups, and it felt good to put the theory into practice.\nI was still using Windows in my personal setup, and I started running into limitations. Finally, I realized how much I appreciated the freedom and control over my system that Linux gave me. So I decided I wanted to switch to Linux for my daily operating system. But a few things were holding me back. Will I be able to play my favorite games? Will I run into a lot of problems with my sound and microphone? Are all the apps I need for working from home available on Linux? Can I even edit videos on Linux?\npreparing to switch I made a dual boot install of Ubuntu to try things out to answer these questions. I started things off by setting small goals for myself. For example, I need to be able to work from home. Which programs do I need? And I started from there.\nI had no problems installing Slack, Zoom, Teams, and all the other programs I needed for my work. I was very surprised by how well all of the external hardware worked. My Bluetooth keyboard and mouse worked immediately without needing to install any drivers. Even my USB webcam worked instantly without any problems.\nTo put this into perspective, I spent an entire afternoon getting my keyboard to work correctly on my MacBook. It needed a lot of extra drivers. Still, there is a 4-second delay when I press my volume up/down keys when working on my MacBook. All of this works perfectly on my Linux OS without any delays and without any drivers or extra configuration.\nI kept my dual boot setup for a while as I was trying out different distros, and I eventually ended up with Manjaro as my distro of choice. I like it because it is based on Arch Linux, and it gives you access to the Arch User Repository (AUR). I want to use Arch eventually, and I figured this might be a good stepping stone.\nfate decided for me This dual boot setup continued for a while as I was warming up to the idea of completely abandoning Windows. I set Linux as my default boot option, and after a few weeks, I realized I hadn’t needed to boot into Windows for anything at all. However, I still didn’t feel quite ready to switch completely to Linux.\nOne evening I wanted to make another fresh install to check out the GNOME version of Manjaro. I was doing a lot of chores at the same time, and it was getting quite late, but I wanted to have the installer running as I was doing other tasks. Probably not my most brilliant move.\nYou probably know what is coming: in between my chores, I started the installation. In a moment of carelessness, I managed to point the installation to my Windows partition, and it was completely wiped and replaced with a sparkling fresh Linux install.\n“Well, I guess I am moving to Linux today!” I thought while I suppressed a hint of panic as I racked my brain to see if I had lost any important files. I knew that most of my important stuff was safely backed up in the cloud. But if I had formatted my Windows drive by choice, rather than by accident, I would have backed up a lot more files.\nfirst week without windows A week ago, I lost my complete Windows install, but there hasn’t been a single moment where I regretted making the switch. Fortunately, it also seems that I did not lose anything important.\nI am learning so much by forcing myself to use Linux as a daily driver. Most things are correctly configured out of the box. But sometimes, you have to do some work to get the configuration you like.\nFor instance, after installing Steam, I wanted to have the game files located on a different hard disk because my OS SSD is only 256GB. This required me to format my data SSD to an ext4 filesystem and mount it in a folder. I also needed to add it to my /etc/fstab file to make sure that it mounts automatically when I boot my PC.\nThese tasks have been great practice for the things I need to do on my servers at work, and they will make me approach these tasks with a little more confidence because I have done them before on my personal setup. This is the great advantage of having Linux as a daily driver if you are becoming a DevOps Engineer or Linux System Administrator.\n","permalink":"https://mischavandenburg.com/goodbye-windows-hello-linux-switching-to-linux-as-my-daily-driver/","summary":"After getting my LPIC-1 certification, my interest in Linux continued to grow. When I started my new job, I performed more sysadmin tasks, such as increasing the size of filesystems or removing backups, and it felt good to put the theory into practice.\nI was still using Windows in my personal setup, and I started running into limitations. Finally, I realized how much I appreciated the freedom and control over my system that Linux gave me.","title":"Goodbye Windows, Hello Linux! Switching to Linux as my Daily Driver"},{"content":"This week I learned about yadm: yet another dotfile manager. It is the perfect way to keep track of all your custom configuration files, known as dotfiles.\nEven if you have only a little bit of experience with Linux, you know that everything is managed in files. All configuration parameters are set or changed in text files stored on the hard disk. These files are usually located in your home directory and are hidden by default. This is indicated by prefixing the file with a period. So the configuration file for the vim editor is .vimrc, and for zshell you use the .zshrc. This is why configuration files are referred to as dotfiles.\ncustomisation The more I work with Linux, the more I appreciate the ability to customize things. When I first started, I was pretty satisfied with the vanilla experience. You punch your commands into the terminal, and you do your tasks. What more could you need?\nThis started to change when I began working with senior engineers who built their custom setups over the years. I saw them opening 3 terminal windows in a perfect ratio with beautiful colorschemes or previewing files in a file browser directly in vim so they could split them vertically and edit them side by side.\nI wanted to create a similar setup by adding settings and plugins to the .vimrc and .zshrc files. However, before going down this rabbit hole, I asked myself the following question. How can I bring this configuration with me to other machines? What happens if my laptop gets stolen and I lose my precious configuration files?\nyet another dotfile manager Enter yadm. I had thought of putting my dotfiles in a GitHub repo, but this brings up a whole set of new challenges where you would need to create symbolic links across your system to have the files in their correct places. Yadm solves this problem.\nYadm turns your home directory ( ~/ ) into a Git repo which can be pushed to a host of your choice. You can add your files one by one, and yadm will track them. The best thing is that you can add the files from all over your system, and yadm will not bother with any of the other files in your home directory.\nyou want git for your dotfiles Setting up your configuration files in a git repository has a lot of advantages:\nconfiguration is saved in multiple places easily share your configuration across machines version control Version control is especially useful. You will always be able to trace back that one plugin you used a few years ago, but you cannot remember the name of. And it is fun to watch your configuration grow over time.\nsetting up yadm Installing yadm is a breeze. For my mac I just used\nbrew install yadm or you can use the apt-get or dnf install equivalents if you are on Linux.\nYou interact with yadm the same way you interact with git. You simply replace the word git with yadm in the commands.\nThen you navigate to your home directory and set up the repository. If you don’t have a repository yet:\nyadm init yadm add \u0026lt;important file\u0026gt; yadm commit yadm remote add origin \u0026lt;url\u0026gt; yadm push -u origin \u0026lt;local branch\u0026gt;:\u0026lt;remote branch\u0026gt; Or if you already have a dotfiles repository:\nyadm clone \u0026lt;url\u0026gt; yadm status And that’s it. Now add your configuration files and push them to your hosted repo:\nyadm add ~/.vimrc yadm add ~/.zshrc yadm commit -m \u0026#34;first commit\u0026#34; yadm push You will notice that yadm expects you to add all the files every time you want to make a new commit. Use this command to stage all the files you added previously:\nyadm add -u enjoy your synched customisation Having your dotfiles in a GitHub repo makes it easy to set up your preferred settings on a new machine or environment. So install yadm and pull your repo, and off you go!\nI hope you will enjoy it as much as I do. Crafting a customized setup takes a lot of time and effort, and now that I finally have an excellent solution to keep track of my files, I am ready to dive into the customization rabbit hole.\nDownload yadm here. Here you will also find all the necessary information to install and configure your yadm.\n","permalink":"https://mischavandenburg.com/yadm-keep-track-of-your-precious-dotfiles/","summary":"This week I learned about yadm: yet another dotfile manager. It is the perfect way to keep track of all your custom configuration files, known as dotfiles.\nEven if you have only a little bit of experience with Linux, you know that everything is managed in files. All configuration parameters are set or changed in text files stored on the hard disk. These files are usually located in your home directory and are hidden by default.","title":"Yadm: Keep Track of Your Precious Dotfiles"},{"content":"I recently obtained my LPIC-1 certification, and in this blog post, I’ll share the strategy and techniques I used to pass this exam and share my thoughts on the certification. Because I am a Linux novice, the exam was a pretty tough grind for me. This article offers a beginner’s perspective on the LPIC-1 certification. Is the LPIC-1 hard to pass? Keep reading to find out.\nBefore this certification, I had only a little bit of experience. I deployed LAMP stacks using Ansible and configured VMs to be able to communicate with each other using only the command line. I also did a “Linux Fundamentals” video training. I could navigate the filesystem, edit text files and work in the terminal, but that was about it.\nIs it hard? For a beginner: yes, it was hard! But if you are a Linux administrator with a few years of experience, these exams probably are not very difficult to pass. However, even if you are experienced, be prepared to do a lot of memorization. Even though the requirements on the website seem very basic and straightforward, when you dig into the study resources, you will soon discover that you need to learn a large host of commands and many of their accompanying parameters. For example, you will need to know what grep -H does precisely, the difference between passwd -l, chage -l, and chage -L, the location of the directory that contains all the timezones, and the directory that contains the printer configurations for CUPS.\nThe certification The LPIC-1 certificate requires candidates to pass the LPI 101-500 and 102-500 exams. These exams test the candidates on various subjects, such as file management, boot loaders, networking fundamentals, user and group management, file systems and partitioning, and much more.\nEach exam has a 600-page syllabus, so to get your LPIC-1 certification, you need to work through 1200 pages and memorize a few hundred commands and parameters. However, if you work as a Linux sysadmin, you’ll probably know many of these commands and concepts.\nStudy Materials I attended a 4-day course that covered both exams. However, because of the large amount of information that needs to be covered, the teacher could only address the subjects on a superficial level. Therefore, I would advise you to be suspicious of any courses that promise to prep you for the exams in 4 days if you are a beginner. I estimate that you need at least double that amount to get some proper explanation of the material.\nLPI Syllabus After finishing the course, it became clear that I needed a lot of studying to pass the exams. Fortunately, LPI has created a syllabus for each exam. These are available for free on the LPI.org website.\nLPI Practice Exams It is crucial to test your knowledge. This is the resource I used:\nLPIC-1 Linux Professional Institute Certification Practice Tests: Exam 101-500 and Exam 102-500 If you are a member of O’Reilly’s, you can read the book there. It contains around 90 practice questions for every chapter in the LPI syllabus. The questions test your knowledge in detail and are a great way to determine whether you have fully grasped the material.\nHowever, the book was written in 2019 and contains questions about certain subjects that have since been removed from the exams. So if you suddenly encounter questions that do not seem familiar at all, make sure to double-check that it is actually an exam objective.\nLastly, I used these practice exams on Udemy.\nMemorization As I have stated before, the exams require you to do a lot of memorization. Fortunately, we have some tools and techniques available to help us with this task.\nThe primary tool is Anki. If you are not familiar with it, Anki is a very simple and free program that allows you to create flashcards that you can use to study and test your knowledge. The best thing about Anki is that it implements spaced repetition. You can download and learn more about Anki here: https://apps.ankiweb.net\nSecondly, I am fond of memory techniques. You can remember things much more quickly by visualizing them in your mind or utilizing techniques such as Memory Palaces or the Method of Loci. If you are interested in learning more about memory techniques, I highly recommend Dr. Anthony Metivier’s YouTube channel.\nStrategy Here is the strategy that I used to pass the exams:\nRead through a chapter and take notes. Make Anki flashcards for all the commands and flags that you do not know yet Do the exercises at the end of the chapter Do the practice exam for your chapter from the exam book, which should give you a good indication of how well you have grasped the material. Make flashcards of all the questions that you answered wrong (trust me, there will be quite a few) Use Anki to test yourself and memorize all of the commands and exam questions Tips: Do your Anki reviews every day. On some days I was adding more than 100 new cards, which will lead to a lot of reviews in the coming days Although the syllabus for exam 101 explained things very well, the 102 syllabus sometimes is very meager in its explanations and you might need to supplement with reading man pages, YouTube videos, and other tutorials. For example, I needed to find quite a bit of supplementary material for chapter 109 Networking Fundamentals. Ask for help if you don’t understand a certain topic Don’t think you can get away with skipping a topic. You will be tested on absolutely everything that’s in the syllabus, trust me. Try doing it together with someone else. I was doing it together with my friend and colleague, and it was extremely useful to be able to share things I struggled with and to discuss things with him to understand them better. Thank you for the good times, Gino! My thoughts on the certification The subject matter is extensive, and I know my way around Linux much better now. Therefore, if I encounter a problem, I am better positioned to assess where the cause might be and then solve the problem from there. I also feel I have a much better grasp of basic networking concepts, which will prove to be very useful in many situations in my work as a DevOps Engineer.\nHowever, there are also a few drawbacks to this certification. I think there is too much emphasis on memorizing commands and their flags. I think it is not necessary to memorize all of the possible parameters of the chage command because, in the real world, I would take a quick look at the man page to find the parameter that I need. The exams force you to memorize many parameters in a short time, and to be honest, you will probably forget about them very quickly anyway.\nBut overall, I am pleased and grateful to my employer that I was able to obtain this certification, and it has made me hungry for more, and I am very eager to continue my learning in this domain.\n","permalink":"https://mischavandenburg.com/lpic-1-study-guide/","summary":"I recently obtained my LPIC-1 certification, and in this blog post, I’ll share the strategy and techniques I used to pass this exam and share my thoughts on the certification. Because I am a Linux novice, the exam was a pretty tough grind for me. This article offers a beginner’s perspective on the LPIC-1 certification. Is the LPIC-1 hard to pass? Keep reading to find out.\nBefore this certification, I had only a little bit of experience.","title":"LPIC-1 Study Guide"},{"content":"Two months ago I knew nothing about GitHub. This week my first pull request got merged into master!\nProgramming tutorials and books very often suggest that you should try to contribute to open source in order to practice your skills. Even though I am still on the beginner level in Python, I managed to find something I could contribute with. But there were a few things I needed to learn in order to be able to do so.\nGitHub is a place where many open source projects are hosted. Projects are hosted in “repositories” available to the public. Everyone can go in and take a look at the code. And the great thing about it is that everyone can contribute to the code as well.\nTwo months ago I knew almost nothing about GitHub. Surely, I had often downloaded software from GitHub, and I knew it had to do with version control. But I had no idea that it was such a powerful system of enabling collaboration for software projects.\nDuring an assignment in my DevOps Traineeship I spent some time learning about Github and the Git language. I learned about repositories, branches, commits and pull requests. Now I wanted to take it to the next level and make a contribution of my own somewhere.\nthe project As I have mentioned in other posts, I love game automation, and recently I discovered the Botty project, which is a bot written for the game Diablo 2: Resurrected. The bot is written in Python, which means that it is a great way of applying my Python learning to something I am passionate about.\nThe bot uses computer vision in order to recognise what is on the screen and run scripts accordingly. The monsters in the game drop items, and if you want the bot to pick up items, it will need to be taught which items it needs to pick up.\nThis is done by adding some images to its image database and adding the filenames to a list of items. When the bot scans the screen for items, it will look for a match in its image database, and when it matches, it will click the corresponding pixels on the screen to pick up the item.\nHere’s what an image in the database looks like:\nI am doing a Holy Grail project in this game, which means that I am collecting every item in the game. It is quite an undertaking as there are 506 items in the game, and some items have a drop chance of 1 : 1.000.000. Luckily I have a bot to help me with this project.\nNot surprisingly, many items were still missing from the bot because it is a fairly new project that is still in development. And as I needed my bot to pick up the items I needed, I decided to add these 46 missing items to the database.\nforks, commits and pull requests After doing the work I still needed to figure out how I should offer these items to the project. Luckily someone shared a few very helpful tutorials in the project’s discord. This is the tutorial I used for my first contribution:\nStep-by-step Guide to Contributing on Github\nYou begin with “forking” the project repository, which basically means making your own copy of all the code in the project. Then you add your contribution to the fork by cloning it to your local machine and making your changes to a new branch.\nWhen you have committed your changes and pushed your new branch to your fork, you are ready to make your first pull request. A pull request is a way of telling the project that you have something to contribute. You are sharing your version of the project repository including your proposed changes, and someone from the project will take a look at your suggestions and see if they are useful and compatible.\nmerged into master After a few days someone had a look at my contribution and requested me to make a few small adjustments. When I managed to incorporate those my contribution was accepted, and my changes were “merged into master”, which means that my contribution was brought into the main version of the project’s code.\nI learned a lot! As I am typing out this article, I am very satisfied with how much I have learned in the past few months already. I remember being very confused about all the GitHub terminology when I attended my first meetings during my DevOps traineeship.\nGoing through the process of making a contribution to open source on GitHub has been an enriching experience. It seemed quite intimidating at the start, but by following a good tutorial I managed to successfully submit my first pull request. I feel I have a much better understanding of Git, GitHub and the workflow.\nAnother valuable lesson I learned is that you don’t need to be a Senior Engineer in order to be able to contribute to open source. Although this project is written in Python, my contribution had very little to do with code, but I provided assets which were required by the code. So if you are a beginner at programming, you can look for other ways to contribute, such as fixing spelling mistakes in the documentation, providing images or writing wiki pages.\n","permalink":"https://mischavandenburg.com/my-first-contribution-to-open-source/","summary":"Two months ago I knew nothing about GitHub. This week my first pull request got merged into master!\nProgramming tutorials and books very often suggest that you should try to contribute to open source in order to practice your skills. Even though I am still on the beginner level in Python, I managed to find something I could contribute with. But there were a few things I needed to learn in order to be able to do so.","title":"My First Contribution to Open Source"},{"content":"The best part of learning Python is trying to identify things in my life which I can automate by writing a script. Learning a programming language involves doing a lot of exercises that sometimes lack a connection with the real world. But after I decided to go for it, I am always on the lookout for projects. Not only for my job as a DevOps Engineer, but also for my private life. In this case, I needed to write a program that parses log files from a bot so I could get a total number of runs. You can have a look at the final result in my Diablo 2 GitHub repo. Like I wrote in my journey into DevOps article, I love automating games. Diablo 2 is a game that was originally released in 2002 and which recently was remastered. Diablo 2 always had a very strong presence of bots in the online game, and it didn’t take long before I also joined the ride.\nA few months after the remaster the first bots have started emerging as well. There is a a particularly good one written in Python which is an open source project, which is a perfect opportunity for me to learn more about Python by trying to understand its code and solving problems. I was very excited to discover it because I was playing quite a few hours a week. Diablo 2 is a very grindy game and it takes a lot of time to find the needed gear. Now I could finally outsource my grinding to the computer again.\nthe problem Although the bot is very functional and does several tasks very well, there are still features missing because it is relatively early in its development. One of these features is keeping track of the total amount of runs that the bot has done. In Diablo, every time you play you start a “game” or an instance. In that game there are certain bosses you can kill, and when you are finished you exit your game. This is called a run. Then you create a new game and everything is reset, and you get another shot at killing the bosses to get the precious gear.\nBeing the nerd that I am, I like to keep track of the total amount of runs that the bot has done. On these numbers I like to apply some calculations to see how many items I get per xxxx runs and suchlike. The bot keeps track of the amount of runs it does per session and stores them in a log file. But there is no functionality of seeing the total amount of runs you have done, and when I discovered this, I realised I had my first little Python project.\nlog files Every time you close the bot after a session, a log file is created that looks like this:\nIt is formatted as a .txt file and shows information about the bosses that were run and the items that were found. Most importantly, it contains the amount of games that were done in the session. Even after only using the bot for a short time I had over 100 log files to go through, and that’s where I needed a script that would go through these files for me and add the numbers in order to get the total amount of runs.\nthe script After completing chapter 9 and 10 in the Automate the Boring Stuff book, I learned about file paths and opening files and reading from them. Now it was time to apply that knowledge. The process went pretty well and soon I had a script that would open the files for me.\nThings got a little bit more complicated when I needed to read information from the files. And of course, this operation would almost certainly involve the dreaded topic of regex. In the end it was not as bad, and I ended up with the following regex:\nregex_games = re.compile(r\u0026#34;Games:\u0026#34;) regex_dict = { \u0026#39;nihla\u0026#39;: \u0026#39;Nihl|Nihlatak\u0026#39;, \u0026#39;pindle\u0026#39;: \u0026#39;Pin|Pindle\u0026#39;, \u0026#39;eldritch\u0026#39;: \u0026#39;Eld\u0026#39; } As you will see afterwards, I needed a way to check every line for a certain statement. However, rather than hardcoding every operation, I wanted it to loop over a list of terms. This meant that I could easily go back to the code and add a few more search statements if I needed them. I ended up storing them in a dictionary as you can see above. I really like the way you can make dictionaries in Python and have every entry on a new line. It makes the code very readable and structured.\nAnd this is the actual looping sequence that I ended up with:\nfor folder_name, sub_folder, file_names in os.walk(source): for filename in file_names: p = PurePath(folder_name, filename) with open(p, \u0026#39;rt\u0026#39;) as my_file: # search for games number line for line in my_file: # find number of games and add to total games if regex_games.search(line): g = line.split() total_games += int(g[1]) f = my_file.read() # check which runs were done by using the regex dict for key in regex_dict: location = regex_dict[key] reg = re.compile(location) # if there is a match, add the numbers to the total variable if reg.search(f): var_name = key + \u0026#39;_total\u0026#39; globals()[var_name] += int(g[1]) This sequence loops through the folder, the subfolder, and opens each file one by one. When the file is opened it looks for the “Games: 25” line and adds the number to a variable. However, I was not only interested in the total number of games. I also wanted to get more insight in how many Pindle runs or Nihla runs I had done. So I set up another regex search and made sure that the number of games are added to a “pindle_total” or “nihla_total” variable.\nresult When running the script in the shell, the result looks like this:\nmischa@MischaMacBook stats_parser % python3 total_runs.py Total runs: 7159 Pindle runs: 6926 Eldritch + Shenk runs: 367 Nihla runs: 232 mischa@MischaMacBook stats_parser % Exactly what I wanted. Now I can just paste my stats files into a folder and see how many runs I’ve done. Maybe I’ll improve it by building a GUI. Another fun idea I have is to create a little pipeline where this script would be run once an hour and the stats would be uploaded to a webpage somewhere, so others could see the amount of runs of my bot. Not that anyone is interested in that, but it is a fun project for me to do. Let’s see what happens!\nFor now I am very happy with the result. It was a very satisfying experience to identify a problem that I had and to be able to come up with an automated solution. Of course it is still very rudimentary programming, and there is a long long way ahead of me, but it was fun to finally do something practical that solved a particular problem in my life.\nThe final result is in my Diablo 2 GitHub repo.\n","permalink":"https://mischavandenburg.com/my-first-useful-python-script/","summary":"The best part of learning Python is trying to identify things in my life which I can automate by writing a script. Learning a programming language involves doing a lot of exercises that sometimes lack a connection with the real world. But after I decided to go for it, I am always on the lookout for projects. Not only for my job as a DevOps Engineer, but also for my private life.","title":"My Mirst Useful Python Script"},{"content":"I am currently working through the book Automate the Boring Stuff by Al Sweigart . I can already highly recommend it to anybody who is learning Python.\nChapter 9 is about reading and writing files, and there are two assignments at the end of the chapter. Here I’ll discuss my solution of the Mad Libs assignment.\nhere is the full assignment text: Mad Libs Create a Mad Libs program that reads in text files and lets the user add their own text anywhere the word ADJECTIVE, NOUN, ADVERB, or VERB appears in the text file. For example, a text file may look like this: The ADJECTIVE panda walked to the NOUN and then VERB. A nearby NOUN was unaffected by these events. The program would find these occurrences and prompt the user to replace them. Enter an adjective: silly Enter a noun: chandelier Enter a verb: screamed Enter a noun: pickup truck The following text file would then be created: The silly panda walked to the chandelier and then screamed. A nearby pickup truck was unaffected by these events. The results should be printed to the screen and saved to a new text file. Looks pretty simple, right? I went into it with a lot of zeal and started writing a long list of if statements. My first attempts at the solution involved matching the words NOUN and ADJECTIVE directly, like so:\nif word == \u0026#39;ADJECTIVE\u0026#39;: inv = input(\u0026#39;Enter an adjective: \u0026#39;) However, this is problematic because as you can see, the sentence can contain words with a period attached, such as “VERB.” in the above example.\nno, please no regex! I’ve understood that here is a general anxiety around regex. I have certainly noticed it in myself and some of my junior engineer friends. As soon as I read the word regex, or realise that an assignment is going to involve regex, I get a constricting feeling in my throat and a rise in my heart rate.\nI’ve had to struggle with it quite a bit during my freeCodeCamp Front End Development Certificate, and the memories are still fresh in my mind.\nSo, like any other ‘rational’ human being, I tried to approach this relatively simple assignment with all sorts of ways trying to account for a period ending the word:\ndef period_check(x): for letter in x: if letter == \u0026#34;.\u0026#34;: return True # loop over the array and prompt user for word in source_text: period = False if period_check(word): word = word.replace(\u0026#34;.\u0026#34;, \u0026#34;\u0026#34;) period = True if word == \u0026#39;ADJECTIVE\u0026#39;: invoer = input(\u0026#39;Enter an adjective: \u0026#39;) if period: result_text.append(invoer + \u0026#34;.\u0026#34;) period = True else: result_text.append(invoer) elif word == \u0026#39;NOUN\u0026#39;: It’s quite funny to see the lengths we go through to avoid regular expressions. However, as you maybe deduce from the code above, it didn’t work, and after a couple of hours of fiddling I gave up, and like any other frustrated programmer, I started to google.\nI quickly found solutions to this assignment and they all involved regex, and I realised I could not walk away from my fears anymore.\nan elegant solution Eventually I ended up with the following result for the part of my assignment that needed to recognise and replace the words with the user input. Of course I heavily borrowed from my Google search results.\n# set up and match the regex grammar_regex = re.compile(r\u0026#39;ADJECTIVE|NOUN|VERB|ADVERB\u0026#39;) match_regex = grammar_regex.findall(source_text) # replace the matches with user input for i in match_regex: ask_user = input(\u0026#39;Please enter \u0026#39; + i + \u0026#39;: \u0026#39;) source_text = source_text.replace(i, ask_user, 1) When I say elegant, I mean elegant in total Python beginner terms. I’m sure there are enough Seniors out there who will burst out laughing when they see this. But to me, it was quite an eye-opening experience to see this little piece of code do exactly what I had intended to achieve with 3 different functions and long blocks of if statements.\nAlso, I was pleasantly surprised with how simple regex can be in Python. In this case there were no scary [Az ^**/!!${}aa{}aA{nF}] statements. We simply defined which words we wanted and called the findall() module to generate a list with all the matches.\nThen we iterate over the list of matches and for each match we ask the user for the desired word, and replace it in the source_text.\nfinal result Having sorted out the pattern matching and replacing part, it was only a matter of implementing reading from files and writing to a new file.\n# Automate the Boring Stuff chapter 9 # Mad Libs assignment # Mischa van den Burg from pathlib import Path import re # ask the user which file to open file_name = input(\u0026#39;Enter the filename. For example, grammar.txt: \u0026#39;) # my script and .txt file are located in ~/python/automatetheboringstuff/ text_file = open(Path.home() / \u0026#39;python\u0026#39; / \u0026#39;automatetheboringstuff\u0026#39; / file_name ) # read the file and store in variable \u0026amp; close source_text = text_file.read() text_file.close() # set up and match the regex grammar_regex = re.compile(r\u0026#39;ADJECTIVE|NOUN|VERB|ADVERB\u0026#39;) match_regex = grammar_regex.findall(source_text) # replace the matches with user input for i in match_regex: ask_user = input(\u0026#39;Enter \u0026#39; + i + \u0026#39;: \u0026#39;) source_text = source_text.replace(i, ask_user, 1) # write to the new file and print the result new_file = open(\u0026#39;new_\u0026#39; + file_name, \u0026#39;w\u0026#39;) new_file.write(source_text) new_file.close() print(source_text) I was getting into some better functionality, such as accounting for existing filenames, and making the pathing relative so it could be run from anywhere. But I decided to save that for a later assignment.\nThe assignment was clear and did not require such functionality. I need to learn to keep things simple, and I decided to do just what I was asked and not go into any other rabbit holes.\nLessons Learned All in all the assignment is pretty simple, but I learned surprisingly much from it. I decided I’ll need to change and learn to love regex rather than fear it, because it showed me how powerful it can be.\nAlso, I got some insight into my own mind and how I tend to work. I realised I have a tendency to make things much more complicated than they need to be. I need to learn to keep things simple.\n","permalink":"https://mischavandenburg.com/python-project-mad-libs/","summary":"I am currently working through the book Automate the Boring Stuff by Al Sweigart . I can already highly recommend it to anybody who is learning Python.\nChapter 9 is about reading and writing files, and there are two assignments at the end of the chapter. Here I’ll discuss my solution of the Mad Libs assignment.\nhere is the full assignment text: Mad Libs Create a Mad Libs program that reads in text files and lets the user add their own text anywhere the word ADJECTIVE, NOUN, ADVERB, or VERB appears in the text file.","title":"Python Project: Mad Libs"},{"content":"In order to learn more about Docker and Ansible I am working on an assignment to take an existing application and to break it down into containers. However, in order to be able to understand this process properly, I first needed to understand more about Docker and containerisation.\nI wrote a playbook that installs Docker and deploys a fully containerised LEMP stack on a virtual machine.\nYou can have a look at the Github repo with the result here. The repo is using the “ansible-galaxy init” role structure. You will find the playbooks as follows: roles/your_choice/tasks/main.yml\nDocker I was very excited to learn more about Docker and containerisation. I was familiar with the concept of virtualisation, which is creating virtual versions of fully functional machines on a host operating system. But the concept of containerisation was new to me.\nAs I understand it, containerisation differs drastically from virtualisation because containers are able to use resources from host directly. They do not need an entire operating system to run, and therefore they are a much more lightweight.\nThis means that resources can be used much more efficiently which eventually can mean cost reduction in your cloud infrastructure.\nDocker is a very popular platform for building and running containers. It seemed like the best option to get started with deploying my own containers.\nLEMP Stack My colleague recommended me this tutorial to become more familiar with Docker. It uses a LEMP stack as an example application. When I told friends about the fact that I was building a LEMP stack, they corrected me and said it was a LAMP stack.\nThe LAMP stack is a collection of software built out of these elements:\nL – Linux: the operating system\nA – Apace: webserver\nM – MySQL: database\nP – PHP: server scripting language\nHowever, in a LEMP stack, we use NGINX as a webserver, which is pronounced “Engine X”, hence the E in LEMP stack. Therefore, LEMP is the correct way to spell it, and it is used in all the tutorials that I have been using.\nI highly recommend the tutorial in order to learn how to deploy your first collection of containers. Deploying one container is relatively easy with Docker, but it gets a little more complicated when deploying several containers and making them communicate with each other in order to combine them into one application. But this tutorial does a great job at showing you how it’s done and it is especially good at explaining the steps along the way.\nDocker Compose vs. Ansible Docker Compose is a tool you can use to run multi-container applications. With the help of the tutorial, it was fairly easy to understand and hit the ground running by deploying multiple containers into one network.\nNow let’s have a look at how we actually set up the containers. In the Docker Compose file, the NGINX container was defined like this:\nversion: \u0026#39;3.8\u0026#39; #Services services: #Nginx Service nginx: image: nginx:1.19 ports: - 80:80 volumes: - ./src:/var/www/php - ./.docker/nginx/conf.d:/etc/nginx/conf.d depends_on: - php It looks pretty straightforward, right? Almost like pseudocode. We tell Docker which image to pull from the Docker Hub, and we tell it to route container’s port 80 to our host’s port 80. This ensures that the web server can be accessed from the outside, provided you have opened this port in the firewall.\nNext there is the volumes section: this mounts certain directories on the host into the container so it is accessible. In this case this was necessary to transfer the web server configuration and the index.php which we wanted to serve to the outside.\nHaving successfully deployed my LEMP using Docker Compose, the next step was to automate this process by using Ansible. Ansible is a very powerful tool which enables you to automate configuration management and application deployment by writing scripts called playbooks.\nWhy was it necessary to introduce Ansible? By using Docker Compose, you would need to have Docker and Docker Compose installed on the virtual machine before you could start running the containers.\nHowever, Ansible gives you the power to take a completely fresh virtual machine, configure it from scratch, and install Docker and its necessary dependencies, followed by deploying the containers.\nNow let’s take a look at the same container defined in Ansible: - name: start nginx docker_container: name: nginx image: nginx:1.19 detach: yes ports: - 80:80 networks: - name: network_one volumes: - /src:/var/www/php - /.docker/nginx/conf.d:/etc/nginx/conf.d Although there are some differences, they look very similar. Converting my Docker Compose file to an Ansible playbook was quite a natural and easy experience. It also helps that both are written in YAML and therefore use the same indentation conventions.\nA few differences we can observe:\nIn the Ansible playbook we invoke the docker_container module, whereas they are defined as services in the Docker Compose file. Another difference is that we need to set up the network ourselves. In the Docker Compose file, we just specified the containers and Docker Compose created a network automatically and made sure that all containers were connected to it.\nHowever, it isn’t very complicated in Ansible either:\n- name: setup network docker_network: name: network_one We simply call the docker_network module and tell it to make a network called network_one. All we need to do then is make sure to set the networks: parameter to network_one in the docker_container module as we saw above.\nThe last point to note is the detach parameter. This means that the container will keep running in the background after it is started.\nResult After some debugging here and there and making sure all of the elements were in place, eventually we get the satisfying message that everything went according to plan:\nThe result is a webpage being served on the server ip:\nI know, it is not the prettiest or most intricate design. But remember that I am working towards becoming a DevOps Engineer, not a Front End Developer 😉\nWe can also enter the phpMyAdmin dashboard by adding port 8080 to our ip in the browser:\nConclusion The assignment of deploying a LEMP stack in separate containers has been very useful and I learned a lot from the process. There were a few more modules that needed to be configured in Ansible as opposed to the Docker Compose method, but the tradeoff is that Ansible is much more powerful and enables you to configure the server from scratch. You can have a look at the code in the GitHub repo to see all of the changes I needed to do.\nThe only part that I needed to do by hand is to create the VM in the Microsoft Azure portal, open the ports and configure the SSH keys. The next step in my learning process will be to learn how I can automate this step as well. This means that I will need to learn Terraform.\nBy using Terraform I will be truly deploying this stack as Infrastructure as Code, but doing all of these steps with Ansible has given me a much better understanding of Infrastructure as Code already.\n","permalink":"https://mischavandenburg.com/docker-lemp-stack-deployed-with-ansible/","summary":"In order to learn more about Docker and Ansible I am working on an assignment to take an existing application and to break it down into containers. However, in order to be able to understand this process properly, I first needed to understand more about Docker and containerisation.\nI wrote a playbook that installs Docker and deploys a fully containerised LEMP stack on a virtual machine.\nYou can have a look at the Github repo with the result here.","title":"Docker LEMP Stack deployed with Ansible"},{"content":"I always struggled with finding an online nickname for myself. I was never given one, and over the years I used a few here and there, ranging from Nordic gods to my favourite fantasy character: Gandalf the Grey.\nI intended to create a tech blog to document my journey ever since I started my career change. But for months I was stopped by trying to decide on a name. (That’s me in a nutshell), because it needed to be perfect. Eventually I decided to just use my full name.\nAlthough I have zero connections with Russia, neither genetically nor culturally, my parents decided to give me a name of Russian origin: Mischa.\nAccording to this website, Mischa has the following meaning:\n“The name Mischa is primarily a gender-neutral name of Russian origin that means Who Is Like God“\nAlthough I admire my parents for giving me such an ambitious name, I must confess that I turned out to be of a much more earthy and less godly nature.\nWhen I was younger, an old gymnastics teacher once told me that Mischa meant “bear” in Russian, and I always liked that connotation much more. I also turned out to be more bear-like than god-like, being 190cm tall and having thick and bristly curly hair.\nIndeed, this post on Quora confirms that my name indeed has the meaning of bear:\n\u0026ldquo;In Russia Mishka sometimes also used to denote a bear, particularly a bear cub.\u0026rdquo; Misha Sivan, Born in USSR.\nAlthough I am conveniently ignoring the “cub” part of his explanation, I thought it was pretty cool that my actual name had connotations with our ursine friends.\nMoreover, I lived 9 years in Norway where I roamed the mountains for weeks at a time, just me and my tent and a fishing rod. I developed a very close connection with nature during those years. Not only its beauty, but also its merciless forces and awe-inspiring ingenuity.\nAlthough I never encountered a bear myself, they are most definitely present in the Norwegian nature. One time the newspapers told me that there was a bear sighted 4 kilometers from where I was camping one weekend.\nBut this is what the bear represents to me: the time I was allowed to spend in the North and the resulting connection with nature. The solitary character of the male, calmly roaming for many miles in search of sustenance. A force to be reckoned with when aggravated, but in general preferring to stay at a distance.\n","permalink":"https://mischavandenburg.com/why-i-chose-a-bear-for-my-logo/","summary":"I always struggled with finding an online nickname for myself. I was never given one, and over the years I used a few here and there, ranging from Nordic gods to my favourite fantasy character: Gandalf the Grey.\nI intended to create a tech blog to document my journey ever since I started my career change. But for months I was stopped by trying to decide on a name. (That’s me in a nutshell), because it needed to be perfect.","title":"Why I Chose a Bear as a Logo"},{"content":"In 2021 I had reached a certain stage in my life where I had the liberty to make a choice. I was 31 years old and had just finished an important chapter of my life, and was ready to begin a new one. After thinking about where I wanted to steer my professional career, I decided to follow my passion for programming and automation and attempt to make a career out of my interests in tech and IT.\nI was in a fortunate situation, because there were large shortages of people on the IT job market in The Netherlands. Consequently, employers were much more willing to train their employees to perform the roles that they required to fulfill.\nBots and Scripts I have always loved messing around with computers, and I learned to write small and simple programs at a very young age. At the same time I was an avid gamer, and spent many hours slaying monsters in online RPG’s. One day I came across the concept of a bot: a program that plays the computer game for you, and I was hooked. This is where I developed my ‘fetish’ for automation.\nI was very lucky that I had a friend who shared my interests, and together we built our own automation projects (called ‘botfarms’) in which we ran large amounts of bots that played a certain game for us. This army of bots generated in-game currency which we could sell for actual money. They weren’t huge profits, but it was an amazingly satisfying feeling to be the overlords of an army of automations that actually generated some income for us.\nFrom Bots to DevOps These botfarms were hosted on servers which set up ourselves. In order to save costs we rented Linux servers, and I spent many evenings figuring out how configure them via the command line. Often I would suddenly snap out of my flow at 3am and realise I had to go to work at 7 in the morning again.\nAlthough I did not manage to make these personal interests into a personal career, my friend eventually became a Data Engineer. After making the decision to make a career switch to IT I needed to figure out which direction I wanted to go in, because IT covers a very broad range of topics and skills. Based on on our shared interests and previous projects, he recommended me to become a DevOps Engineer.\nI very quickly realised that he was right on the money with his suggestion and I started to become very enthusiastic to learn how to make a living by working with computers and automation.\nTraineeship As I mentioned before, employers in The Netherlands are now willing to train potential candidates, and I used my hobby projects as a way to demonstrate my genuine interest and affinity with IT and automation. I was offered a traineeship to become a DevOps Engineer in 2021. After a period of training I started working for the City of Amsterdam and I\u0026rsquo;ve been part of an IT4IT operations team since.\n","permalink":"https://mischavandenburg.com/my-journey-into-devops-so-far/","summary":"In 2021 I had reached a certain stage in my life where I had the liberty to make a choice. I was 31 years old and had just finished an important chapter of my life, and was ready to begin a new one. After thinking about where I wanted to steer my professional career, I decided to follow my passion for programming and automation and attempt to make a career out of my interests in tech and IT.","title":"My Journey Into DevOps So Far"},{"content":"On this page I share the things I\u0026rsquo;m currently focused on, which habits I\u0026rsquo;m tracking, and what my goals are.\nReading Currenlty reading The Longevity Diet\nAlso started reading the Polity series by Neal Asher, now reading the first book Gridlinked.\nI have never read much science fiction but I\u0026rsquo;m broadening my horizon a bit.\nWith the current AI craze going on it seemed like an interesting AI themed series.\nHere is a list of all the books I\u0026rsquo;ve read\nWeekly Activity Weight Loss I\u0026rsquo;ve been on a weight loss regime sinds late 2021. I\u0026rsquo;ve maintained a caloric deficit since I started, but in some periods life got in the way and I had breaks from the caloric deficit.\nSee:\n🍎 My Weight Loss Journey And Current Goal 📉\nDiet I eat a whole foods plant based diet. I\u0026rsquo;ve been vegan for almost 7 years, but I\u0026rsquo;ve had periods where I had a vegetarian diet. Sometimes I even ate meat for a short period during the winter. But I always feel best when I go full plant based.\nI\u0026rsquo;ve narrowed my diet down to fruits and vegetables, beans, brown rice, nuts and seeds.\nMacro division:\nCarbs: 33%\nProtein: 20%\nFat: 47%\nFasting I\u0026rsquo;ve been doing some form of Intermittent Fasting for over 7 years now.\nAfter a period of eating One Meal A Day (OMAD) for a few months, I\u0026rsquo;m back on an 8 hour eating window, starting at noon and ending at 8pm.\nDaily Habits Morning Light Viewing Popularized by Andrew Huberman. Get at least 10 minutes of sunlight directly into the eyes within 2 hours of waking up.\nExercise Goal is to get at least 30 minutes of exercise everyday, but I\u0026rsquo;m averaging much more. I averaged 66 minutes over the past 6 months, and 90 minutes over the past two months (as per 2023-05-26)\nCurrently I go for a fasted run right after I wake up in the morning. I aim to do this 6 times a week. After my run I do 10 minutes of pushups and other bodyweight exercises.\nIn the afternoon I do a session of Ashtanga Yoga mostly focussing on stretching my back and hamstrings.\nAfter dinner I go for a 20 minute walk.\nMeditation I practice formal sitting meditation 30-60 minutes a day. Sometimes I\u0026rsquo;ll go for several hours a day.\nThroughout my daily activities I strive to maintain continuous mindfulness.\nRunning has become a meditation as well, and I do that for about 45 minutes a day too.\nCleaning I keep my environment clean and clutter free because it aids in mental calm, focus and well being. I want my apartment to always be presentable to visitors at any time of the day.\nWork I\u0026rsquo;ve fallen in love with Kubernetes after I obtained my CKA.\nI\u0026rsquo;m currently getting a lot of Cloud Engineer experience in an Azure environment. I focus on Azure Kubernetes Service, but I also contribute with deploying and maintaining other resources such as Virtual machines, firewalls and Application Gateways.\nAfter getting my AZ104 and AZ400 during February, I don\u0026rsquo;t have any certifications on the horizon currently because I discovered the joy of running and I\u0026rsquo;m focusing more on health and exercise in my free time. But this will change soon, everything goes in phases with me. When I feel more established in my training routines there will be mental space for learning again.\nHealth Sleep I aim to sleep 7 hours a day. My 6 month average as per 2023-05-26 is 8 hours and 4 minutes.\nExercise See above :)\nSobriety I don\u0026rsquo;t drink alcohol or use any other mind-altering drugs. On 2023-07-04 I\u0026rsquo;ll be celebrating 5 years of sobriety.\nSpirituality I\u0026rsquo;m a practicing Buddhist. I found my religion in Therevadan Buddhism, and I found that the Thai Forest Tradition of Ajahn Chah suits me best. I\u0026rsquo;ve been on the 5 precepts for nearly 5 years now.\nQuotes that Inspire me \u0026ldquo;“I’m only a scribe,” I mumbled. “All I know is clay tablets.” “Nonsense!” he interjected. “You’re skilled in language and communication, which puts you far ahead of most. And remember this—the best investment you can make is in yourself. Continue to educate yourself and seek out wisdom, adding new skills and experiences that will make you more valuable.\u0026rdquo; - location: 169 ^ref-57645 - The Richest Man in Babylon\n\u0026ldquo;The Fifth Law of Wealth: Invest in yourself. Gain knowledge and skills to increase your earning power.\u0026rdquo; - location: 184 ^ref-12741 - The Richest Man in Babylon\n","permalink":"https://mischavandenburg.com/current/","summary":"On this page I share the things I\u0026rsquo;m currently focused on, which habits I\u0026rsquo;m tracking, and what my goals are.\nReading Currenlty reading The Longevity Diet\nAlso started reading the Polity series by Neal Asher, now reading the first book Gridlinked.\nI have never read much science fiction but I\u0026rsquo;m broadening my horizon a bit.\nWith the current AI craze going on it seemed like an interesting AI themed series.","title":"Current"},{"content":"Why bother with a personal website? Why not just write on social media?\nThis post captures it beautifully.\nFavorites These articles came out particularly well, and might provide some value to you, or help you get to know me a little better.\nI\u0026rsquo;m In Love with my Work: Lessons from a Japanese Sushi Master My Neovim Zettelkasten: How I Take Notes in Markdown Using Vim and Bash How and Why I Started Using Vim What is a Zettelkasten? Zettelkasten is a system of note taking and personal knowledge management. Zettelkasten means \u0026ldquo;slip box\u0026rdquo; in German. Traditionally it is a physical box of slips of paper or index cards containing smaller notes. Each of these cards have a unique identifier, and these identifiers are used to create links between the cards.\nIt was used by Niklas Luhmann who was one of the most prolific scholars in history. He wrote 70 books and nearly 400 academic articles, and he credited the Zettelkasten with making his productivity possible. It contained around 90,000 index cards.\nI first came across this concept by reading the book How to take Smart Notes by Sönke Ahrens.\nHow to Navigate this Website To see an index of my entire Zettelkasten sorted in chronological order, visit Index (Zet). Longer articles can be viewed at the articles page.\nIf you want to see an overview of topics and notes centered around certain topics, use the Tags page. My Zettelkasten can also be searched.\nAbout This Website What you are seeing here is the public section of my personal Zettelkasten. I keep a large collection of notes which are stored as markdown files on my harddisk. Whenever I\u0026rsquo;m studying a topic by reading or watching videos I keep notes about what I learn and store them in my Zettelkasten.\nWhen I want to reflect on a certain topic or to write an article, I go through my collection of notes and link them together. Very often I find that the creation of these links will stimulate even more new connections and associations, and I end up with new ideas for even more topics of study or things that I want to write about. I use my Zettelkasten as a vehicle for reflection, learning and creativity.\nI decided to make part of my notes public so I can share my learning journey in the exciting field of DevOps, cloud computing and coding. And I recently started publishing my notes on other topics such as health and execrice as well.\nAbout me I’m Mischa. I’ve worked across various fields ranging from project management in the oil industry to health care, but my driving passion has always been IT. Fascinated since childhood, I’ve always passionately worked on projects that leveraged computers and automation to reach my goals.\nIn 2007 I started learning to code to automate the video games I used to play and to build my own websites. In 2014 I taught myself to use Linux and utilized these skills to run large-scale video game and social media automation projects to drive traffic to the websites I coded at night.\nI lived in Norway for 9 years, and when I moved back home to the Netherlands, I succeeded in following my dream and turning my passion into my career, and I’ve been working as a full-time DevOps Engineer since 2021.\nI\u0026rsquo;m in love with my work. After I finish my day\u0026rsquo;s work, I usually sit down to study more about my field. There is always something new to learn. Learning can take many forms. Very often I read or watch videos and courses and take notes. But you cannot learn everything from the books alone. You also need to learn by doing. I work on coding projects or building my Kubernetes home lab. I created a lab repo where I store all the files I use to explore these topics.\nI\u0026rsquo;m curently focused on learning Go, and I store all of my learning projects in my go repo\nLiving On The Command Line I\u0026rsquo;m a nerd. I use neovim for all of my text editing. I have a fully customized setup with dozens of custom keybindings so I can work a little more effectively, and this blog is entirely written on the command line using vim.\nI love UNIX based operating systems and I\u0026rsquo;ve built my custom setup in Arch Linux. I wrote an article about how customizing and maintaining my tailored operating system is a creative activity to me.\nIn the words of Rob Muhlenstein, \u0026ldquo;Using the Linux Bash terminal command-line is coding. Every command you type on every line is part of an interactive, ongoing program interpreted by Bash and processed by Linux.\u0026rdquo; Having this dialogue with the computer through commands is one of the most fascinating things on this earth to me, and I feel fortunate that I can work with this every day as a DevOps engineer.\nWhy Take Notes? “Your professional success and quality of life depend directly on your ability to manage information effectively.”\nTiago Forte, Building A Second Brain\nIn the modern age we consume very large amounts of information, much more than we can remember. It is therefore very important to manage your intake of information, but also the retention of that information. I find that taking notes on the topics that may be of interest to me at any given time helps me understand the subject much better, because it forces me to clearly formulate my thoughts and convert them to written form.\nOver time a large collection is built up which can be used to generate new ideas.\nI publish certain sections of my note collection hoping it might provide value to others.\nTags and links To organize my notes for the website I use tags, but in my personal note taking system I use markdown links. This is why you will sometimes see [[health]] or [[coding]] in my notes. These are the links that I make in my personal system which I use for navigation and idea generation. It\u0026rsquo;s not very pretty to have these included in the published notes, but it\u0026rsquo;s the side effect of mixing a public and private Zettelkasten.\nCode If you\u0026rsquo;re curious about the writing and publishing process of this blog, see this note.\nYou can find the source code of the blog at github.com/mischavandenburg/blog, and the contents of the zettelkasten are hosted in the zet directory at /blog/content/zet/\n","permalink":"https://mischavandenburg.com/aboutme/","summary":"Why bother with a personal website? Why not just write on social media?\nThis post captures it beautifully.\nFavorites These articles came out particularly well, and might provide some value to you, or help you get to know me a little better.\nI\u0026rsquo;m In Love with my Work: Lessons from a Japanese Sushi Master My Neovim Zettelkasten: How I Take Notes in Markdown Using Vim and Bash How and Why I Started Using Vim What is a Zettelkasten?","title":"Welcome!"}]